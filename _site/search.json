[
  
    {
      "title"       : "Deep Q-Network + ML-agents 구현",
      "category"    : "",
      "tags"        : "cuda, pytorch, unity, dqn, ml-agents",
      "url"         : "./DQN_ml_agents.html",
      "date"        : "2024-05-03 09:32:20 +0900",
      "description" : "Deep Q-Network + ML-agents 구현",
      "content"     : "에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 해당 내용은 다음의 강의 내용을 개인적으로 재학습 하기 위해 작성됨. 인프런 - 유니티 머신러닝 에이전트 완전정복 (기초편) | 민규식 DQN 알고리즘의 전체 흐름 이미지 출처0. 전체 코드 요약전체 코드는 다음의 내용으로 구성된다. 프로그램 기본 설정 필요한 파이썬 라이브러리 가져오기 파라미터 설정 유니티 연결 환경 설정 학습된 모델 저장/불러오기 연산장치 (CPU or GPU) 선택 Deep Q-Network class 정의 Layer 구현 (입/출력, Convolution layer 정의) 신경망 함수 DQNAgent class 정의 Agent 구현 환경 정의(ex. network, optimizer, memory) network 를 통한 action 선택 함수 replay memory 에 데이터 추가 함수 network parameter 학습 시키는 함수 target_network update 함수 모델 저장 함수 tensorboard 기록 함수 프로그램 동작 구현 (main) unity 와 상호 작용이 가능한 UnityEnvironment 인스턴스(env) 생성 env 로 부터 관측/target 공간 정보, step 진행 후 정보 및 구동 환경(time scale) 설정 반복문을 통해 run_step + test_step 동안 학습을 진행시킴 (run_step 마지막 단계에서 모델을 저장하고 test_mode 로 전환) 전처리: 시각적 관측 정보와 목적지 관측 정보를 전처리하여 state 로 저장 agent 를 통해 action 을 결정하고, 해당 action 으로 unity 에서 다음 step 을 진행시킴 진행된 현재 step 정보 가져옴 종료(termination) 확인 및 next_step -&gt; next_state 정보로 전처리 (train mode 일 경우) next_state 를 replay memory 에 저장 충분히 메모리에 state 정보가 차 있다면, 모델 학습으로 손실값을 계산하고, 일정 주기로 target_model 을 update 함. episode 종료 시, 필요한 설정값을 조정하고, tensorboard 에 보상/손실 값을 기록, 필요 조건마다 훈련된 모델 저장 1. 프로그램 기본 설정1.1 필요한 파이썬 라이브러리 가져오기import numpy as npimport randomimport copyimport datetimeimport platform # system (OS) 관련import torchimport torch.nn.functional as Ffrom troch.utils.tensorboard import SummaryWriterfrom collections import dequefrom mlagetns_envs.environment import UnityEnvironment, ActionTuple # (1)from malagents_envs.side_channel.engine_configuration_channel import EngineConfigurationChannel # (2)(1) 유니티 환경 클래스, 액션을 환경에 전달하기 위한 환경 객체 (2) 유니티 환경 조건을 조정하기 위한 라이브러리 (ex. 타임 스케일 조절)1.2 파라미터 설정state_size = [3*2, 64, 84] # goal-plus RGB + goal-ex RGB =&gt; 6 채널 * h * w (아래 이미지 참조)action_size = 4 # 오른쪽, 왼쪽, 위, 아래load_model = False # 모델 불러오기 여부train_mode = True # 모델 학습 여부 (True : 학습모드, False: 평가모드)batch_size = 32mem_maxlen = 10000 # replay memory 최대 크기discount_factor = 0.9 # 미래에 대한 보상 감가율learning_rate = 0.00025 # 네트워크 학습률run_step = 50000 if train_mode else 0 # 학습모드에서 진행할 스텝 수 설정 (평가 모드 = 0)test_step = 5000 # 평가 모드에서 진행할 스텝 수train_start_step = 5000 # 학습 시작 전에 리플레이 메모리에 충분한 데이터를 모으기 위해 몇 스텝동안 임의의 행동으로 게임 진행할 것인지 설정target_update_step = 500 # 타겟 네트워크를 몇 스텝 주기로 업데이트 할지 설정print_interval = 10 # 학습 진행 상황을 텐서보드에 기록할 주기save_interval = 100 # 학습 모델을 저장할 에피스드 주기 설정epsilon_eval = 0.05 # 평가모드의 eps 값epsilon_init = 1.0 if train_mode else epsilon_eval # eps 초기값epsilon_min = 0.1 # 학습구간에서의 eps 최소값explore_step = run_step * 0.8 # eps 이 감소되는 구간eplsilon_data = (epsilon_init - epsilon_min) / explore_step if train_mode else 0.05 # 한스텝당 감소하는 eps 변화량# 다음의 파라미터 값들은 실제 데이터를 가리키는 인덱스, 즉 enum 과 유사한 개념으로 사용됨.VISUAL_OBS = 0 # 시각적 관측 데이터. 에이전트가 이미지 형태로 관측하는 정보를 가리키는 인덱스 GOAL_OBS = 1 # 목적지 관측 데이터. 에이전트가 목표를 달성하는데 필요한 정포를 가리키는 인덱스VECTOR_OBS = 2 # 수치적 관측 인덱스. 에이전트가 벡터 형태로 관측하는 정보를 가리키는 인덱스OBS = VISUAL_OBS # DQN 에서는 시각적 관측 인덱스를 사용 state_size = [3*2, 64, 84] 관련 이미지이미지 출처 epsilon-greedy 를 적용한 학습에서 각 파라미터들의 사용 그래프이미지 출처1.3 유니티 연결 환경 설정game = \"GridWorld\" # 환경 빌드명 os_name = platform.system() # 현재 사용 OSif os_name == 'Windows': env_name = f\"../envs/{game}_{os_name}/{game}\" # 불러올 유니티 환경 경로elif os_name == 'Darwin': # Mac OS env_name = f\"../envs/{game}_{os_name}\"1.4 학습된 모델 저장/불러오기date_time = datetime.datetime.now().strftime(\"%Y%m%d%H%M%S\")save_path = f\"./saved_models/{game}/DQN/{date_time}\" # 모델 파일일 저장될 경로load_path = f\"./saved_models/{game}/DQN/20240503201212\" # 불러올 모델 파일 경로1.5 연산장치 (CPU or GPU) 선택device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # 연산 장치 (CPU or GPU)2. Deep Q-Network class 정의class DQN(torch.nn.Module): # 2.1 Layer 구현 (입/출력, Convolution layer 정의) def __init__(self, **kwargs): super(DQN, self).__init__(**kwargs) self.conv1 = torch.nn.Conv2d( in_channels=state_size[0], out_channels=32, kernel_size=8, stride=4 ) dim1 = ((state_size[1] - 8)//4 + 1, (state_size[2] - 8)//4 + 1) self.conv2 = torch.nn.Conv2d( in_channels=32, out_channels=64, kernel_size=4, stride=2 ) dim2 = ((dim1[0] - 4)//2 + 1, (dim1[1] - 4)//2 + 1) self.conv3 = torch.nn.Conv2d( in_channels=64, out_channels=64, kernel_size=3, stride=1 ) dim3 = ((dim2[0] - 3)//1 + 1, (dim2[1] - 3)//1 + 1) self.flat = torch.nn.Flatten() # 전체 텐서를 1차원을 변환 self.fc1 = torch.nn.Linear(64*dim3[0]*dim3[1], 512) # 완전 연결 레이어를 만들어 주기 위함. self.q = torch.nn.Linear(512, action_size) # 2.2 신경망 함수 def forward(self, x): x = x.permute(0, 3, 1, 2) # 데이터 차원 순서 변환 input : unity data (H, W, Ch) -&gt; pytorch data (Ch, H, W) x = F.relu(self.conv1(x)) x = F.relu(self.conv2(x)) x = F.relu(self.conv3(x)) x = self.flat(x) x = F.relu(self.fc1(x)) return self.q(x)2.1 Layer 구현 (입/출력, Convolution layer 정의)ML-Agents 를 사용하여 unity 부터 상태 정보를 받을 때, agent 에 설정된 카메라를 통한 이미지를 받아 사용하거나, 해당 환경에서의 좌표값 (vector) 값을 사용할 수 있다. 해당 모델에서는 이미지를 사용하여 처리할 것이므로, 이미지 처리에 적합한 convolution layer 를 사용하여 처리하는 것으로 구현되었다. convolution layer + flattent layer + linear layer 의 연결 이미지이미지 출처2.2 신경망 함수일반적으로 PyTorch 에서 신경망 모델 구현 클래스는 torch.nn.Module 을 상속받아 사용한다. 해당 부모 class 에 __call__ 메서드 상 정의에 의해 해당 class 명으로 요청 (ex. DQN())시 forward 메서드가 실행 요청된다. 구현된 신경망 모델 개념도이미지 출처3. DQNAgent class 정의class DQNAgent: # 3.1 Agent 구현 환경 정의(ex. network, optimizer, memory) def __init__(self): self.network = DQN().to(device) self.target_network = copy.deepcopy(self.network) self.optimizer = torch.optim.Adam(self.network.parameters(), lr=learning_rate) self.memory = deque(maxlen=mem_maxlen) self.epsilon = epsilon_init self.writer = SummaryWriter(save_path) if load_model == True: print(f\"... Load Model from {load_path}/ckpt\") checkpoint = torch.load(load_path+'/ckpt', map_location=device) self.network.load_state_dict(checkpoint[\"network\"]) self.target_network.load_state_dict(checkpoint[\"network\"]) self.optimizer.load_state_dict(checkpoint[\"optimizer\"]) # 3.2 network 를 통한 action 선택 함수 def get_action(self, state, training=True): self.network.train(training) epsilon = self.epsilon if training else epsilon_eval if epsilon &gt; random.random(): action = np.random.randint(0, action_size, size=(state.shape[0], 1)) else: q = self.network(torch.FloatTensor(state).to(device)) action = torch.argmax(q, axis=-1, keepdim=True).data.cpu().numpy() return action # 3.3 replay memory 에 데이터 추가 함수 def append_sample(self, state, action, reward, next_state, done): self.memory.append((state, action, reward, next_state, done)) # 3.4 network parameter 학습 시키는 함수 def train_model(self): batch = random.sample(self.memory, batch_size) state = np.stack([b[0] for b in batch], axis=0) action = np.stack([b[1] for b in batch], axis=0) reward = np.stack([b[2] for b in batch], axis=0) next_state = np.stack([b[3] for b in batch], axis=0) done = np.stack([b[4] for b in batch], axis=0) state, action, reward, next_state, done = map( lambda x: torch.FloatTensor(x).to(device), [state, action, reward, next_state, done] ) eye = torch.eye(action_size).to(device) one_hot_action = eye[action.view(-1).long()] q = (self.network(state) * one_hot_action).sum(1, keepdims=True) with torch.no_grad(): next_q = self.target_network(next_state) target_q = reward + next_q.max(1, keepdims=True).values * ((1 - done) * discount_factor) loss = F.smooth_l1_loss(q, target_q) self.optimizer.zero_grad() loss.backward() self.optimizer.step() self.epsilon = max(epsilon_min, self.epsilon - eplsilon_data) return loss.item() # 3.5 target_network update 함수 def update_target(self): self.target_network.load_state_dict(self.network.state_dict()) # 모델 저장 함수 def save_model(self): print(f\"... Save Model to {save_path}/ckpt ...\") torch.save({ \"network\" : self.network.state_dict(), \"optimizer\" : self.optimizer.state_dict(), }, save_path+'/ckpt') # tesorboard 기록 def write_summary(self, score, loss, epsilon, step): self.writer.add_scalar(\"run/score\", score, step) self.writer.add_scalar(\"model/loss\", loss, step) self.writer.add_scalar(\"model/epsilon\", epsilon, step)3.1 Agent 구현 환경 정의(ex. network, optimizer, memory) def __init__(self): self.network = DQN().to(device) # (1) self.target_network = copy.deepcopy(self.network) # (2) self.optimizer = torch.optim.Adam(self.network.parameters(), lr=learning_rate) self.memory = deque(maxlen=mem_maxlen) # (3) self.epsilon = epsilon_init # (4) self.writer = SummaryWriter(save_path) if load_model == True: # (5) print(f\"... Load Model from {load_path}/ckpt\") checkpoint = torch.load(load_path+'/ckpt', map_location=device) self.network.load_state_dict(checkpoint[\"network\"]) self.target_network.load_state_dict(checkpoint[\"network\"]) self.optimizer.load_state_dict(checkpoint[\"optimizer\"])(1) self.network = DQN().to(device) 훈련에 사용할 network 를 DQN 인스턴스를 생성하여 연산 device 메모리에 넣는다.(2) self.target_network = copy.deepcopy(self.network) 초기 Target_network 설정은 훈련용과 동일하게 설정되므로 그대로 깊은 복사하여 사용(3) self.memory = deque(maxlen=mem_maxlen) replay memory 로 사용될 자료 구조는 FIFO 구조인 deque 를 사용(4) self.epsilon = epsilon_init 초기 설정 epsilon 값으로 사용되며, 훈련이 반복되면서 앞에서 언급된 그래프의 형태와 같이 epsilon 값을 작게 하여 무작위 요소를 점차 줄여 나간다.(5) if load_model == True: 만약 기존에 저장된 model 을 사용하고자 할 경우, 해당 조건문 실행으로 기존 모델을 가져와서 실행3.2 network 를 통한 action 선택 함수 def get_action(self, state, training=True): self.network.train(training) epsilon = self.epsilon if training else epsilon_eval if epsilon &gt; random.random(): action = np.random.randint(0, action_size, size=(state.shape[0], 1)) else: q = self.network(torch.FloatTensor(state).to(device)) action = torch.argmax(q, axis=-1, keepdim=True).data.cpu().numpy() return action다음과 같이 epsilon-greedy 방법을 사용하여 무작위 값 또는 가장 큰 q값을 가진 idx 행동을 선택이미지 출처3.3 replay memory 에 데이터 추가 함수 def append_sample(self, state, action, reward, next_state, done): self.memory.append((state, action, reward, next_state, done))replay momory 에 각 상태 값들을 추가3.4 network parameter 학습 시키는 함수def train_model(self): batch = random.sample(self.memory, batch_size) # (1) state = np.stack([b[0] for b in batch], axis=0) # (2) action = np.stack([b[1] for b in batch], axis=0) reward = np.stack([b[2] for b in batch], axis=0) next_state = np.stack([b[3] for b in batch], axis=0) done = np.stack([b[4] for b in batch], axis=0) state, action, reward, next_state, done = map( lambda x: torch.FloatTensor(x).to(device), [state, action, reward, next_state, done] ) # (3) eye = torch.eye(action_size).to(device) # (4) one_hot_action = eye[action.view(-1).long()] # (5) q = (self.network(state) * one_hot_action).sum(1, keepdims=True) # (6) with torch.no_grad(): # (7) next_q = self.target_network(next_state) # (8) target_q = reward + next_q.max(1, keepdims=True).values * ((1 - done) * discount_factor) #(9) loss = F.smooth_l1_loss(q, target_q) # (10) # model update self.optimizer.zero_grad() # 기울기 초기화 loss.backward() # 역전파를 통해 gradient 계산 self.optimizer.step() # model parameter update # eps 감소 (훈련이 진행됨에 따라 무작위 적용 확률를 차츰 줄여나감) self.epsilon = max(epsilon_min, self.epsilon - eplsilon_data) return loss.item()(1) batch = random.sample(self.memory, batch_size)replay memory 에 저장된 값들 중 임의의 값을 가져옴으로써, 가져오는 데이터들 간 상관 관계가 존재하지 않게되어, 과적합 또는 선형 근사가 발생하는것을 방지 한다.아래 이미지는 하나의 episode 또는 근방에서 훈련된 step 간 동일 색으로 표현하였다. 그림과 같이 근방의 step 끼리 학습을 진행하면 전체 데이터에 대한 근사 함수가 아닌 각각에 근접한 step 에 대한 함수로 각각 근사되게 된다.이미지 출처따라서 해당 문제를 막기 위해 한번에 학습되는 step 들을 무작위 분포에서 추출해야 아래와 같이 전체에 대한 근사함수를 얻을 수 있게 된다.이미지 출처(2) state = np.stack([b[0] for b in batch], axis=0) 추출된 batch 값에서 state, action, reward, next_state, done 값들을 각각의 array 값으로 추출한다.(3) state, action, reward, next_state, done = map( lambda x: torch.FloatTensor(x).to(device), [state, action, reward, next_state, done] ) 각 상태값들의 array 값들을 실수형 tensor 로 타입 변환 후, device 메모리에 추가(4) eye = torch.eye(action_size).to(device) 주 대각선 값 1, 나머지 요소는 0인 2차원 배열 (4 * 4 (action_size))을 생성하여 device 메모리에 추가(5) one_hot_action = eye[action.view(-1).long()] action [0, 2, 3, 2, 1, 1, …] (0~3) 의 값 * 32 np array 에서 각각의 원소를 long 형 (int64) one_hot type * 32 형 으로 변경 한다. 즉 [0, 2, 3, 2, 1, 1, …] -&gt; [[1, 0, 0, 0], [0, 0, 1, 0], [0, 0, 0, 1], [0, 0, 0, 1], ….](6) q = (self.network(state) * one_hot_action).sum(1, keepdims=True)현재 상태에 대한 모델 q값 * one_hot_action = 선택된 action 에 대한 Q(x) 값 이외 값은 0 으로 변환하여 각 q값 ([32.334, 0, 0, 0]) 과 같은 형태에서 ([[\\32.334]]) 로변환하여 q에 저장한다. (즉, one_hot data 에서 0 인 부분은 모두 제거 한다.)(7) with torch.no_grad(): loss 를 계산하기 위해서 target 값이 필요하지만, target 값에 대한 제어는 별도로 이루어지므로 target 값을 얻는 과정이 network 에 영향을 주어서는 안되므로 with 문 내부에서 torch.no_grad() (gradient 추적이 되지 않는) 상태에서 값을 얻는다.(8) next_q = self.target_network(next_state) next_q : target network 을 이용하요 다음상태 s’ 에대한 q 값들을 예측함.(9) target_q = reward + next_q.max(1, keepdims=True).values * ((1 - done) * discount_factor) .max(1, keepdims=True).values : (0 차원: batch , 1 차원, action) 에서 action 차원의 최대값을 가져옴 (1 - done) : done == False 이면 1 True 이면 해당 값은 0 이 됨. discount_factor : 감가율을 곱함.즉 벨만 방정식 최적 q 를 얻는 공식 target_q = 보상값 + 감가율(다음 상태에서의 최대 Q(x)값) 을 구함 + 혹시 끝난 상태인 경우 0으로 만들어 주는 수식을 결합한 상태(10) loss = F.smooth_l1_loss(q, target_q) Huber loss 계산이미지 출처3.5 target_network update 함수 def update_target(self): self.target_network.load_state_dict(self.network.state_dict()) self.network.state_dict() : 일반 (훈련) 네트워크를 가져옴 self.target_network.load_state_dict() : 가져운 일반 네트워크를 target 네트워크로 저장4. 프로그램 동작 구현 (main)아래 도식의 동작을 구현이미지 출처if __name__ == '__main__': # 4.1 unity 와 상호 작용이 가능한 UnityEnvironment 인스턴스(env) 생성 engine_configuration_channel = EngineConfigurationChannel() env = UnityEnbironment( file_name=env_name, side_channels=[engine_configuration_channel] ) env.reset() # 4.2 env 로 부터 관측/target 공간 정보, step 진행 후 정보 및 구동 환경(time scale) 설정 behavior_name = list(env.behavior_specs.keys())[0] spec = env.behavior_specs[behavior_name] engine_configuration_channel.set_configuration_parameters(time_scale=12.0) dec, term = env.get_steps(behavior_name) agent = DQNAgent() losses, scores, episode, score = [], [], 0, 0 # 4.3 반복문을 통해 run_step + test_step 동안 학습을 진행시킴 for step in range(run_step + test_step): # 4.3.1 (run_step 마지막 단계에서 모델을 저장하고 test_mode 로 전환) if step == run_step: if train_mode: agent.save_model() print(\"TEST START\") train_mode = False engine_configuration_channel.set_configuration_parameters(time_scale=1.0) # 4.3.2 전처리: 시각적 관측 정보와 목적지 관측 정보를 전처리하여 state 로 저장 preprocess = lambda obs, goal: np.concatenate((obs*goal[0][0], obs*goal[0][1]), axis=-1) state = preprocess(dec.obs[OBS], dec.obs[GOAL_OBS]) # 4.3.3 agent 를 통해 action 을 결정하고, 해당 action 으로 unity 에서 다음 step 을 진행시킴 action = agent.get_action(state, train_mode) real_action = action + 1 action_tuple = ActionTuple() action_tuple.add_discrete(real_action) env.set_actions(behavior_name, action_tuple) env.step() # 4.3.4 진행된 현재 step 정보 가져옴 dec, term = env.get_steps(behavior_name) # 4.3.5 종료(termination) 확인 및 next_step -&gt; next_state 정보로 전처리 done = len(term.agent_id) &gt; 0 reward = term.reward if done else dec.reward next_state = preprocess(term.obs[OBS], term.obs[GOAL_OBS]) if done \\ else preprocess(dec.obs[OBS], dec.obs[GOAL_OBS]) score += reward[0] # 4.3.6 (train mode 일 경우) next_state 를 replay memory 에 저장 if train_mode: agent.append_sample(state[0], action[0], reward, next_state[0], [done]) # 4.3.7 충분히 메모리에 state 정보가 차 있다면, 모델 학습으로 손실값을 계산하고, 일정 주기로 target_model 을 update 함. if train_mode and step &gt; max(batch_size, train_start_step): loss = agent.train_model() losses.append(loss) if step % target_update_step == 0: agent.update_target() # 4.3.8 episode 종료 시, 필요한 설정값을 조정하고, tensorboard 에 보상/손실 값을 기록, 필요 조건마다 훈련된 모델 저장 if done: episode += 1 scores.append(score) score = 0 if episode % print_interval == 0: mean_score = np.mean(scores) mean_loss = np.mean(losses) agent.write_summary(mean_score, mean_loss, agent.epsilon, step) losses, scores = [], [] print(f\"{episode} Episode / Step: {step} / Score: {mean_score:.2f} /\" + \\ f\"Loss: {mean_loss:.4f} / Epsilon: {agent.epsilon:.4f}\") if train_mode and episode % save_interval == 0: agent.save_model() env.close()4.1 unity 와 상호 작용이 가능한 UnityEnvironment 인스턴스(env) 생성 engine_configuration_channel = EngineConfigurationChannel() env = UnityEnvironment( file_name=env_name, side_channels=[engine_configuration_channel] ) env.reset()env (UnityEnvironment 인스턴스)의 역할 및 기능 유니티와의 인터페이스: UnityEnvironment는 유니티 엔진과 파이썬 코드 간의 주요 인터페이스. 이 인스턴스를 통해 유니티 게임 환경을 시작, 중지 및 관리할 수 있다. 데이터 교환: 유니티 게임 환경에서 생성된 데이터(에이전트의 관측값, 보상 등)를 파이썬으로 전송하고, 파이썬에서 생성한 행동 지시를 유니티로 보내는 역할 환경 제어: side_channels을 통해 유니티 환경의 세부적인 설정을 조정할 수 있다. 이를 통해 학습 중 시뮬레이션의 속도를 조절, 테스트 중에는 보다 정밀한 테스트를 수행 가능 file_name=env_name : 유니티 게임 환경의 실행 파일 경로를 지정 side_channels=[engine_configuration_channel] : 유니티 환경의 timescale, 해상도, 그래픽 품질 등을 수정할 때 사용4.2 env 로 부터 관측/target 공간 정보, step 진행 후 정보 및 구동 환경(time scale) 설정 (유니티 브레인 설정) # 유니티 브레인 설정 behavior_name = list(env.behavior_specs.keys())[0] # env.behavior_specs : 모든 behavior 정보 (예: 관측 공간의 크기, 행동의 유형 및 크기 등)를 가지고 있음. # 해당 프로젝트에서는 behavior_sepc 중 behavior_name 만 있으면 된다. 해당 spec 은 첫번쩨 요소 이므로 [0] 의 값만 가져온다. spec = env.behavior_specs[behavior_name] # behavior_name 에 대한 spec 을 가져오며 관련 정보는 아래와 같다. # 1. 관측 공간(Obervation Space) : 에이전트가 환경에서 관측할 수 있는 데이터의 형태와 크기를 설명 # 카메라 이미지, 속도계의 값, 위치 좌표 등 # # 2. 행동 공간(Action Space) : 에이전트가 취할 수 있는 행동의 유형과 범위 # 에이전트가 조종할 수 있는 방향, 속도 조절, 점프 등의 행동 engine_configuration_channel.set_configuration_parameters(time_scale=12.0) # 시간 12 배속 (빠르게) 설정 dec, term = env.get_steps(behavior_name) # behavior_name 으로 부터 step 정보를 얻음 # dec : decision step - decision request step 정보 # term : termination step - 에피소드 종료 스텝 정보 # DQNAgent 클래스를 agent 객체 생성 agent = DQNAgent() # c.0 학습을 진행하기 위해 필요한 정보 초기화 losses, scores, episode, score = [], [], 0, 04.3 반복문을 통해 run_step + test_step 동안 학습을 진행시킴4.3.1 (run_step 마지막 단계에서 모델을 저장하고 test_mode 로 전환) for step in range(run_step + test_step): # run_step : 학습 모드 step # test_step: 테스트모드 step # test step 진행 코드 if step == run_step: if train_mode: agent.save_model() print(\"TEST START\") train_mode = False engine_configuration_channel.set_configuration_parameters(time_scale=1.0) # test_step 은 정속으로 수행4.3.2 전처리: 시각적 관측 정보와 목적지 관측 정보를 전처리하여 state 로 저장 # 전처리 : 시각적 관측 정보와 목적지 관측 정보를 전처리하여 state 에 저장 preprocess = lambda obs, goal: np.concatenate((obs*goal[0][0], obs*goal[0][1]), axis=-1) # a. obs*goal[0][0] : agent 관즉 이미지 * goal[0][0] (goal_plus 이면 1, goal_ex 이면 0) # b. obs*goal[0][1] : agent 관측 이미지 * goal[0][1] (goal_plus 이면 0, goal_ex 이면 1) # 위 값을 concatenate # -&gt; 6 채널 중 goal_plus 의 경우 전반부 3 채널에 대해 값이 채워지고, 나머지 3채널에 대한 값은 모두 0 으로 처리 # -&gt; 6 채널 중 goal_ex 의 경우 후반부 3 채널에 대해 값이 채워지고, 나머지 3채널에 대한 값은 모두 0 으로 처리 state = preprocess(dec.obs[OBS], dec.obs[GOAL_OBS]) # dec.obs : 지정된 behavior_name 을 가진 모든 agent 에 대한 모든 관측을 포함하는 튜플 # dec.obs[0] (OBS = 0 시각적 관측 idx) : 로 시각적 관측 정보를 얻을 수 있음. # dec.obs[1] (GOAL_OBS = 1 (시각적) 목적지 관측 idx) : 로 목적지의 시각적 정보를 얻음. # dec.obs[GOAL_OBS] 에서 goal_plus : [[1., 0]] / goal_ex: [[0., 1.]]4.3.3 agent 를 통해 action 을 결정하고, 해당 action 으로 unity 에서 다음 step 을 진행시킴 action = agent.get_action(state, train_mode) # get_action 을 통해 현재 state 의 eps-greedy 행동 선택 real_action = action + 1 # unity 에서 0 은 정지 action 을 의미하게 되므로 , 0 ~3 -&gt; 1 ~ 4 로 +1 action_tuple = ActionTuple() action_tuple.add_discrete(real_action) # 신경망을 통해 결정된 action 값을 동작 값으로 저장 env.set_actions(behavior_name, action_tuple) # action 을 unity 환경에 전달 env.step() # unity 에서 시뮬레이션 step 진행4.3.4 진행된 현재 step 정보 가져옴 dec, term = env.get_steps(behavior_name) # 진행한 현재 스텝 정보 가져오기4.3.5 종료(termination) 확인 및 next_step -&gt; next_state 정보로 전처리 done = len(term.agent_id) &gt; 0 # 현재 시뮬레이션은 agent 가 1개 이므로 termination agent_id 가 존재하면 종료되었음을 바로 확인 가능 reward = term.reward if done else dec.reward next_state = preprocess(term.obs[OBS], term.obs[GOAL_OBS]) if done \\ else preprocess(dec.obs[OBS], dec.obs[GOAL_OBS]) score += reward[0] # step 보상 누적4.3.6 (train mode 일 경우) next_state 를 replay memory 에 저장 # replay memory 에 data 저장 (학습 모드) if train_mode: agent.append_sample(state[0], action[0], reward, next_state[0], [done])4.3.7 충분히 메모리에 state 정보가 차 있다면, 모델 학습으로 손실값을 계산하고, 일정 주기로 target_model 을 update 함. if train_mode and step &gt; max(batch_size, train_start_step): # 충분한 학습 데이터가 모였다면 (최소 batch_size 이상) # 학습수행 loss = agent.train_model() losses.append(loss) # 타겟 네트워크 업데이트 (특정 수의 step 타이밍 마다) if step % target_update_step == 0: agent.update_target()4.3.8 episode 종료 시, 필요한 설정값을 조정하고, tensorboard 에 보상/손실 값을 기록, 필요 조건마다 훈련된 모델 저장 # episode 완료 시, if done: episode += 1 scores.append(score) score = 0 # 초기화 # 게임 진행 상황 출력 및 텐서 보드에 보상과 손실 함수 값 기록 if episode % print_interval == 0: mean_score = np.mean(scores) mean_loss = np.mean(losses) agent.write_summary(mean_score, mean_loss, agent.epsilon, step) losses, scores = [], [] print(f\"{episode} Episode / Step: {step} / Score: {mean_score:.2f} /\" + \\ f\"Loss: {mean_loss:.4f} / Epsilon: {agent.epsilon:.4f}\") # 네트워크 모델 저장 if train_mode and episode % save_interval == 0: agent.save_model() env.close()최종 전체 코드import numpy as npimport randomimport copyimport datetimeimport platform # system (OS) 관련import torchimport torch.nn.functional as Ffrom torch.utils.tensorboard import SummaryWriterfrom collections import dequefrom mlagents_envs.environment import UnityEnvironment, ActionTuple from mlagents_envs.side_channel.engine_configuration_channel import EngineConfigurationChannel state_size = [3*2, 64, 84] action_size = 4 load_model = False train_mode = True batch_size = 32mem_maxlen = 10000 discount_factor = 0.9learning_rate = 0.00025 run_step = 50000 if train_mode else 0 test_step = 5000 train_start_step = 5000 target_update_step = 500 print_interval = 10 save_interval = 100 epsilon_eval = 0.05 epsilon_init = 1.0 if train_mode else epsilon_eval epsilon_min = 0.1 explore_step = run_step * 0.8 eplsilon_data = (epsilon_init - epsilon_min) / explore_step if train_mode else 0.05VISUAL_OBS = 0 GOAL_OBS = 1 VECTOR_OBS = 2 OBS = VISUAL_OBS game = \"GridWorld\" os_name = platform.system() if os_name == 'Windows': env_name = f\"../envs/{game}_{os_name}/{game}\" elif os_name == 'Darwin': env_name = f\"../envs/{game}_{os_name}\"date_time = datetime.datetime.now().strftime(\"%Y%m%d%H%M%S\")save_path = f\"./saved_models/{game}/DQN/{date_time}\" load_path = f\"./saved_models/{game}/DQN/20240503201212\" device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") class DQN(torch.nn.Module): def __init__(self, **kwargs): super(DQN, self).__init__(**kwargs) self.conv1 = torch.nn.Conv2d( in_channels=state_size[0], out_channels=32, kernel_size=8, stride=4 ) dim1 = ((state_size[1] - 8)//4 + 1, (state_size[2] - 8)//4 + 1) self.conv2 = torch.nn.Conv2d( in_channels=32, out_channels=64, kernel_size=4, stride=2 ) dim2 = ((dim1[0] - 4)//2 + 1, (dim1[1] - 4)//2 + 1) self.conv3 = torch.nn.Conv2d( in_channels=64, out_channels=64, kernel_size=3, stride=1 ) dim3 = ((dim2[0] - 3)//1 + 1, (dim2[1] - 3)//1 + 1) self.flat = torch.nn.Flatten() self.fc1 = torch.nn.Linear(64*dim3[0]*dim3[1], 512) self.q = torch.nn.Linear(512, action_size) def forward(self, x): x = x.permute(0, 3, 1, 2) x = F.relu(self.conv1(x)) x = F.relu(self.conv2(x)) x = F.relu(self.conv3(x)) x = self.flat(x) x = F.relu(self.fc1(x)) return self.q(x)class DQNAgent: def __init__(self): self.network = DQN().to(device) self.target_network = copy.deepcopy(self.network) self.optimizer = torch.optim.Adam(self.network.parameters(), lr=learning_rate) self.memory = deque(maxlen=mem_maxlen) self.epsilon = epsilon_init self.writer = SummaryWriter(save_path) if load_model == True: print(f\"... Load Model from {load_path}/ckpt\") checkpoint = torch.load(load_path+'/ckpt', map_location=device) self.network.load_state_dict(checkpoint[\"network\"]) self.target_network.load_state_dict(checkpoint[\"network\"]) self.optimizer.load_state_dict(checkpoint[\"optimizer\"]) def get_action(self, state, training=True): self.network.train(training) epsilon = self.epsilon if training else epsilon_eval if epsilon &gt; random.random(): action = np.random.randint(0, action_size, size=(state.shape[0], 1)) else: q = self.network(torch.FloatTensor(state).to(device)) action = torch.argmax(q, axis=-1, keepdim=True).data.cpu().numpy() return action def append_sample(self, state, action, reward, next_state, done): self.memory.append((state, action, reward, next_state, done)) def train_model(self): batch = random.sample(self.memory, batch_size) state = np.stack([b[0] for b in batch], axis=0) action = np.stack([b[1] for b in batch], axis=0) reward = np.stack([b[2] for b in batch], axis=0) next_state = np.stack([b[3] for b in batch], axis=0) done = np.stack([b[4] for b in batch], axis=0) state, action, reward, next_state, done = map( lambda x: torch.FloatTensor(x).to(device), [state, action, reward, next_state, done] ) eye = torch.eye(action_size).to(device) one_hot_action = eye[action.view(-1).long()] q = (self.network(state) * one_hot_action).sum(1, keepdims=True) with torch.no_grad(): next_q = self.target_network(next_state) target_q = reward + next_q.max(1, keepdims=True).values * ((1 - done) * discount_factor) loss = F.smooth_l1_loss(q, target_q) self.optimizer.zero_grad() loss.backward() self.optimizer.step() self.epsilon = max(epsilon_min, self.epsilon - eplsilon_data) return loss.item() def update_target(self): self.target_network.load_state_dict(self.network.state_dict()) def save_model(self): print(f\"... Save Model to {save_path}/ckpt ...\") torch.save({ \"network\" : self.network.state_dict(), \"optimizer\" : self.optimizer.state_dict(), }, save_path+'/ckpt') def write_summary(self, score, loss, epsilon, step): self.writer.add_scalar(\"run/score\", score, step) self.writer.add_scalar(\"model/loss\", loss, step) self.writer.add_scalar(\"model/epsilon\", epsilon, step)if __name__ == '__main__': engine_configuration_channel = EngineConfigurationChannel() env = UnityEnbironment( file_name=env_name, side_channels=[engine_configuration_channel] ) env.reset() behavior_name = list(env.behavior_specs.keys())[0] spec = env.behavior_specs[behavior_name] engine_configuration_channel.set_configuration_parameters(time_scale=12.0) dec, term = env.get_steps(behavior_name) agent = DQNAgent() losses, scores, episode, score = [], [], 0, 0 for step in range(run_step + test_step): if step == run_step: if train_mode: agent.save_model() print(\"TEST START\") train_mode = False engine_configuration_channel.set_configuration_parameters(time_scale=1.0) preprocess = lambda obs, goal: np.concatenate((obs*goal[0][0], obs*goal[0][1]), axis=-1) state = preprocess(dec.obs[OBS], dec.obs[GOAL_OBS]) action = agent.get_action(state, train_mode) real_action = action + 1 action_tuple = ActionTuple() action_tuple.add_discrete(real_action) env.set_actions(behavior_name, action_tuple) env.step() dec, term = env.get_steps(behavior_name) done = len(term.agent_id) &gt; 0 reward = term.reward if done else dec.reward next_state = preprocess(term.obs[OBS], term.obs[GOAL_OBS]) if done \\ else preprocess(dec.obs[OBS], dec.obs[GOAL_OBS]) score += reward[0] if train_mode: agent.append_sample(state[0], action[0], reward, next_state[0], [done]) if train_mode and step &gt; max(batch_size, train_start_step): loss = agent.train_model() losses.append(loss) if step % target_update_step == 0: agent.update_target() if done: episode += 1 scores.append(score) score = 0 if episode % print_interval == 0: mean_score = np.mean(scores) mean_loss = np.mean(losses) agent.write_summary(mean_score, mean_loss, agent.epsilon, step) losses, scores = [], [] print(f\"{episode} Episode / Step: {step} / Score: {mean_score:.2f} /\" + \\ f\"Loss: {mean_loss:.4f} / Epsilon: {agent.epsilon:.4f}\") if train_mode and episode % save_interval == 0: agent.save_model() env.close()"
    } ,
  
    {
      "title"       : "(Windows) CUDA 사용 tensorflow 작업 환경 설정",
      "category"    : "",
      "tags"        : "cuda, cudnn, tensorflow",
      "url"         : "./tensorflow_gpu_setting.html",
      "date"        : "2024-04-08 09:32:20 +0900",
      "description" : "(Windows 10) CUDA 사용 tensorflow 작업 환경 설정",
      "content"     : "에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지tensflow 기반 딥러닝 학습을 하는데 cpu 기반 작업이 너무 느려서 GPU 를 사용하고자 하였으나 최신 자료는 없는것 같아 이를 다시 정리해 보았다. 다만 윈도우 환경에서 지원되는 CUDA toolkit 버젼은 그리 변화가 있지는 않았다. 사용환경 OS: Windows 10 64bits GPU : RTX 3070 GPU driver : Nvidia Graphic Driver 537.13 CUDA Toolkit : 11.2 Visual Studio : 2019 cudnn : 8.2.1 (for cuda toolkit 11.x) python : 3.10 Anacoda 가상환경 - jupyter notebook tensorflow-gpy : 2.102024년 4월 기준, 아래 페이지에서 다음과 같이 윈도우 환경에서 Nvidia GPU 사용 환경 조건을 확인 할 수 있다. 링크 : Tensorflow Build from source on Windows 1.Nvidia Graphic Driver 설치 확인 및 전체 환경 설정 조건 확인아래와 같이 우선 cmd 에서 ‘nvidia-smi’명령어를 실행하여 그래픽 드라이버라 정상적으로 설치되었는지 확인하며, 이 때 ‘CUDA Version’ 을 확인한다.만약 본인 GPU CUDA 버전과 Tensorflow 가이드에 명시된 버젼이 맞다면 해당 버젼에 맞게 모든 설정을 조정하면 된다. 그러나 내 경우와 같이 아직 해당 버젼이 지원하지 않는 경우, 낮춰 모든 설정을 적용해야 한다. 내 경우는 CUDA 11.2 로 적용하였다.2. CUDA Tookit &amp; cuDNN 설치아래 링크에서 CUDA Tookit 을 받아 설치한다. CUDA Tookit 11.2 Downlaods상위 버전의 경우, 필요한 경우 함께 visual studio 를 설치지만, 해당 버젼은 별도로 설치 해주어야 한다. 해당 버전에 맞는 visual studio 는 2019 로 아래 링크에서 다운로드 받아 추가 설치해야 한다. Visual Studio 2019 Download그리고 아래 링크에서 본인에게 맞는 버전의 cuDNN 을 다운 받는다. cuDNN download내 경우, 아래 버젼으로 받아 설치하였다.해당 파일을 받아 압축을 풀고 내부 파일들을 모두 복사하여, CUDA Toolkit 이 설치된 폴더 ( C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v11.2)에 붙여 넣는다.3. 환경변수 설정앞에서 설치한 CUDA Toolkit 이 정상적으로 설치되었는지 확인과 함께 환경 변수 경로를 추가 해준다.작업표시줄 검색창에서 “환경 변수” 를 검색하여 시스템 환경 변수 편집을 찾아 들어간다. 환경변수 버튼을 눌러서 들어가면 아래와 같이 창이 나오는데 여기에서 시스템 변수로 ‘CUDA_PATH’ 와 ‘CUDA_PATH_해당버전’ 이 포함되어 있어야 한다.(다음 작업은 필요한지 잘 모르겠다.)추가로 사용자 변수 - Path 에 아래와 같이 CUDA Toolkit 설치 경로에 bin, include, lib 폴더 경로를 추가한다.4. 아나콘다 내 가상환경 설정 및 tensorflow-gpu 설치아나콘다를 최신 버전으로 설치하고, Anaconda Prompt 를 실행한다. 여기서 가상환경을 추가할 때 phython 버젼을 앞에서 확인한 tensorflow-gpu 지원 버전을 설치한다. 내 경우는 3.10 으로 설치하여 진행하였다.conda create -n [가상환경 이름] python=3.10이후 해당 가상환경을 활성화 한다.conda activate [가상환경이름]그리고 tensorflow-gpu 를 홈페이지에서 확인한 버전으로 설치해 준다.pip install tensorflow-gpu==2.10기타 필요한 라이브러리들을 설치하고, jupyter notebook 을 실행하기 위한 notebook 을 설치하고 jupyter notebook 을 실행한다.pip install notebook...jupyter notebook5. jupyter 에서 tensorflow-gpu 정상 작동 확인jupyter 커널에서 새 notebook 을 실행하여 아래 code 를 입력하여 gpu 가 정상적으로 연결되었는지를 확인한다.from tensorflow.python.client import device_libprint(device_lib.list_local_devices())코드를 실행하면 아래와 같이 출력되는데, 만약 GPU 연결이 되지 않았다면, CPU 정보만 출력되고, GPU 관련 정보는 출력되지 않는다.만약 여기에서 CPU 만 잡힌 상태라면, 앞의 과정에서 무언가 잘못되었다는 의미이므로 다시 작업해야 한다. (개인적으로도 해당 설치까지 여러번 반복하였으며, 타 블로그 글에도 수차례 실패했다는 글이 많다.)최종적으로 성공했다면, 이제 GPU 실행 환경으로 설정하고 사용하면 된다. 우측 상단에 ‘Python 3(ipkernel)’ 로 되어 있다면 클릭해서 본인이 생성한 가상환겅 (ex. b2404) 로 선택하여 사용하면 된다."
    } ,
  
    {
      "title"       : "IPC 실습 05 - Named Semaphore",
      "category"    : "",
      "tags"        : "linux, IPC, daemon, shared systemd, socket",
      "url"         : "./service-daemon.html",
      "date"        : "2024-03-24 10:32:20 +0900",
      "description" : "개발자를 위한 반도체 SW개발 기초 (디바이스 드라이버 개발) 관련 학습 20",
      "content"     : "에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지아래 내용은 개발자를 위한 시스템 반도체 SW개발 기초(디바이스 드라이버 개발) (https://comento.kr/) 강의 내용 중 일부에 해당함.1. Systemd 란?커널이 가장 처음 띄우는 init 프로세스 (PID : 1) 시스템을 초기화 하여 여려가지 서비스 데몬들을 띄우고 관리함. 예를 들어, 디바이스 노드를 자동을 생성하는 udev 데몬도 systemd 서비스로 구동됨. journalctl 을 사용하여 각 데몬의 로그도 저장 관리함. 각 서비스 간의 의존성을 자동으로 관리 기본 Systemd 서비스 관리 명령어 systemctl status : 해당 서비스의 상태 조회 systemclt enable/disable : 해당 서비스 활성화/비활성화 systemclt start/stop : 해당 서비스 시작/종료 systemclt daemon-reload : 어떤 서비스를 수정하거나 추가했을 때 해당 명령를 통해 변경사항을 적용해줘양 함. systemctl list-unit : 모든 서비스 목록 출력 systemctl list-sockets : 서비스가 사요아는 소켓의 목록을 출력 systemctl list-dependencies : 서비스를 tree 구조로 의존성을 표시하여 출력 journalctl -fn : 모든 systemd 서비스 데몬들의 로그 출력 journalctl -fn -u .service : 모든 systemd 서비스 데몬들의 로그 출력2. Daemon 이란?여러 요청에 따라서 서비스를 제공하기 위해 백그라운드로 길게 떠 있는 프로세스사용자가 직접 제어하지 않으며 init 시스템 등이 데몬을 관리하게 됨. 부모의 PID 는 1 (systemd) 이며 세션 및 그룩 아이디는 본인 자신이어야 함 - daemonize 과정 필요 init 프로세스에 입양시킨다고 표현되기도 daemon(nochdir, noclose)데몬 프로세스를 생성 함수. nochdir : 0 이면, daemon 함수는 루트 디렉토리(/)로 현재 작업 디렉토리를 변경, 1 이면 현재 디렉토리를 변경하지 않고 진행. 일반적으로 0 의 설정값을 가지며 그 이유는 데몬 프로세스가 파일 시스템을 마운트 해제하는데 방해가 되지 않도록 하기 위함이다. noclose : 0이면, daemon 함수는 표준 입력(stdin), 표준 출력(stdout), 그리고 표준 에러(stderr)를 /dev/null로 리다이렉트. 만약 1이라면, 이러한 파일 디스크립터들을 리다이렉트하지 않음. 일반적으로 1의 값으로 설정되며 그 이유는 데몬 프로세스가 터미널과의 연결을 끊고, 백그라운드에서 조용히 실행되게 하고자함이다. 데몬 생성 과정 프로세스 분기: 부모 프로세스를 종료하고 자식 프로세스를 백그라운드에서 실행하여 세션 리더가 되게 한다. 세션 생성: 새로운 세션을 생성하여 프로세스 그룹 리더가 된다. 작업 디렉토리 변경: 파일 시스템의 마운트 해제를 방지하기 위해 작업 디렉토리를 루트(/)로 변경(nochdir 0 인 경우). 파일 모드 마스크 초기화: 새로 생성되는 파일과 디렉토리의 권한을 제어. 표준 입출력 리다이렉트: 데몬 프로세스가 터미널과의 입출력 연결을 끊음(noclose 1 인 경우). 3. 서비스 데몬 개발구현하고자 하는 서비스 데몬은 systemd socket 활셩화하는 것이다.구현 동작 systemd 소켓을 열고 listen 상태로 둠. 소켓에 접속 요청이 들어오면, systemd 는 서비스 데몬을 실행 서비스 데몬은 실행되었을 때, accept 부터 처리하게 됨. 서비스 데몬이 더이상 처리할 것이 없으면 종료함. 요청이 들어올 때마다 2~4번 작업을 반복함.구현 서비스 데몬 관련 내용 (이해가 안감…;;) 소켓으로의 접속이 없을 경우는 서비스 데몬을 열지 않아 메모리 절약 가능 Accept = yse 까지 사용하면 accpet 도 systemd 가 해주나 성능상 이유로 추천되지는 않음.4. 코드 작성1.1. 루트 파일 시스템의 /usr/lib/systemd/system 밑에 .socket 파일 생성[Unit]Description=socket for Comento Exampleservice[Socket]ListenStream=/run/comento.sock[Install]WantedBy=sockets.target1.2. systemctl enable .socket : 해당 소켓 켜기 소켓을 켜게 되면 ls -l /run/comento.sock 파일 생성2.1 루트파일 시스템의 /usr/lib/systemd/system 밑에 .service 파일 생성[Unit]Description=Comento Example service[Service]Type=forkingExecStart=/usr/bin/comento-daemonStandardOutput=journalRestart=on-failureStartLimitIntervalSec=1sStartLimitBurst=32[Install]WantedBy=basic.target"
    } ,
  
    {
      "title"       : "IPC 실습 05 - Named Semaphore",
      "category"    : "",
      "tags"        : "linux, IPC, inter-process communication, shared memory, semaphore",
      "url"         : "./IPC05.html",
      "date"        : "2024-03-22 14:32:20 +0900",
      "description" : "개발자를 위한 반도체 SW개발 기초 (디바이스 드라이버 개발) 관련 학습 19",
      "content"     : "에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지아래 내용은 개발자를 위한 시스템 반도체 SW개발 기초(디바이스 드라이버 개발) (https://comento.kr/) 강의 내용 중 일부에 해당함.1. Semaphore동시에 자원에 접근할 수 있는 스레드의 수를 제한하는 메커니즘. 일종의 카운터로, 특정 자원을 접근하려는 스레드의 수를 제어한다. 세마포어는 주로 두 가지 유형으로 나뉜다: 이진 세마포어(Binary Semaphore): 값이 0 또는 1만 될 수 있으며, 이는 뮤텍스와 유사한 방식, 자원에 대한 독점적 접근을 제어하는데 사용됨. 카운팅 세마포어(Counting Semaphore): 값이 정해진 범위 내에서 증가하거나 감소할 수 있으며, 동시에 여러 스레드가 자원에 접근할 수 있게 함. (카운팅) 세마포어의 동작 과정 읽기 작업 시작: 스레드가 읽기 작업을 시작하기 전, 쓰기 세마포어의 상태를 확인하여 쓰기 작업이 진행 중이지 않은지 확인한다. 그 후 읽기 세마포어의 카운트를 증가시켜 읽기 작업을 수행 중인 스레드의 수를 저장. 읽기 작업 종료: 스레드가 읽기 작업을 마치면, 읽기 세마포어의 카운트를 감소시켜 읽기 작업을 수행 중인 스레드의 수를 감소시킨다. 쓰기 작업 시작: 스레드가 쓰기 작업을 시작하기 전, 먼저 읽기 작업이 진행 중인지 확인하기 위해 읽기 세마포어의 카운트가 0이 될 때까지 기다린다. 이는 모든 읽기 작업이 완료됨을 의미합니다. 그 다음, 쓰기 세마포어를 잠금 상태로 전환하여 쓰기 작업을 시작한다. 쓰기 작업 종료: 쓰기 작업을 마친 후, 쓰기 세마포어를 해제하여 다른 스레드가 읽기 또는 쓰기 작업을 시작할 수 있도록 한다. 위와 같은 방법을 통해 데이터를 쓰기 작업과 읽기 작업의 충돌을 예방할 수 있다. 다만 데이터의 일관성 (data consistency) 의 경우, 위와 같은 기본적인 세마포어로는 보장될 수 없다.예를 들어 기존 데이터가 0 일때, 하나의 스레드에서 해당 값을 읽어서 +1 을 하고 나서 쓰고, 그 결과 (1)을 다른 스레드가 읽어서 -1 하여 0최종 0의 결과 값을 의도 했을 때, 단순히 읽는 과정이 마무리되었을 때 쓰기를 하는 형태로 구현한다면, 위의 과정에서 최종 결과가 0 일 수도 있고 1 이거나 -1 일 수도 있는 불확정한 상황이 발생할 수 있다.이런 과정은 해당 작업 전체 (읽기-연산-쓰기) 과정에 lock 을 사용하여, 모든 작업이 작업의 절차가 분리되지 않고 하나의 덩어리르 처리되는 원자성이 보장되도록 처리하거나 하는 등의 방식을 사용하여 처리하여야 일관성을 유지할 수 있다.2. 주요 함수sem_t *sem_open(const char *name, int oflag, mode_t mode, unsigned int value);POSIX 세마포어를 생성하거나 열기 위한 함수 name : 세마포어의 이름 oflag : O_CREAT (세마포어가 존재하지 않을 경우 생성), O_EXCL (함께 O_CREAT와 사용되며, 세마포어가 이미 존재할 경우 실패), 등 mode : 세마포어에 대한 접근 권한을 설정 (e.g. 0600) valeu : 세마포어의 초기값. 이 값은 세마포어가 생성될 때만 의미가 있으며, 세마포어가 동시에 허용할 수 있는 최대 리소스 접근 수를 나타낸다. 예를 들어, 1로 설정할 경우, 해당 세마포어는 뮤텍스(mutex)와 유사하게 동작한다.int sem_wait(sem_t *sem);세마포어의 제어권 획득 sem : 작업할 세마포어 객체에 대한 포인터int sem_post(sem_t *sem);세마포어의 제어권 내려 놓음 sem : 작업할 세마포어 객체에 대한 포인터3. code#include &lt;fcntl.h&gt;#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;string.h&gt;#include &lt;unistd.h&gt;#include &lt;sys/mman.h&gt;#include &lt;sys/stat.h&gt;#include &lt;sys/wait.h&gt;#include &lt;semaphore.h&gt;#define SEM_NAME \"comento\"int main(int argc, char *argv[]) { int *ptr, i, sem_init = 1; sem_t *sem; pid_t pid; // 동시 접근 가능 스레드 : 2 // -&gt; 두 스레드가 동시에 제어권을 가지므로써 데이터 일관성을 유지할 수 없는 상태로 만듬. if(argc == 2 &amp;&amp; !strcmp(argv[1], \"-no-sem\")) { sem_init = 2; } sem_unlink(SEM_NAME); // Remove semaphore if exists sem = sem_open(SEM_NAME, O_CREAT | O_EXCL, 0600, sem_init); if (sem == SEM_FAILED) { fprintf(stderr, \"Failed to create semaphore\\n\"); return 1; } printf(\"Mapping an anonymous share memory\\n\"); // 익명의 공유 메모리 // 프로그램 내에서 바로 해당 메모리 포인터를 받아 부모-자식 간 사용할 것이므로 이름 없이 사용 가능 ptr = mmap(NULL, sizeof(*ptr), PROT_READ | PROT_WRITE, MAP_SHARED | MAP_ANONYMOUS, -1, 0); pid = fork(); // 자식 프로세스는 1씩 10000 번 더하기 수행 if(pid == 0) { for (i = 0; i &lt; 10000; i++) { sem_wait(sem); (*ptr)++; // 해당 더하기 작업은 실제 기계어 수준에서는 // load *ptr, reg // inc reg, 1 // store reg, *ptr // 이렇게 세번의 명령어 수행으로 이루어진다. sem_post(sem); if(i % 1000 == 0) { printf(\"[Child] %d\\n\", *ptr); } } } // 부모 프로세스는 1씩 10000 번 빼기 수행 else { for (i = 0; i &lt; 10000; i++) { sem_wait(sem); (*ptr)--; // // 해당 빼기 작업은 실제 기계어 수준에서는 // load *ptr, reg // dec reg, 1 //store reg, *ptr // 이렇게 세번의 명령어 수행으로 이루어진다. sem_post(sem); if (i % 1000 == 0 ) { printf(\"[Parent] %d\\n\", *ptr); } } wait(NULL); printf(\"Final value: %d\\n\", *ptr); } return 0;}4. 실행위 코드 파일을 컴파일하고, 동시 접근 스레드를 1개만 허용하여 실행하면 그 최종 결과 값은 항상 0이 나오게 된다.user@DESKTOP:~$ gcc -o sema sema.cuser@DESKTOP:~$ ./semaMapping an anonymous share memory[Parent] -1[Parent] -1001[Parent] -2001[Parent] -3000[Child] -2652[Parent] -3039[Child] -3000[Parent] -3175[Child] -3000[Parent] -3119[Child] -3000[Parent] -3287[Child] -3000[Parent] -3250[Child] -3000[Parent] -3060[Child] -3000[Child] -2999[Child] -1999[Child] -999Final value: 0그러나 ‘-no-sem’ 옵션을 써서 부모 자식 스레드 동시 접근이 가능하도록 설정하면, 그 최종 결과는 0일 수도 있고, 아래와 같이 0 이 아닌 다른 값이 나올 수 도 있게 된다.user@DESKTOP:~$ ./sema -no-semMapping an anonymous share memory[Parent] -1[Parent] -992[Child] -177[Parent] -1005[Child] -999[Child] -626[Parent] -1001[Parent] -1006[Child] -1001[Parent] -1086[Child] -1007[Parent] -1034[Child] -1010[Parent] -1041[Child] -1021[Parent] -1078[Child] -1014[Parent] -1097[Child] -1013[Child] -1006Final value: -7"
    } ,
  
    {
      "title"       : "IPC 실습 04 - Shared Memeory",
      "category"    : "",
      "tags"        : "linux, IPC, inter-process communication, shared memory",
      "url"         : "./IPC04.html",
      "date"        : "2024-03-22 10:32:20 +0900",
      "description" : "개발자를 위한 반도체 SW개발 기초 (디바이스 드라이버 개발) 관련 학습 18",
      "content"     : "에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지아래 내용은 개발자를 위한 시스템 반도체 SW개발 기초(디바이스 드라이버 개발) (https://comento.kr/) 강의 내용 중 일부에 해당함.1. 공유메모리 란?데이터 공유를 목적으로 물리적인 메모리의 동일한 영영을 각 프로세스가 매핑 일반적인 메모리 접근과 동일한 방식으로 사용 가능 별동의 시스템콜이나 함수 없이 직접 데이터 접근이 가능하므로 작업 속도가 빠름. 여러 프로세스가 동시에 같은 영역에 작업하여 데이터의 일관성이 깨지는 것을 방지하기 위한 기법 필요 (e.g. semaphore)2. 주요 함수void *mmap(void *start, size_t length, int prot, int flags, int fd, off_t offset);파일이나 장치의 내용을 메모리에 매핑하여, 이를통해 프로세스는 파일이나 장치를 마치 메모리 배열인것저럼 접근할 수 있게 해주는 함수. start : 매핑 시작 메모리 주소. NULL 로 설정시, 커널이 자동으로 설정. length: 매핑할 메로리 크기(bytes) prot : 매핑된 메모리 영역의 보호 수준 PROT_READ : 읽기 가능 PROT_WRITE: 쓰기 가능 PROT_EXEC : 실행 가능 PROT_NONE : 접근 금지 flag : 매핑의 특성을 제어 MAP_SHARED : 매핑된 메모리 영역에 대한 변경사항이 파일이 직접 반영되며, 변경사항은 다른 모든 매핑을 통해서도 볼 수 있음. MAP_PRIVATE : 매핑된 메모리 영영에 대한 변경사항이 복사본에만 적용되며, 원본 파일은 변경되지 않음. 변경사항은 해당 프로세스에서만 볼 수 있음. MAP_FIXED : start 에 지정된 주소에 매핑을 강제. fd : 매핑할 파일의 파일 디스크립터. open 함수등을 통해 얻을 수 있음. offset: 파일 내에서 매핑을 시작할 offset. 이값은 시스템의 메모리 관리 기본단위 (페이지 - 일반적으로 4KB) 의 배수로 표기int shm_open(const char *name, int flags, mode_t mode);POSIX (Portable Operating System Interface) 기반 시스템에서 공유 메모리 객체를 생성하거나 열기 위해 사용되는 함수. 이 함수는 공유 메모리를 사용하여 프로세스 간 통신(IPC)에 활용될 수 있는 메커니즘을 제공, 해당 함수로 생성된 객체는 파일처럼 관리되며, 이를 통해 프로세스들이 메모리 공간을 공유할 수 있다. 해당 객체는 ‘/dev/shm’ 밑에 생성, 재부팅시 사라짐. name : 공유 메모리 객체 이름. ‘/’ 로 시작하는 경로 형식을 사용 flags : O_RDONLY : 읽기 전용 O_RDWR : 읽기 및 쓰기 O_CREAT : (존재하지 않을 경우) 객체 생성 O_EXCL : (O_CREATE 와 함께 사용하여), 동일 경로의 객체가 이미 존재한다면 shm_open은 -1을 반환하고, errno를 EEXIST로 설정 mode : 생성한 공유메모리 객체에 대한 접근 권한 지정 (e.g. 0644는 소유자는 읽기와 쓰기 권한 부여) 반환값: 파일 디스크립터int ftruncate(int fd, off_t length)파일 크기를 변경하는데 사용하며, 특히 공유 메모리 객체의 크기를 조정할 때 사용됨. fd : 크기를 변경하고자 하는 파일의 파일 디스크립터 length: 파일의 새로운 크기를 바이트 단위로 지정3. code#include &lt;fcntl.h&gt;#include &lt;unistd.h&gt;#include &lt;stdio.h&gt;#include &lt;string.h&gt;#include &lt;sys/mman.h&gt; // mmap, munmap, PROT_READ, PROT_WRITE, MAP_SHARED, MAP_FAILED 등을 정의#include &lt;sys/stat.h&gt; // shm_open, shm_unlink 함수 사용 시 필요한 mode 매크로(S_IRUSR, S_IWUSR 등)를 정의// POSIX 호환 시스템에서 정의된, 오류를 보고하는 데 사용되는 전역 변수 // 해당 코드에서 'errno' 변수에 함수 실행 오류 반환 값을 받아 처리하기 위해 사용#include &lt;errno.h&gt; #define SHM_NAME \"/comento_mem\"#define SHM_SIZE 4096int main(int argc, char *const argv[]) { int needs_init = 0, fd; char *ptr; // 파일 실행 '-d' 옵션 시 기존 공유 메모리 삭제 if (argc == 2 &amp;&amp; !strcmp(argv[1], \"-d\")) { printf(\"Delete the shared memory\\n\"); shm_unlink(SHM_NAME); return 0; } // '-l' : 생성된 객체를 리스트로 확인 // ls 명령어로 \"/dev/shm\" 내 파일 목록을 가져오는 것으로 구현 else if (argc == 2 &amp;&amp; !strcmp(argv[1], \"-l\")) { static char *const ls_argv[] = { \"/bin/ls\", \"/dev/shm\", NULL }; printf(\"List the shared memory:\\n\"); execve(ls_argv[0], ls_argv, NULL); fprintf(stderr, \"Failed to run ls command\"); return 5; } // 위 옵션 &amp;&amp; 옵션 없는 상태를 제외하고 예외 처리 else if(argc != 1) { fprintf(stderr, \"Usage : %s &lt;-d&gt; &lt;-l&gt;\\n\", argv[0]); return 4; } // 옵션이 없는 상태 - 공유 메모리 객체 사용 모드 설정 fd = shm_open(SHM_NAME, O_RDWR, 0600); if (fd == -1) { // 'ENOENT' : \"Error NO ENTry\" 파일, 디렉토리 또는 지정된 객체가 존지 하지 않을 때 반환되는 오류코드 // 'shm_open' 함수 실행 오류 코드를 errno 전역 변수에 할당. if (errno == ENOENT) { printf(\"Create new shared memory\\n\"); // 기존에 객체가 없는 경우 새로 생성하고 사용 모드 설정 fd = shm_open(SHM_NAME, O_CREAT | O_RDWR, 0600); printf(\"Set the size of shared memory\\n\"); if (ftruncate(fd, SHM_SIZE) == -1) { fprintf(stderr, \"Failed to ftruncate\\n\\n\"); return 2; } needs_init = 1; } else { fprintf(stderr, \"Failed to shm_open\\n\"); return 1; } } // 메모리 매핑 설정 printf(\"Mapping the shared memeory\\n\"); ptr = (char*) mmap(NULL, SHM_SIZE, PROT_READ | PROT_WRITE, MAP_SHARED, fd, 0); if (ptr == MAP_FAILED) { fprintf(stderr, \"Failed to mmap\\n\"); return 3; } // 공유 메모리 객체가 새로 생성한 상태가 아니라면, 해당 메모리에 기존에 저장된 내용을 출력 if (!needs_init) { printf(\"before: %.4095s\\n\", ptr); // 최대 4095 개 문자 출력 } scanf(\"%4095s\", ptr); munmap(ptr, SHM_SIZE); close(fd); return 0;}4. 공유 메모리 사용위 소스 파일을 컴파일 하여 사용user@DESKTOP:~$ gcc -o mmap mmap.c우선, 사용하기전 공유 메모리 객체 저장 디렉토리를 확인하면, 아무것도 없는 것을 확인할 수 있다.user@DESKTOP:~$ ls -lah /dev/shmtotal 0drwxrwxrwt 2 root root 40 Mar 22 11:40 .drwxr-xr-x 16 root root 3.5K Mar 22 11:27 ..객체 생성 파일을 실행하고, 다시 ls 명령어 또는 mmap -l 옵션을 사용하여 모두 객체가 생성되었음을 확인할 수 있다.user@DESKTOP:~$ ./mmapCreate new shared memorySet the size of shared memoryMapping the shared memeoryFirst!!!!!!!!!user@DESKTOP:~$ ls -lah /dev/shmtotal 4.0Kdrwxrwxrwt 2 root root 60 Mar 22 11:38 .drwxr-xr-x 16 root root 3.5K Mar 22 11:27 ..-rw------- 1 gon gon 4.0K Mar 22 11:38 comento_memuser@DESKTOP:~$ ./mmap -lList the shared memory:comento_mem만약 다시 객체를 생성하고자 하면 기존 저장된 내용을 확인할 수 있다.user@DESKTOP:~$ ./mmapMapping the shared memeorybefore: First!!!!!!!!!Second!!!!!!!마지막으로 해당 객체를 제거 및 확인user@DESKTOP:~$ ./mmap -dDelete the shared memoryuser@DESKTOP:~$ ls -lah /dev/shmtotal 0drwxrwxrwt 2 root root 40 Mar 22 11:40 .drwxr-xr-x 16 root root 3.5K Mar 22 11:27 ..그러나, 실제 공유 메모리의 경우, 여러 프로세스가 접근하여 읽기, 쓰기를 수행할 수 있기 때문에 위와 같이 작성하면 데이터의 일관성을 보장할 수 없다. 따라서 일관성을 보장하기 위한 추가 작업 (e.g. semaphore 구현 등) 이 필요하다."
    } ,
  
    {
      "title"       : "IPC 실습 03 - Unix socket",
      "category"    : "",
      "tags"        : "linux, IPC, inter-process communication, unix socket",
      "url"         : "./IPC03.html",
      "date"        : "2024-03-20 10:32:20 +0900",
      "description" : "개발자를 위한 반도체 SW개발 기초 (디바이스 드라이버 개발) 관련 학습 17",
      "content"     : "에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지아래 내용은 개발자를 위한 시스템 반도체 SW개발 기초(디바이스 드라이버 개발) (https://comento.kr/) 강의 내용 중 일부에 해당함.1. Unix Socket웹서버 서버-클라이언트 구조와 같이, 다수의 프로세스간 양방향 통신을 가능하게 함. serever#include &lt;sys/socket.h&gt;#include &lt;sys/un.h&gt;#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;unistd.h&gt;#include &lt;string.h&gt;#define SOCKET_NAME \"/tmp/echo_socket\"int main() { pid_t pid; int sockfd, connfd; struct socketaddr_un addr; int recv_bytes; char buf[256]; sockfd = socket(AF_UNIX, SOCK_STREAM, 0); if(sockfd &lt; 0) { fprintf(stderr, \"[Server] Failed to create socket\\n\"); return 1; } memset(&amp;addr, 0, sizeof(addr)); addr.sun_family = AF_UNIX; snprintf(addr.sun_path, sizeof(addr.sun_path) - 1, SOCKET_NAME); unlink(addr.sun_path); // remove the socket file if exists if(bind(sockfd, (struct sockaddr*)&amp;addr, sizeof(addr)) &lt; 0) { fprintf(stderr, \"[Server] Failed to bind\\n\"); return 2; } if(listen(sockfd, 0) &lt; 0) { fprintf(stderr, \"[Server] Failed to listen\\n\"); return 2; } while(1) { connfd = accept(sockfd, NULL, NULL); if(connfd &lt; 0) { fprintf(stderr, \"[Server] Failed to accept\\n\"); break; } printf(\"[Server] Client connected!\\n\"); pid = fork(); if(pid == 0) { while(1) { recv_bytes = read(connfd, buf, sizeof(buf)); if(recv_bytes &lt;= 0) { break; } printf(\"[Server] Recv : %.*s\\n\", recv_bytes, buf); write(connfd, buf, recv_bytes); } close(connfd); printf(\"[Server] Client disconnected!\\n\"); return 0; } } close(sockfd); return 3; } client#include &lt;sys/socket.h&gt;#include &lt;sys/un.h&gt;#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;unistd.h&gt;#include &lt;string.h&gt;#define SOCKET_NAME \"/tmp/echo_socket\"int main() { pid_t pid; int socketfd, recv_bytes; struct sockaddr_un addr; char buf[256]; sockfd = socket(AF_UNIX, SOCK_STREAM, 0); if(sockfd &lt; 0) { fprintf(stderr, \"[Client] Failed to create socket\\n\"); return 1; } memset(&amp;addr, 0, sizeof(addr)); addr.sun_family = AF_UNIX; snprintf(addr.sun_path, sizeof(addr.sun_path) - 1, SOCKET_NAME); if(connect(sockfd, (strcut sockaddr*)&amp;addr, sizeof(addr)) &lt; 0) { fprintf(stderr, \"[Client] Failed to connect\\n\"); return 2; } while(1) { printf(\"'q' for exit&gt;\"); buf[0] = '\\0'; scanf(\"%255s\", buf); if(!strcmp(buf, \"q\")) { break; } write(sockfd, buf, strlen(buf)); recv_bytes = read(sockfd, buf, sizeof(buf)); if(recv_bytes &lt;= 0) { printf(\"[Client] Server shutdown!\\n\"); break; } printf(\"[Client] Recv: %.*s\\n\", recv_bytes, buf); } close(sockfd); printf(\"[Client] Exit!\\n\"); return 3;}"
    } ,
  
    {
      "title"       : "IPC 실습 02 - pipe",
      "category"    : "",
      "tags"        : "linux, IPC, inter-process communication, pipe",
      "url"         : "./IPC02.html",
      "date"        : "2024-03-19 10:32:20 +0900",
      "description" : "개발자를 위한 반도체 SW개발 기초 (디바이스 드라이버 개발) 관련 학습 16",
      "content"     : "에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지아래 내용은 개발자를 위한 시스템 반도체 SW개발 기초(디바이스 드라이버 개발) (https://comento.kr/) 강의 내용 중 일부에 해당함.1. pipe 구현을 통한 부모 프로세서와 자식 프로세서 IPCpipe 개념도 #include &lt;stdio.h&gt;#include &lt;string.h&gt;#include &lt;unistd.h&gt;#include &lt;sys/wait.h&gt;int main() { pid_t pid; int pipe_from_parent_to_child[2]; int pipe_from_child_to_parent[2]; char buf[256]; pipe(pipe_from_parent_to_child); pipe(pipe_from_child_to_parent); pid = fork(); if(pid == 0) { // 사용하지 않는 fd 는 닫아줌. close(pipe_from_child_to_parent[0]); close(pipe_from_parent_to_child[1]); const char *msg = \"I'm child~!!\"; printf(\"[Child] send mes: %s\\n\", msg); write(pipe_from_child_to_parent[1], msg, strlen(msg) + 1); sleep(1); read(pipe_from_parent_to_child[0], buf, 256); printf(\"[Child] recv msg: %s\\n\", buf); close(pipe_from_child_to_parent[1]); close(pipe_from_parent_to_child[0]); } else { // 사용하지 않는 fd 는 닫아줌. close(pipe_from_child_to_parent[1]); close(pipe_from_parent_to_child[0]); const char *msg = \"I'm parent~!!\"; printf(\"[Parent] send mes: %s\\n\", msg); write(pipe_from_parent_to_child[1], msg, strlen(msg) + 1); sleep(1); read(pipe_from_child_to_parent[0], buf, 256); printf(\"[Parent] recv msg: %s\\n\", buf); close(pipe_from_child_to_parent[0]); close(pipe_from_parent_to_child[1]); } return 0;}실행user@DESKTOP:~$ vim pipe.cuser@DESKTOP:~$ gcc -o pipe pipe.cuser@DESKTOP:~$ ./pipe[Parent] send mes: I'm parent~!![Child] send mes: I'm child~!![Child] recv msg: I'm parent~!![Parent] recv msg: I'm child~!!2. 파이프 명령어 구현리눅스에서 사요하는 파이프 기호 | 도 동일한 pipe IPC 를 사용한 기능이다. 따라서, 예를 들면 cat /etc/passwd | wc -l 을 pipe IPC 를 사용하여 프로그램으로 구현해볼 수 있다. #include &lt;stdio.h&gt;#include &lt;string.h&gt;#include &lt;unistd.h&gt;#include &lt;sys/wait.h&gt;/* cat /etc/passwd | wc -l */extern char** environ;char* const front_argv[] = { \"/bin/cat\", \"/etc/passwd\", NULL};char* const back_argv[] = { \"/bin/wc\", \"-l\", NULL};int main() { pid_t pid; int pipefd[2]; pipe(pipefd); pid = fork(); if(pid == 0) { close(pipefd[0]); // 읽기 fd 사용 X dup2(pipefd[1], STDOUT_FILENO); // 쓰기 fd 를 표준출력 -&gt; 모든 표준출력은 쓰기 fd 로 전송됨 close(pipefd[1]); // 표준 출력 복제 후 닫음. execve(front_argv[0], front_argv, environ); } pid = fork(); if(pid == 0) { close(pipefd[1]); // 읽기 fd 사용 X dup2(pipefd[0], STDIN_FILENO); // 일기 fd 를 표준출력 -&gt; 읽기 fd 에서 읽ㅇ느 값을 표준입력으로 사용 close(pipefd[0]); // 표준 입력 복제 후 닫음. execve(back_argv[0], back_argv, environ); } wait(NULL); // 부모프로세스에서의 fd 는 별개로 닫아야 함. close(pipefd[0]); // 읽기 fd 가 닫히면 2번째 프로세스의 표준 입력도 close(pipefd[1]); // 닫히면서 2번째 프로세스도 종료됨. wait(NULL); return 0;}결과 확인아래와 같이 해당 파일을 실행한 결과와 cat /etc/passwd | wc -l 의 실행 결과가 동일함을 확인할 수 있다.user@DESKTOP:~$ gcc -o pipe2 pipe2.cuser@DESKTOP:~$ ./pipe227user@DESKTOP:~$ cat /etc/passwd | wc -l273. 네임드 파이프부모 자식간이 아닌 프로세스간 FIFO 파일의 경로를 알 수 있다면 통신이 가능하며, 이는 mkfifo(fifo_file, mode) 를 사용하여 수행 가능하다.따라서, 앞에서 구현한 cat /etc/passwd | wc -l 를 독립적으로 수행하는 두개의 프로세스를 구현하고 이를 연결하여 사용가능하다. 해당 사항을 shell script 로 구현하면#!/bin/bashmkfifo -m 0600 fifowc -l &lt; fifo &amp;cat /etc/passwd &gt; fiform fifo실행결과user@DESKTOP:~$ chmod +x pipe3.shuser@DESKTOP:~$ ./pipe3.sh27user@DESKTOP:~$ cat /etc/passwd | wc -l27"
    } ,
  
    {
      "title"       : "IPC 실습 01 - fork / execve",
      "category"    : "",
      "tags"        : "linux, IPC, inter-process communication, fork, execve",
      "url"         : "./IPC01.html",
      "date"        : "2024-03-18 10:32:20 +0900",
      "description" : "개발자를 위한 반도체 SW개발 기초 (디바이스 드라이버 개발) 관련 학습 15",
      "content"     : "에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지아래 내용은 개발자를 위한 시스템 반도체 SW개발 기초(디바이스 드라이버 개발) (https://comento.kr/) 강의 내용 중 일부에 해당함.fork 를 사용한 자식 프로세스 생성 및 종료아래와 같이 소스코드를 작성하여 자식 프로세스의 생애 주기 (생성 - 작업 - 좀비(작업완료) - 정리) 를 확인할 수 있는 코드를 작성한다.#include &lt;stdio.h&gt;#include &lt;unistd.h&gt;#include &lt;sys/wait.h&gt;extern char **environ; // 환경변수를 나타내는 전역 변수char ppid_str[32];char* const ps_argv[] = { \"/bin/ps\", \"-fx\", NULL,};int run_ps() { // 현재 작업 중인 시스템 프로세스 리스트를 확인하기 위한 자식 프로세스 생성 -- (b) int status; pid_t pid; printf(\"Process list &gt;\\n\"); pid = fork(); if (pid == 0) { execve(ps_argv[0], ps_argv, environ); // execve 시스템 콜 실행 -- (c) } waitpid(pid, &amp;status, 0/*no option*/); }int main() { // fork 프로세스 생애 주기를 보기 위해 순차적 작업 구현 -- (a) int status; pid_t pid; pid = fork(); if (pid == 0) { // c. 생성된 자식 프로세스의 작업 printf(\"[Child] pid-%d ppid-%d\\n\", getpid(), getppid()); sleep(1); // 부모프로세스 printf(\"[Child] exit\\n\"); return 3; // c-1. 자식 프로세스 작업 종료 } else { // p. 부모 프로세스 printf(\"[Parent] pid-%d\\n\", getpid()); run_ps(); // p-1 작업 수행 sleep(2); // 자식 프로세스 작업 완료 대기 run_ps(); // p-2 자식 프로세스 작업 완료 후 전체 시스템 프로세스 상태 확인 waitpid(pid, &amp;status, 0/*no option*/); // p-3 자식 프로세스 작업 완료 대기 및 좀비 프로세스 정리 후 printf(\"[Parent] child exit: %d\\n\", WEXITSTATUS(status)); // 자식 프로세스 종료 상태 확인 run_ps(); // p-4 (자식 프로세스를 완전히 제거한 이후) 프로세스 실행 상태 확인 printf(\"[Parent] exit\\n\"); return 0; }}a. fork 프로세스 생애 주기를 보기 위해 순차적 작업 구현pid = fork(); 를 수행하면 동일한 내용을 가진 부모 프로세스와 자식 프로세스가 생성된다. 다른 점은 해당 시스템콜 수행후 반환값 pid 는 자식프로세스는 0, 부모 프로세스는 자식 프로세스 PID 값을 가지게 된다.따라서 그다음 조건문에서 각각의 프로세스 작업이 달라지게 되며, 각각의 작업은 동시에 수행되므로, 작업의 우선 순위를 확정할 수 없다. 여기서는 그 작업을 시간 순서대로 실행시켜서 그 생애 주기를 정확하게 확인하기 위해 필요한 구간에 각 프로세스에 sleep() 조건을 주어서 구현하였다.그 작업 과정을 시간 순서대로 정리하면 아래와 같다. 부모/ 자식 프로세스 각각 pid 출력 (우선순위 없음) 부모 p-1 : 자식 프로세스가 아직 실행 중인 상태에서 시스템 프로세스 리스트를 출력하는 작업 수행 자식 c-1 : 자식 프로세스 내부 작업을 종료. 해당 프로세스는 반환 값(3) 을 가진 좀비 상태로 전환됨. 부모 p-2 : 시스템 프로세스 리스트를 출력하는 작업 수행. 여기서 아직 자식 프로세스가 좀비(z) 상태로 남아있음을 볼 수 있다. 부모 p-3 : 좀비 상태의 자식 프로세스를 정리하고, 자식 프로세스 반환값(3)을 확인. 부모 p-4 : 마지막으로 시스템 프로세스 리스트에서 자식 프로세스가 사라짐을 확인.위 내용을 실제로 실행하여 그 결과를 확인하면 아래와 같다user@DESKTOP:~$ gcc -o fork fork.cuser@DESKTOP:~$ ./fork[Parent] pid-7653Process list &gt;[Child] pid-7654 ppid-7653 PID TTY STAT TIME COMMAND 437 pts/1 S+ 0:00 -bash 372 pts/0 Ss 0:00 -bash 7653 pts/0 S+ 0:00 \\_ ./fork 7654 pts/0 S+ 0:00 \\_ ./fork 7655 pts/0 R+ 0:00 \\_ /bin/ps -fx 431 ? Ss 0:00 /lib/systemd/systemd --user 432 ? S 0:00 \\_ (sd-pam)[Child] exitProcess list &gt; PID TTY STAT TIME COMMAND 437 pts/1 S+ 0:00 -bash 372 pts/0 Ss 0:00 -bash 7653 pts/0 S+ 0:00 \\_ ./fork 7654 pts/0 Z+ 0:00 \\_ [fork] &lt;defunct&gt; 7664 pts/0 R+ 0:00 \\_ /bin/ps -fx 431 ? Ss 0:00 /lib/systemd/systemd --user 432 ? S 0:00 \\_ (sd-pam)[Parent] child exit: 3Process list &gt; PID TTY STAT TIME COMMAND 437 pts/1 S+ 0:00 -bash 372 pts/0 Ss 0:00 -bash 7653 pts/0 S+ 0:00 \\_ ./fork 7665 pts/0 R+ 0:00 \\_ /bin/ps -fx 431 ? Ss 0:00 /lib/systemd/systemd --user 432 ? S 0:00 \\_ (sd-pam)[Parent] exit해당 출력중 아래에 해당하는 항목을 보면, 자식 프로세스 작업을 완료한 이후 7654 pts/0 Z+ 0:00 \\_ [fork] &lt;defunct&gt;state 는 좀비(z) 이며 처리된 것을 볼 수 있다.b. 현재 작업 중인 시스템 프로세스 리스트를 확인하기 위한 자식 프로세스 생성run_ps() 는 현재 실행 중인 시스템 프로세스 목록을 출력하기 위한 명령어 ps 을 해당 명령어 파일로 실행 시키는 함수 이다.해당 함수 내에서 실제로 ps 명령어를 실행하는 작업은 fork 하여 자식 프로세스가 작업하도록 구성되어 있으며, 해당 프로세스는 아래와 같이 출력됨을 확인 할 수 있다. 7655 pts/0 R+ 0:00 \\_ /bin/ps -fxc. execve 시스템 콜 실행` execve(ps_argv[0], ps_argv, environ) 시스템 콜이 자식 프로세스가 ps` 명령어를 실행 시키는 부분이다.해당 함수의 매개 변수를 보면 다음가 같다.execve(filename, argv, env) filename : 현재 프로세스에서 실행 시킬 파일 argv : 실행 프로그램에 전달할 인자 배열. 배열 첫번째는 일반적으로 실행파일의 이름, 중간 인자들은 해당 프로그램 실행시 설정 옵션, 파라미터 들, 마지막은 NULL 로 종료를 의미한다. env(환경변수) : 실행 프로그램에게 전달되는 환경 변수 배열이며, 각 환경 변수는 “KEY=value” 형태의 문자열이며, 마지막 값은 NULL 이어야 한다. 다만, 환경변수는 프로세스가 실행될 때, 자체적으로 설정되며, 해당 변수를 extern char **environ; 선언으로 포인터로 지정해서 사용하게 된다."
    } ,
  
    {
      "title"       : "udev 와 연동하기",
      "category"    : "",
      "tags"        : "linux, device driver, udev",
      "url"         : "./udev1.html",
      "date"        : "2024-03-02 10:32:20 +0900",
      "description" : "개발자를 위한 반도체 SW개발 기초 (디바이스 드라이버 개발) 관련 학습 14",
      "content"     : "에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지아래 내용은 개발자를 위한 시스템 반도체 SW개발 기초(디바이스 드라이버 개발) (https://comento.kr/) 강의 내용 중 일부에 해당함.1. udev 란?리눅스 시스템에서 장치 관리를 담당하는 사용자 공간의 데몬. 이는 커널에서 장치 이벤트를 수신하고, 이를 기반으로 장치 파일을 동적으로 생성하거나 삭제하며, 장치에 대한 규칙을 처리하는 역할을 한다. udev의 주요 목적은 시스템이 실행 중일 때 장치를 관리하고, 장치 간의 일관된 명명 규칙을 유지하며, 사용자가 정의한 규칙에 따라 장치에 대한 추가적인 설정을 자동으로 적용하는 것이다.주요 기능 동적 장치 관리: udev는 USB 드라이브나 네트워크 어댑터 같은 하드웨어 장치가 시스템에 추가되거나 제거될 때, 해당 변화를 감지하고 반응한다. 이를 통해, 시스템은 실행 중에도 장치의 추가 및 제거를 실시간으로 처리할 수 있다. 특히 해당 경우는, 미리 앞에서 학습한 방법(major 번호를 미리 입력)으로 처리할 수 없다. (ex. USB 인식) 장치 파일 생성 및 삭제: 장치가 시스템에 연결될 때, udev는 /dev 디렉토리에 해당 장치를 대표하는 장치 파일(또는 노드)을 생성합니다. 장치가 제거되면, 해당 파일도 삭제됩니다. 이 과정은 자동으로 수행되어 사용자나 시스템 관리자가 수동으로 장치 파일을 관리할 필요가 없습니다. 규칙 기반 장치 관리: udev는 /etc/udev/rules.d와 같은 디렉토리에 저장된 규칙 파일을 사용하여 장치에 대한 세부적인 관리를 수행합니다. 이 규칙들은 장치의 명명, 권한 설정, 장치에 대한 사용자 정의 액션 실행 등을 정의할 수 있습니다. 장치 정보 제공: udev는 연결된 장치에 대한 상세한 메타데이터를 제공합니다. 이 정보는 시스템이 장치를 정확히 식별하고, 적절한 드라이버를 로드하며, 사용자 정의 규칙을 적용하는 데 사용됩니다. 사용자 정의 액션: 사용자는 udev 규칙을 통해 특정 장치에 대해 특정 이벤트가 발생했을 때 실행할 명령이나 스크립트를 지정할 수 있습니다. 이를 통해 장치가 시스템에 연결될 때 자동으로 필요한 설정을 적용하거나, 필요한 서비스를 시작할 수 있습니다. 장치 인식 process새로운 디바이스가 인식되면, 커널이 uevent 를 발생시켜서 udev 데몬에게 이를 알림 udev 데몬은 /sys 를 확인하여 디바이스에 대한 정보를 알아냄 커널이 /sys/devices 와 /sys/class 에 새로운 디바이스에 대한 디렉토리를 생성 디렉토리 내의 dev 파일을 읽으면 주번호와 부번호를 알 수 있음. udev 데몬은 알아낸 정보를 바탕으로 새로운 디바이스 노드를 /dev 에 생성2. device class리눅스 커널의 디바이스 모델에서 “디바이스 클래스(Device Class)”는 시스템 내의 디바이스들을 분류하는 방법 중 하나. 유사한 기능이나 목적을 가진 디바이스들을 그룹화하여 관리예를 들면, input 클래스 : 키보드, 마우스 등의 입력 장치를 포함 net 클래스 : 네트워크 인터페이스 카드(NICs)와 같은 네트워킹 장치를 포함디바이스 클래스 기능 통합된 관리: 디바이스 클래스는 특정 유형의 디바이스들(예: 입력 디바이스, 네트워크 인터페이스, 오디오 장치 등)을 묶어서 일관된 방식으로 시스템 내에서 작동할 수 있도록 관리. 자동 디바이스 파일 생성: /dev 디렉토리에 있는 디바이스 파일들은 사용자 공간의 애플리케이션이 커널의 디바이스 드라이버와 통신하는 인터페이스를 제공한다. 클래스 시스템을 사용하면, 새로운 디바이스가 시스템에 추가될 때 자동으로 해당 디바이스 파일이 생성된다. 시스템의 가시성 및 접근성 향상: /sys/class 내에는 각 디바이스 클래스에 대한 디렉토리가 있으며 (ex. input, mem, pci_bus, net, tty ..), 이는 디바이스에 대한 메타데이터와 상태 정보를 제공한다. 이 정보를 통해 사용자나 애플리케이션은 디바이스의 현재 상태를 쉽게 파악할 수 있다. 표준화된 인터페이스 제공: 디바이스 클래스는 개발자들에게 표준화된 프로그래밍 인터페이스를 제공한다. 이를 통해 개발자는 특정 클래스에 속하는 모든 디바이스들과 일관된 방식으로 상호작용할 수 있게 된다. 3. 디바이스 생성을 udev 에게 알리기 class_create(owner, name): /sys/class 에 새로운 디바이스 클래스 생성 owner : 어떤 모듈에 속해 있는가를 나타냄 (자체 모듈인 경우 THIS_MODULE 로 지정) device_create(class, parent, dev_no, data, name): 새로운 디바이스 생성 (/dev) parent : 부모 디바이스 (일반적으로 버스 디바이스) 를 나타내며 NULL 로 지정 가능 dev_no : MKDEV(major, minor) 매크로를 사용하여 주번호, 부번호 명시. (MKDEV 매크로는 주/부번호를 하나의 디바이스 번호로 결합항 디바이스 파일 고유 식별자 역할을 함.) data : 디바이스와 관련된 데이터를 지정 name : 디바이스의 이름을 지정. printf 함수에서 사용하는 것과 유사하게, 문자열과 숫자를 조합하여 디바이스 이름을 생성할 수 있다. (ex. \"%s%d\", DEVICE_NAME, minor) -&gt; /sys/devices/ 에 새로운 디렉토리와 dev 파일 생성 4. 드라이브 노드 소스코드 작성기존 /linux/drivers/comento/main.c 파일의 init 함수 내용을 수정한다.아래 첫번째 코드는 udev 를 사용하는 해당 함수의 정식적 구조를 따라 작성된 것이며, 그 아래 코드는 해당 포스트 실습에서 사용한 간략화된 코드 이다. 일반적 구조 구현 코드```c#include &lt;linux/device.h&gt;#include &lt;linux/fs.h&gt;#define COMENTO_DEVICE_NAME “comento-device”#define COMENTO_CLASS_NAME “comento”static struct file_operations comento_device_fops;static int comento_device_major;static struct class *comento_class;static struct device *comento_device;static int __init comento_module_init(void) { int minor = 0;comento_device_major = register_chardev( 0, COMENTO_DEVICE_NAME, &amp;comento_device_fops );if(comento_device_major &lt; 0) { printk(KENR_ERR \"%s: Failed to get major number\", COMENTO_DEVICE_NAME); ret = comento_device_major; goto err_register_chrdev;}comento_class = class_create(THIS_MODULE, COMENTO_CLASS_NAME);// 반환값이 error 인지 확인 if(IS_ERR(comento_class)) { printk(KERN_ERR \"%s: Failed to create class\", COMENTO_DEVICE_NAME); ret = PTR_ERR(comento_class); goto err_class; // goto 문의 사용은 일반적으로 anti-pattern 이지만, // 예외적으로 어떤 자원의 획득과 해제 관련(해당의 경우) 자주 사용됨. }comento_device = device_create( comento_class, NULL, MKDEV(comento_device_major, minor), NULL, \"%s%d\", COMENTO_DEVICE_NAME, minor );if (IS_ERR(comento_device[minor])) { ret = PTR_ERR(comento_device[minor]); goto err_device;}// error 발생시 class 해제 device 등록 해제 err_device: class_destroy(comento_class);err_class: unregister_chrdev(comento_device_major, COMENTO_DEVICE_NAME);err_register_chrdev: return ret; }module_init(comento_module_init);* 실습 구현 코드```c...#include &lt;linux/spinlock.h&gt;// 기존 device name, major number 설정값 삭제// #define COMENTO_DEVICE_NAME \"comento-device\"// #define COMENTO_MAJOR_NUMBER 177#define COMENTO_BUF_SIZE 16...// 현재 코드에서 구현하지 않았지만 일반적으로 exit 할 때, // class / device 모두 destroy 처리해준다. // 이 때 goto 문 이용하기도 하므로 이런 이유로 전역 변수로 선언해준다. static struct class* class;static struct device* device;static int __init comento_module_init(void){ printk(KERN_DEBUG \"%s\\n\", __func__); // udev 를 통해서 major 번호를 자동 부여받을 것이브로 0 (자동 지정) 으로 설정 int major = register_chrdev(0, \"comento\", &amp;fops); int minor = 17; // 임의의 숫자 부여 // THIS_MODULE : 이 모듈이 클래스의 주인 (owner)임을 명시. (최신 코드에서는 명시하지 않음?) // owner의 의미 : 이 모듈이 사라졌을 때, class destroy 를 따라하지 않는다고 하더라도 // 해당 클래스는 알아서 사라지게 된다. 이유는 owner 인 `THIS_MODULE` 이 사라졌기 때문이다. // 그래도 일반적으로 exit 할 때, 해당 클래스를 destroy 해준다. class = class_create(\"comento\"); // 부모 디바이스, data 는 NULL // name : printf 함수에서 사용하는 것과 유사하게, 문자열과 숫자를 조합하여 디바이스 이름을 생성 device = device_create(class, NULL, MKDEV(major, minor), NULL, \"%s%d\", \"comento\", minor); return 0; // 자동 지정 이므로 0 으로 설정}...빌드 &amp; ko 파일 rootfs 이미지 내 추가, QEMU 실행user@DESKTOP:~/linux$ ARCH=arm64 CROSS_COMPILE=/home/gon/gcc-arm-10.3-2021.07-x86_64-aarch64-none-linux-gnu/bin/aarch64-none-linux-gnu- makech64-none-linux-gnu/bin/aarch64-none-linux-gnu- make CALL scripts/checksyscalls.sh CC [M] drivers/comento/main.o LD [M] drivers/comento/comento.o MODPOST Module.symvers LD [M] drivers/comento/comento.kouser@DESKTOP:~/linux$ sudo mount -o loop buildroot/output/images/rootfs.ext4 /mntuser@DESKTOP:~/linux$ sudo cp drivers/comento/comento.ko /mnt/usr/lib/modules/.user@DESKTOP:~/linux$ sync user@DESKTOP:~/linux$ sudo umount /mntuser@DESKTOP:~/linux$ cd ..user@DESKTOP:~$ qemu-system-aarch64 -kernel linux/arch/arm64/boot/Image -drive format=raw,file=buildroot/output/images/rootfs.ext4,if=virtio -append \"root=/dev/vda console=ttyAMA0 nokaslr\" -nographic -M virt -cpu cortex-a72 -m 2G -smp 25. 커널 모듈 삽입 및 실행# cd /sys/class# lsata_device drm misc scsi_device ttyata_link graphics net scsi_disk vcata_port hwmon pci_bus scsi_generic virtio-portsbdi i2c-adapter power_supply scsi_host vtconsoleblock input pps thermal wakeupbsg iommu ptp tpmdevlink mem rtc tpmrm위와 같이 /sys/class 에 들어가면 기존 class 디렉토리들이 있다.# insmod /usr/lib/modules/comento.ko# lsata_device devlink mem rtc tpmrmata_link drm misc scsi_device ttyata_port graphics net scsi_disk vcbdi hwmon pci_bus scsi_generic virtio-portsblock i2c-adapter power_supply scsi_host vtconsolebsg input pps thermal wakeupcomento iommu ptp tpm# cd comento# ls -lahtotal 0drwxr-xr-x 2 root root 0 Mar 3 08:48 .drwxr-xr-x 36 root root 0 Mar 3 08:46 ..lrwxrwxrwx 1 root root 0 Mar 3 08:53 comento17 -&gt; ../../devices/virtual/comento/comento17comento 커널 모듈을 삽입해주면 comento 디렉토리가 추가된것을 확인할 수 있으며, 해당 디렉토리 안에 코드에서 명명한 대로 comento17 (minor 번호 추가) 디바이스가 생성된 것을 볼 수 있다. 해당 파일을 symbolic link 실제 파일은 /sys/devices/virtual/coment/comento17 에 존재함을 알 수 있다 해당 경로로 다시 가보면,# cd /sys/devices/virtual/comento/comento17# ls -lahtotal 0drwxr-xr-x 3 root root 0 Mar 3 08:53 .drwxr-xr-x 3 root root 0 Mar 3 08:53 ..-r--r--r-- 1 root root 4.0K Mar 3 08:59 devdrwxr-xr-x 2 root root 0 Mar 3 08:59 powerlrwxrwxrwx 1 root root 0 Mar 3 08:59 subsystem -&gt; ../../../../class/comento-rw-r--r-- 1 root root 4.0K Mar 3 08:59 uevent여기에 dev 파일이 존재한다. 그 내용을 출력해보면# cat dev248:17주번호:부번호 를 볼 수 있다. 주번호 값은 udev 데몬 가 할당한 임의의 번호임도 확인 된다. 주번호, 부번호는 /dev/coment 내 존재하는 드라이버 노드 정보로도 확인 가능하다.# ls -lah /dev/comento*crw------- 1 root root 248, 17 Mar 3 08:48 /dev/comento17앞에서 확인한 내용과 udev 를 사용하여 어떻게 디바이스 파일이 생성되는지 과정을 정리하면 아래와 같다. 커널 모듈을 삽입 (insmod): 해당 모듈을 커널에 로드 uevent 발생: 시스템에 새로운 하드웨어가 추가되었거나, 새로운 드라이버가 로드되었음을 알림 udev class 생성 (/sys/class/): 커널 모듈(또는 드라이버) 내에서 class_create() 함수를 호출하여 디바이스 클래스를 생성하고, 이 정보는 /sys/class/에 반영 udev는 앞에서 생성한 정보를 바탕으로 작업을 수행 주번호 및 디바이스 생성 (/sys/device/): 커널에 의해 주번호가 생성되며, 커널 모듈이나 드라이버는 디바이스 파일에 대한 메이저 번호와 마이너 번호를 할당받아 사용. /sys/devices/는 실제 장치와 그 속성을 반영하는 커널의 디바이스 트리를 나타내며, 여기서 디바이스는 커널이나 모듈에 의해 등록됨. 드라이버 생성 (/dev/): /dev/ 디렉토리에 디바이스 파일이 생성됨. 이 과정은 udev에 의해 자동으로 처리되며, /dev/ 내의 디바이스 파일은 사용자 공간에서 해당 디바이스에 접근하기 위한 인터페이스를 제공. udev 규칙에 따라 디바이스 파일의 이름, 권한 등이 설정."
    } ,
  
    {
      "title"       : "Device Driver 개발 3 (파일 특수 제어 (ioctl) 구현)",
      "category"    : "",
      "tags"        : "linux, device driver, device node, ioctl",
      "url"         : "./device_driver3.html",
      "date"        : "2024-03-02 10:32:20 +0900",
      "description" : "개발자를 위한 반도체 SW개발 기초 (디바이스 드라이버 개발) 관련 학습 13",
      "content"     : "에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지아래 내용은 개발자를 위한 시스템 반도체 SW개발 기초(디바이스 드라이버 개발) (https://comento.kr/) 강의 내용 중 일부에 해당함.1. 파일 특수 제어 (ioctl) 이란?ioctl은 리눅스에서 주로 사용되는 시스템 콜 중 하나로, “Input/Output Control”의 약자이다. 단순 읽기/쓰기 외 디바이스 드라이버에 특정 명령을 전달하거나, 드라이버의 상태를 변경하거나, 내부 데이터를 얻기 위해 사용된다. 일반적인 파일 입출력 시스템 콜과는 달리, ioctl을 통해 디바이스 특화 명령을 수행할 수 있기 때문에, 다양한 종류의 하드웨어 디바이스와 상호작용하는 데 매우 유용하다.unlocked_ioctl 함수 포인터 프로토타입 : long (*unlocked_ioctl)(struct file *file, unsigned int cmd, unsigned long arg); struct file *file : 현재 열린 파일(디바이스)을 나타내는 file 구조체에 대한 포인터. 이 구조체는 파일에 대한 중요한 정보를 담고 있으며, ioctl 호출 시 해당 디바이스 파일에 대한 참조를 제공. unsigned int cmd : 디바이스 드라이버에 전달된 명령. user space에서 ioctl 함수를 호출할 때 지정한 명령 코드가 이 인자로 전달된다. 드라이버는 이 코드를 사용하여 어떤 작업을 수행할지 결정한다. 명령 코드는 보통 드라이버의 헤더 파일에 상수로 정의되어 있다. cmd 의 경우 일반적을 _IOR과 _IOW 매크로를 사용해서 정의 한다. _IO(type, nr): arg 없이 단순한 명령 매크로. type은 (디바이스 고유의) 명령 유형, nr 은 명령의 고유 번호를 의미 _IOW(type, nr, size): arg 를 사용해서 user space 에 size 만큼의 데이터를 kernel 에 넘김. _IOR(type, nr, size): arg 를 사용해서 kernel 내에서 읽고, 해당 data 를 size 크기 만큼 가져옴. 이를 사용하여 파일 읽기/쓰기와는 다른 디바이스의 상태, 구성, 또는 내부 정보 등을 읽거나 수정할 수 있다. unsigned long arg : 명령에 대한 추가 데이터를 포함할 수 있는 사용자 공간의 포인터 또는 값. 명령의 성격에 따라 이 값은 주소 값일 수도 있고, 직접적인 데이터 값일 수도 있다. 드라이버는 이 값을 통해 필요한 추가 정보를 얻거나 사용자 공간으로 데이터를 전달할 수 있다. unlocked_ioctl 함수는 성공 시 0 또는 양의 정수를, 실패 시 음의 에러 코드를 반환한다. 이 반환 값은 시스템 콜을 호출한 사용자 공간 프로세스에게 전달된다.(unlocked_ioctl 대신 ioctl 함수 포인터를 사용하는 이유 중 하나는, unlocked_ioctl이 빅 커널 락(BKL, Big Kernel Lock)을 사용하지 않기 때문이다. 이는 더 나은 성능과 동시성을 제공하며, 현대의 멀티코어 시스템에서 중요한 특징이다. 따라서, 새로운 드라이버를 작성할 때는 unlocked_ioctl을 사용하는 것이 권장된다.)2. 파일 특수 제어 (ioctl) 구현기존의 main.c 파일에 ioctl 관련 구현 내용을 추가해 준다. 해당 코드는 buffer 내용을 지우는 (clear) 하는 작업을 정의하였다.#define COMENTO_MAGIC 'c' // type ( ioctl 명령을 유일하게 식별하기 위한 문자)#define COMENTO_IOCTL_CLEAR _IO(COMENTO_MAGIC, 0) // nr: 0 함수 내부 switch 문의 구분 번호static long comento_device_ioctl(struct file *fp, unsigned int cmd, unsigned long arg) { switch(cmd) { case COMENTO_IOCTL_CLEAR: memset(comento_device_buf, 0, COMENTO_BUF_SIZE); break; default: printk(KERN_DEBUG \"%s failed - %d\\n\", __func__, cmd); return -EINVAL; // 정의되지 않은 값이 입력된 경우, \"Invalid Argument\" 오류 반환 } return 0;}//...static struct file_operations comento_device_fops = { // ... .unlocked_ioctl = comento_device_ioctl,};한편, 이전 post - 파일 읽기/ 쓰기 에서는 파일 읽기/쓰기 기능만 사용되므로, 기존의 읽기/쓰기 함수를 사용하여 구현하였다. 그러나 ioctl 은 사용자 정의 명령을 통해 특정 디바이스 드라이버와 상호작용해야 하므로, 이를 별도로 구현해 주어야 한다. 이와 관련하여 해당 내용은 다음과 같다.#include &lt;sys/ioctl.h&gt;#include &lt;linux/limits.h&gt;#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;fcntl.h&gt;#include &lt;unistd.h&gt;#define COMENTO_DEVICE_NAME \"comento\" // 디바이스 파일명 #define COMENTO_MAGIC 'c'// 디바이스에 대한 ioctl 명령을 정의, _IO 매크로를 사용하여 COMENTO_IOCTL_CLEAR 명령을 생성// 해당 정의는 앞에 커널 모듈의 소스코드에서 정의한 것과 일치해야 한다.#define COMENTO_IOCTL_CLEAR _IO(COMENTO_MAGIC, 0) int main(int argc, char *argv[]) { // open 함수를 사용하여 /dev/comento-device 디바이스 파일을 읽기/쓰기 모드(O_RDWR)로 염 // 파일 디스크립터는 fd 변수에 저장 // 파일 열기에 실패한 경우, 오류 메시지를 출력하고 프로그램을 종료 int fd = open(\"/dev/\" COMENTO_DEVICE_NAME, O_RDWR); if(fd &lt; 0) { printf(\"Failed to open device\\n\"); return -1; } // ioctl(fd, COMENTO_DEVICE_IOCTL_CLEAR, 0) 해당 호출을 통해 // 시스템 콜을 통해 커널 공간으로 전달되고, 커널은 등록된 디바이스 드라이버의 ioctl 처리 함수 // 'comento_device_ioctl' - case COMENTO_DEVICE_IOCTL_CLEAR 이 실행되게 된다. // 파일 디스크립터는 fd 변수에 저장되며, 파일 열기에 실패한 경우, // 오류 메시지를 출력하고 프로그램을 종료합니다. if(ioctl(fd, COMENTO_IOCTL_CLEAR, 0) &lt; 0) { printf(\"Failed to do ioctl command\\n\"); return -1; } return 0;}3. 구현 작업main.c 을 열어 위 소스 코드 추가user@DESKTOP:~/linux$ vim drivers/comento/main.c소스 코드 빌드user@DESKTOP:~/linux$ ARCH=arm64 CROSS_COMPILE=/home/gon/gcc-arm-10.3-2021.07-x86_64-aarch64-none-linux-gnu/bin/aarch64-none-linux-gnu- make CALL scripts/checksyscalls.sh CC [M] drivers/comento/main.o LD [M] drivers/comento/comento.o MODPOST Module.symvers LD [M] drivers/comento/comento.ko빌드된 커널 모듈을 이미지내 삽입user@DESKTOP:~/linux$ sudo mount -o loop ../buildroot/output/images/rootfs.ext4 /mntuser@DESKTOP:~/linux$ sudo cp drivers/comento/comento.ko /mnt/usr/lib/modules/.사용자 프로그램 생성 (위 작성 코드 내용 사용)user@DESKTOP:~/linux$ cd ..user@DESKTOP:~$ vim ioctl.ctoolchain 을 사용하여 사용자 프로그램 빌드user@DESKTOP:~$ gcc-arm-10.3-2021.07-x86_64-aarch64-none-linux-gnu/bin/aarch64-none-linux-gnu-gcc -o ioctl ioctl.c사용자 프로그램 이미지 내 추가user@DESKTOP:~$ sudo cp ioctl /mnt/usr/binuser@DESKTOP:~$ syncuser@DESKTOP:~$ sudo umount /mntQEMU 실행user@DESKTOP:~$ qemu-system-aarch64 -kernel linux/arch/arm64/boot/Image -drive format=raw,file=buildroot/output/images/rootfs.ext4,if=virtio -append \"root=/dev/vda console=ttyAMA0 nokaslr\" -nographic -M virt -cpu cortex-a72 -m 2G -smp 24. ioclt 사용모듈 삽입 및 드라이버 노드 파일 생성# insmod /usr/lib/modules/comento.ko# cd /dev/# mkmod /dev/comento c 177 34# ls -lah comentocrw-r--r-- 1 root root 177, 34 Mar 2 07:12 comentonode file buffer 문자열 넣기 및 확인# echo \"hello~~!!\" &gt; /dev/comento# cat /dev/comentohello~~!!사용자 프로그램(ioctl) 을 실행하여 buffer 초기화 (clear) 실행# ioctl# cat /dev/comento(출력 내용 없음)"
    } ,
  
    {
      "title"       : "Device Driver 개발 2 (파일 읽기/ 쓰기)",
      "category"    : "",
      "tags"        : "linux, device driver, device node, ssize_t()",
      "url"         : "./device_driver2.html",
      "date"        : "2024-03-01 10:32:20 +0900",
      "description" : "개발자를 위한 반도체 SW개발 기초 (디바이스 드라이버 개발) 관련 학습 12",
      "content"     : "에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지아래 내용은 개발자를 위한 시스템 반도체 SW개발 기초(디바이스 드라이버 개발) (https://comento.kr/) 강의 내용 중 일부에 해당함.1. 파일 읽기/ 쓰기 구현1.1 ssize_t type리눅스 드라이버에서 ssize_t 타입은 일반적으로 데이터의 크기나 양을 나타내는 데 사용되며, 부호 있는 64비트(시스템에 따라 다를 수 있음) 정수를 의미한다. ssize_t는 시스템 호출이나 함수들이 실패할 경우 음수 값을 반환할 수 있게 하며, 성공적인 경우에는 양의 값을 반환한다. 이는 주로 파일이나 소켓의 읽기 및 쓰기 연산에서 반환 타입으로 사용된다.리눅스 커널 모듈에서 파일 또는 장치 드라이버의 읽기 및 쓰기 연산을 구현할 때, read와 write 시스템 호출에 대응하는 함수 포인터를 file_operations 구조체에 설정하고 ssize_t 를 반환 타입으로 설정한다. ssize_t(*read)(file, buf, len, ppos) : 파일 읽기 함수 callback ssize_t(*write)(file, buf, len, ppos) : 파일 쓰기 함수 callback file (struct file *) : 읽기/쓰기 연산을 수행할 파일에 대한 포인터. struct file은 열린 파일의 상태를 나타내며, 파일의 현재 위치(offset) 같은 정보를 포함한다. 이 구조체를 통해 커널은 어떤 파일에 대한 작업을 수행하고 있는지 알 수 있다. buf (char __user *) : user space 의 버퍼 주소를 가리키는 포인터. 커널은 데이터를 읽어 user mode process 가 접근한 memory 에 전달할 때, __user 포인터가 가리키는 위치부터 버퍼 공간을 확보. len (size_t) : 버퍼의 크기. ‘__user’ 포인터 위치로부터 해당 크기만큼의 buffer 를 user space 에 확보하여 data 을 옮기 수 있게 한다. ppos (loff_t *) : 파일 내의 현재 위치(offset)를 나타내는 포인터. loff_t 타입은 대용량 파일 지원을 위해 사용되며, 파일의 어느 부분에서 데이터를 읽을지 결정한다. 함수 호출이 성공하면, 이 위치는 읽은 바이트 수만큼 증가한다. 따라서 파일로부터 원하는 부분에 대한 data 를 읽기 위해서 이에 대한 ppos 의 수정/갱신이 필요하다.데이터의 이동이 kernel space 와 user space 간 이루짐으로 일반적인 memcpy 는 사용할 수 없으며, copy_from_user / copy_to_user 를 사용하여 데이터 복사를 진행해야 한다.1.2 source 코드 작성 및 빌드기존에 작성한 Kernel Module 만들기 1 참조 main.c 파일을 읽기/쓰기 함수를 추가한다.user@DESKTOP:~/linux$ vim drivers/comento/main.c#include &lt;linux/device.h&gt;#include &lt;linux/fs.h&gt;#include &lt;linux/module.h&gt;#include &lt;linux/spinlock.h&gt;#define COMENTO_DEVICE_NAME \"comento-device\"#define COMENTO_MAJOR_NUMBER 177 #define COMENTO_BUF_SIZE 16static DEFINE_RWLOCK(comento_device_rwlock); // * rwlock 관련static char comento_device_buf[COMENTO_BUF_SIZE] = {0, }; // 이 버퍼는 커널 모듈의 일부로서, 커널 모듈이 로드될 때 커널의 메모리 영역에 할당되고, // 모듈이 언로드될 때 해제된다. // char __user *buf : __user attribute (생략 가능하지만 가독성/명확성을 위해 사용)static ssize_t comento_device_read(struct file *fp, char __user *buf, size_t len, loff_t *ppos) { ssize_t written_bytes = 0; read_lock(&amp;comento_device_rwlock); // * rwlock : read 용 lock 얻기 // 데이터를 읽거나 쓸 때, 요청된 작업이 디바이스 또는 버퍼의 실제 크기를 넘어서지 않도록 보장 // 현재는 *ppos 16 을 넘어가면 실제로 읽지 못하는 상태임 (?) if(COMENTO_BUF_SIZE &lt;= len + *ppos) { len = COMENTO_BUF_SIZE - *ppos; } // 실제로 복사된 bytes = 사용자가 요청한 복사 길이 bytes - 실패하거나 복사되지 않은 bytes 수를 반환 // copy_to_user(목적지 space, 출발지 pointer, 복사 요청 길이 ) : 출발지 pointer 의 경우 ppos(offset) 고려해야 written_bytes = len - copy_to_user(buf, comento_device_buf + *ppos, len); *ppos += written_bytes; // offset 값 갱신 read_unlock(&amp;comento_device_rwlock); // * rwlock : read 완료 후 unlock return written_bytes;}// const char __user *buf : 쓰기의 경우 kernel 에서 user space data 를 읽기만 한다. // kernel 이 해당 주소를 임의로 수정할 필요가 없으므로 const 로 고정시켜 안정성을 높인다.// const 로 미 선언시 error 또는 warning 발생static ssize_t comento_device_write(struct file *fp, const char __user *buf, size_t len, loff_t *ppos) { int read_bytes = 0; write_lock(&amp;comento_device_rwlock); // * rwlock : write 용 lock 얻기 if (COMENTO_BUF_SIZE &lt;= len + *ppos) { len = COMENTO_BUF_SIZE - *ppos; } // copy_from_user(목적지 space, 출발지 pointer, 복사 요청 길이 ) read_bytes = len - copy_from_user(comento_device_buf + *ppos, buf, len); *ppos += read_bytes; // offset 값 갱신 write_unlock(&amp;comento_device_rwlock); // * rwlock : write 완료 후 unlock return read_bytes;}static int comento_device_open(struct inode *inode, struct file *file) { int minor = iminor(inode); printk(KERN_DEBUG \"%s - minor : %d/n\", __func__, minor); return 0;}struct file_operations fops= { .open = comento_device_open, // .open 생략시 open 되었다고 가정하고 시스템에서 에러를 발생시키지 않음. .read = comento_device_read, .write = comento_device_write,};static int __init comento_module_init(void){ printk(KERN_DEBUG \"%s\\n\", __func__); int ret = register_chrdev(177, \"comento\", &amp;fops); return ret;}static void __exit comento_module_exit(void){ unregister_chrdev(177, \"comento\"); printk(KERN_DEBUG \"%s\\n\", __func__);}module_init(comento_module_init);module_exit(comento_module_exit);MODULE_AUTHOR(\"Hello&lt;hello@comento.com&gt;\");MODULE_DESCRIPTION(\"Example module\");MODULE_LICENSE(\"GPL v2\");2. 파일 빌드, 추가, QEMU 실행파일 빌드 및 ko 파일 생성user@DESKTOP:~/linux$ ARCH=arm64 CROSS_COMPILE=/home/gon/gcc-arm-10.3-2021.07-x86_64-aarch64-none-linux-gnu/bin/aarch64-none-linux-gnu- make CALL scripts/checksyscalls.sh CC [M] drivers/comento/main.o LD [M] drivers/comento/comento.o MODPOST Module.symvers LD [M] drivers/comento/comento.koko 파일 rootfs 이미지에 복사user@DESKTOP:~/linux$ sudo mount -o loop ../buildroot/output/images/rootfs.ext4 /mntuser@DESKTOP:~/linux$ sudo cp drivers/comento/comento.ko /mnt/usr/lib/modules/.user@DESKTOP:~/linux$ syncuser@DESKTOP:~/linux$ sudo umount /mntQEMU 실행user@DESKTOP:~/linux$ cd ..user@DESKTOP:~$ qemu-system-aarch64 -kernel linux/arch/arm64/boot/Image -drive format=raw,file=buildroot/output/images/rootfs.ext4,if=virtio -append \"root=/dev/vda console=ttyAMA0 nokaslr\" -nographic -M virt -cpu cortex-a72 -m 2G -smp 23. 파일 읽기, 쓰기 사용드라이버 모듈 삽입 및 확인# insmod /usr/lib/modules/comento.ko# dmesg...comento_module_init# cd /dev# ls -lah comentocrw-r--r-- 1 root root 177, 34 Mar 1 05:50 comentodev 디렉토리 내 디바이스 노드 생성# mknod /dev/comento c 177 34값 넣어보기# echo \"wow\" &gt; /dev/comento# cat /dev/comentowow추가된 comento 디바이스 노드에 “wow” 문자열을 redirection 하고, 해당 디바이스 노드 내용을 출력하면 redirect 된 값이 그대로 출력됨을 확인할 수 있다.이는 앞에서 구현한 소스코드 중 comento_device_write 함수가 실행되어, user space 에서 작성한 문자열이 copy_from_user 를 사용하여 kernel space memory (comento_device_buf)에 쓰기가 되었음을 의미한다.cat 명령을 사용하면, 해당 디바이스 노드의 버퍼 공간 내용을 읽어 온다. 즉 앞에서 구현한 comento_device_read 함수를 실행하여 copy_to_user 로 comento_device_buf 에 저장된 문자열을 표준 출력으로 제공하게 되는 것이다.4. strace 를 사용한 읽기 과정 관찰strace 를 사용하기 위해 커널을 빠져 나온 이후, 임의 파일을 생성하고 이를 strace 를 사용하여 그 과정을 좀더 로그로 출력했을때, 그 일부 내용은 아래와 같다.user@DESKTOP:~$ touch emptyuser@DESKTOP:~$ strace cat empty...openat(AT_FDCWD, \"empty\", O_RDONLY) = 3newfstatat(3, \"\", {st_mode=S_IFREG|0644, st_size=0, ...}, AT_EMPTY_PATH) = 0fadvise64(3, 0, 0, POSIX_FADV_SEQUENTIAL) = 0mmap(NULL, 139264, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7f854e8ec000read(3, \"\", 131072) = 0munmap(0x7f854e8ec000, 139264) = 0close(3) = 0close(1) = 0close(2) = 0exit_group(0) = ?+++ exited with 0 +++openat(AT_FDCWD, “empty”, O_RDONLY) = 3 openat: 파일이나 디렉토리를 열기 위한 시스템 호출. AT_FDCWD: 현재 작업 디렉토리 (at file descriptor current working directory) “empty”: 열고자 하는 파일의 이름 O_RDONLY: 읽기 전용 모드로 열라는 옵션 3: openat 시스템 호출의 반환 값. 리눅스와 유닉스 시스템에서 파일은 파일 디스크립터를 통해 관리되며, 이 값은 성공적으로 파일을 열었을 때 시스템이 할당한 파일 디스크립터를 나타낸다. 여기서 3은 열린 파일을 나타내는 파일 디스크립터 번호이다. 일반적으로 0, 1, 2는 각각 표준 입력, 표준 출력, 표준 에러를 위해 예약되어 있으므로, 사용자가 열 수 있는 첫 번째 파일 디스크립터는 3부터 시작한다.read(3, “”, 131072) = 0 앞에서 구현한 파일 읽기와 동일한 callback 이 발생함을 확인할 수 있다. 파일 디스크립터 3 에 대해 값 “” 을 131072 buffer size 를 가지고 read 함수가 callback 된다."
    } ,
  
    {
      "title"       : "Device Driver 개발 1",
      "category"    : "",
      "tags"        : "linux, device driver, device node",
      "url"         : "./device_driver1.html",
      "date"        : "2024-02-29 10:32:20 +0900",
      "description" : "개발자를 위한 반도체 SW개발 기초 (디바이스 드라이버 개발) 관련 학습 11",
      "content"     : "에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지아래 내용은 개발자를 위한 시스템 반도체 SW개발 기초(디바이스 드라이버 개발) (https://comento.kr/) 강의 내용 중 일부에 해당함.1. 디바이스 드라이버 종류디바이스 드라이버는 플랫폼 별 (윈도우 드라이버, 리눅스 드라이버, 맥 OS 드라이버) 등 또는 OS 수준 별(커널 모드 드라이버, 사용자 모드 드라이버) 로 구분되기도 하며, 아래와 같이 하드웨어의 유형과 기능에 따라 장치별 드라이버로 구분되기도 한다. 블록 장치 드라이버데이터를 블록이라는 고정된 크기의 단위로 저장하고 검색하는 저장 장치를 관리. 이러한 장치에는 하드 디스크 드라이브(HDD), 솔리드 스테이트 드라이브(SSD), USB 플래시 드라이브 등이 포함되며. 블록 장치 드라이버는 파일 시스템을 지원하여, 사용자와 시스템이 데이터를 효율적으로 저장하고 액세스할 수 있게 한다. (ex. 블록 장치 드라이버는 운영 체제가 디스크의 특정 블록을 읽거나 쓸 수 있도록 하며, 디스크 상의 데이터의 물리적 위치를 추상화.) 문자 장치 드라이버데이터를 문자 단위로 처리하는 장치, 즉 한 번에 하나의 문자(또는 바이트)를 전송하는 장치를 관리한다. 이에는 키보드, 마우스, 시리얼 포트, 프린터 등이 포함된다. 문자 장치 드라이버는 사용자 입력을 처리하거나 문자 기반의 데이터를 장치로 전송하는 역할을 한다. (ex. 키보드 드라이버는 사용자가 누른 키의 신호를 받아 운영 체제가 이해할 수 있는 입력 데이터로 변환.) 네트워크 드라이버네트워크 인터페이스 카드(NIC)나 기타 네트워킹 하드웨어 장치를 관리한다. 이 드라이버는 데이터 패킷을 네트워크를 통해 송수신하는 데 필요한 기능을 제공한다. 네트워크 드라이버는 네트워크 프로토콜(예: TCP/IP)과 상호 작용하여 데이터를 올바르게 포맷하고, 주소를 지정하며, 에러 검사를 수행한다. 네트워크 드라이버는 데이터의 안정적인 전송을 보장하기 위해 중요한 역할을 한다. 버스 디바이스 드라이버컴퓨터 내의 다양한 하드웨어 장치를 연결하는 통신 경로인 버스를 관리한다. 대표적인 예로는 PCI(Peripheral Component Interconnect), USB(Universal Serial Bus), SATA(Serial ATA) 등이 있습니다. 버스 드라이버는 하드웨어 장치 간의 데이터 전송을 조정하고, 장치 간의 호환성을 보장한다. (ex. USB 버스 드라이버는 USB 장치가 컴퓨터에 연결될 때 필요한 전력 관리, 데이터 전송 속도 조정, 연결된 장치의 식별 및 구성을 담당.) 2. 디바이스 노드디바이스 노드(Device Node)는 유닉스 및 유닉스 계열 운영 체제에서 하드웨어 장치를 파일 시스템 내의 파일로 표현하는 방법. 유닉스 계열 시스템은 ‘모든 것은 파일’이라는 철학을 따르는데, 이는 하드웨어 장치를 포함한 모든 자원을 파일처럼 취급한다는 의미이다. 디바이스 노드를 통해, 사용자와 응용 프로그램은 표준 파일 입출력(IO) 시스템 호출을 사용하여 하드웨어 장치와 통신할 수 있다.디바이스 노드의 종류 (타입) 문자 디바이스(Character Device) : c 블록 디바이스(Block Device) : b (네트워크 드라이버와 버스 디바이스 드라이버는 노출되지 않고 별도로 관리됨.) 디바이스 노드의 특징 및 사용 방법 mknod &lt;파일이름&gt; &lt;타입&gt; &lt;주번호&gt; &lt;부번호&gt; : 디바이스 노드 파일 생성 파일 시스템 내 위치 디바이스 노드는 주로 /dev 디렉토리에 위치한다. 예를 들어, /dev/sda는 첫 번째 SATA 하드 드라이브를, /dev/tty는 현재 터미널을 나타낸다. 특수 파일 디바이스 노드는 특수 파일로 분류된다. 일반 파일과 달리, 실제 데이터를 디스크에 저장하는 대신, 커널의 하드웨어 장치 드라이버와 통신하는 인터페이스 역할을 한다. MAJOR/MINOR 번호 각 디바이스 노드는 MAJOR 번호와 MINOR 번호를 가진다. MAJOR 번호(0 ~ 511)는 장치 유형(예: 하드 디스크, 시리얼 포트)을 식별한다. 디바이스 드라이버마다 고유하며 커널이 자동으로 할당하기도 한다. MINOR 번호(0 ~ 1048576)는 해당 유형 내의 개별 장치를 구분한다. 즉 디바이스마다 고유하며 디바이스 드라이버가 할당을 관리한다. ex. USB 마우스를 여러개 꽂았을 경우 - 디바이스(minor 번호)는 여러개, 디바이스 드라이버(major 번호) 는 하나 사용자와 그룹 권한 디바이스 노드는 파일과 마찬가지로 사용자와 그룹 권한을 가진다. 이를 통해 특정 사용자 또는 그룹만이 장치에 접근하거나 사용할 수 있는 권한을 제어할 수 있다. 3. 문자 디바이스 드라이버 등록 실습3.1 문자 디바이스 드러이버 구현 시스템콜 파일 생성(이전 post 에서 구현한 linux/drivers/coment/main.c 파일을 사용하여 진행)user@DESKTOP:~/linux/drivers/comento$ vim main.c#include &lt;linux/module.h&gt;// (1)static int comento_device_open(struct inode *inode, struct file *file) { int minor = iminor(inode); printk(KERN_DEBUG \"%s - minor : %d/n\", __func__, minor); return 0;} // (2)struct file_operations fops= { .open = comento_device_open,};static int __init comento_module_init(void) { printk(KERN_DEBUG \"%s\\n\", __func__); int ret = register_chrdev(177, \"comento\", &amp;fops); // (3) return ret;}static void __exit comento_module_exit(void) { unregister_chrdev(177, \"comento\"); printk(KERN_DEBUG \"%s\\n\", __func__);}module_init(comento_module_init);module_exit(comento_module_exit);MODULE_AUTHOR(\"Hello&lt;hello@comento.com&gt;\");MODULE_DESCRIPTION(\"Example module\");MODULE_LICENSE(\"GPL v2\");(1) static int comento_device_open(struct inode *inode, struct file *file) {} 리눅스 커널 내에서 디바이스 파일을 열려고 할 때 호출되는 함수. 이 함수는 file_operations 구조체 내에서 .open 포인터에 의해 참조되며, 사용자 공간에서 디바이스 파일(예: /dev/comento)에 대한 open 시스템 콜이 발생할 때 실행된다.해당 함수는 디바이스 파일이 열릴 때 필요한 초기화나 상태 확인 등의 작업을 수행하기 위애 정의 된다. struct file_operations 의 주요 필드 callback 함수에 대한 정의를 살펴보면 struct file_operations { struct module *owner; loff_t (*llseek) (struct file *, loff_t, int); ssize_t (*read) (struct file *, char __user *, size_t, loff_t *); ssize_t (*write) (struct file *, const char __user *, size_t, loff_t *); int (*open) (struct inode *, struct file *); int (*release) (struct inode *, struct file *); // 다른 필드들... };이와 같이 open 필드의 경우, inode 포인터와 file 포인터를 인자로 취하는 함수이여야 한다. inode inode는 유닉스 및 유닉스 계열 시스템에서 파일 시스템의 파일이나 디렉터리에 대한 메타데이터를 저장하는 데이터 구조 (구조체 타입) 각 파일이나 디렉터리는 고유한 inode를 가지며, 이 inode에는 파일의 소유자, 파일 모드(권한), 파일 크기, 파일이 저장된 디스크 상의 위치, 생성 및 수정 날짜 등의 정보가 포함된다. 디바이스 드라이버의 컨텍스트에서 inode 구조체는 디바이스 파일의 메타데이터에 접근하는 데 사용된다. 특히, 디바이스 파일을 나타내는 inode에서 Major 번호와 Minor 번호를 추출하여, 해당 디바이스 파일이 어떤 디바이스를 참조하는지 식별할 수 있다.(2) file_operations 리눅스 커널 내에서 파일 작업을 위한 callback 함수를 정의하는데 사용되느 구조체. 커널 모듈이나 디바이스 드라이버가 파일 시스템의 파일이나 디바이스 파일에 대한 다양한 작업(예: 열기, 읽기, 쓰기 등)을 수행할 수 있도록 하는 인터페이스를 제공한다. 각 필드는 특정 파일 작업을 위한 함수 포인터를 가리키며, 해당 작업이 호출될 때 실행될 함수를 지정한다. .open : 파일이나 디바이스를 열 때 호출됨 .read : 파일이나 디바이스에서 데이터를 읽을 때 호출됨 .write : 파일이나 디바이스에 데이터를 쓸 때 호출됨 .release: 파일이나 디바이스가 닫힐 때 호출됨 (종종 close 작업으로 참조됨). .llseek : 파일 내에서 읽기/쓰기 위치를 변경할 때 호출됨 .ioctl : 장치에 특정 명령을 보낼 때 사용됨 (장치 제어).(3) register_chrdev(major, name, fops) 새로운 문자 디바이스 드라이버 등록에 사용되는 API major : 주번호로 사용할 번호를 지정, (0으로 지정시 커널이 자동 할당) name : 디바이스의 이름 fops : 디바이스 드라이버가 구현할 file_operations 등록이 성공했다면 0 또는 할당받은 major 번호를 반환, 실패시 음수 반환이제 아래와 같이 수정한 소스 파일을 빌드하여 ko dynamic linker 파일 생성한다.user@DESKTOP:~/linux$ ARCH=arm64 CROSS_COMPILE=/home/gon/gcc-arm-10.3-2021.07-x86_64-aarch64-none-linux-gnu/bin/aarch64-none-linux-gnu- make CALL scripts/checksyscalls.sh CC [M] drivers/comento/main.o LD [M] drivers/comento/comento.o MODPOST Module.symvers LD [M] drivers/comento/comento.korootfs 에 마운트 해당 파일을 마우트 이미지에 삽입user@DESKTOP:~/linux/$ sudo mount -o loop ../buildroot/output/images/rootfs.ext4 /mntuser@DESKTOP:~/linux/$ sudo cp drivers/comento/comento.ko /mnt/usr/lib/modules/.user@DESKTOP:~/linux/$ syncuser@DESKTOP:~/linux/$ sudo umount /mntQEMU 로 커널 실행user@DESKTOP:~/linux/$ cd ..user@DESKTOP:~$ qemu-system-aarch64 -kernel linux/arch/arm64/boot/Image -drive format=raw,file=buildroot/output/images/rootfs.ext4,if=virtio -append \"root=/dev/vda console=ttyAMA0 nokaslr\" -nographic -M virt -cpu cortex-a72 -m 2G -smp 23.2 디바이스 노드 만들기mknod 명령어로 디바이스 노드를 생성한다. 순서대로 c (문자 디바이스), 177 (기존에 지정한 major 번호) 32 (임의의 minor 번호) 를 입력한다.# cd /dev/# mknod /dev/comento c 177 43# cat /dev/comentocat: can't open '/dev/comento': No such device or address명령어 수행 결과를 확인했을 때, 아직 디바이스 드라이버가 로드되지 않아 찾지 못한다고 나온다. 따라서 아래와 같이 해당 디바이스 드라이버를 등록 시키고 다시 확인해보면,3.3 모듈 로드# insmod /usr/lib/modules/comento.ko# cat /dev/comentocat: read error: Invalid argument해당 결과와 같이, 드라이버 노드는 찾은 것 같다. 다만 read 대한 구현이 없기 때문에 해당 에러가 발생하였다.# dmesg...comento_module_init# ls -lah comentocrw-r--r-- 1 root root 177, 43 Feb 29 07:20 comentodmesg 로 init 되었음이 확인 되었으며, (그런데 comento_device_open 함수 실행 메세지는 안나왔네 ;;) ls 명령어를 통해 comento 파일이 생성 및 major, minor 번호가 정상적으로 부여되었음을 볼 수 있다.위 과정에서 모듈로드가 정상적으로 되어야 드라이버 노드가 정상적으로 작동함을 보여주기 위해 mknod 로 디바이스 노드를 생성한 이후 모듈을 로드 했지만, 논리적으로 절차를 생각하면, 우선 디바이스 노드의 binary 값을 매모리에 로드하는 것이 우선으로 시행되는 것이 맞다. 해당 insmod 명령어 수행시 어떤 작업이 수행되는지 정리하면 아래와 같다. 메모리 로드insmod 명령어는 디스크 상의 커널 모듈(.ko 파일)을 찾아 메모리로 로드. 이 파일에는 디바이스 드라이버의 실행 가능한 코드가 포함되어 있다. 초기화 및 등록드라이버 모듈이 메모리로 로드되면, 그 안에 정의된 초기화 함수가 실행된다. 이 초기화 과정에서 드라이버는 자신이 관리할 하드웨어 디바이스를 설정하고, 커널에 필요한 정보(예: 드라이버가 지원하는 연산, 메이저 번호 등)를 등록한다. 이로써 시스템은 해당 드라이버가 존재하고 사용 가능함을 알게 된다. 시스템과의 통합드라이버가 성공적으로 로드되고 초기화되면, 시스템의 다른 부분들은 해당 드라이버를 통해 연결된 하드웨어 디바이스와 통신할 수 있다. 예를 들어, 사용자 공간의 애플리케이션은 표준 파일 입출력 연산을 사용하여 디바이스 파일(/dev에 위치)을 통해 드라이버와 데이터를 주고받을 수 있다. 이후 mknod 명령어 요청시 로드된 모듈을 가지고 어떤 작업들이 진행되는 정리하면 아래와 같다. 파일 유형 및 메이저/마이너 번호 지정사용자는 mknod 명령어를 실행할 때 파일의 경로, 유형(문자 디바이스 또는 블록 디바이스), 메이저 번호, 그리고 마이너 번호를 지정. 이 정보는 생성될 디바이스 파일의 특성을 결정한다.(예: mknod /dev/example c 240 0은 /dev 디렉토리에 example이라는 이름의 문자 디바이스 파일을 생성하며, 이 파일은 메이저 번호 240과 마이너 번호 0을 가진다.) 디바이스 파일 생성지정된 정보를 바탕으로 파일 시스템에 디바이스 파일을 생성. 이 파일은 실제 데이터를 저장하지 않고, 대신 특정 디바이스 드라이버와의 통신 경로 역할을 한다. 생성된 파일의 유형(문자 또는 블록), 메이저 번호, 마이너 번호는 커널이 디바이스 드라이버를 어떻게 찾아야 하는지를 결정하는 데 사용된다. 파일 시스템에 메타데이터 등록생성된 디바이스 파일에 대한 메타데이터가 파일 시스템에 등록. 이 메타데이터에는 파일의 유형, 권한, 소유자, 그룹, 메이저/마이너 번호 등이 포함될 수 있다. 이 정보는 파일 시스템을 통해 파일에 접근하려는 프로세스에 의해 참조된다. 시스템과의 통합디바이스 파일이 성공적으로 생성되면, 시스템의 다른 부분(예: 사용자 공간의 프로그램)은 이 파일을 통해 커널의 디바이스 드라이버와 통신할 수 있다. 파일에 대한 입출력 연산은 커널에 의해 해당 디바이스 드라이버의 적절한 함수로 라우팅된다."
    } ,
  
    {
      "title"       : "Kernel Module 만들기",
      "category"    : "",
      "tags"        : "linux, kernel module",
      "url"         : "./kernelmodule01.html",
      "date"        : "2024-02-28 10:32:20 +0900",
      "description" : "개발자를 위한 반도체 SW개발 기초 (디바이스 드라이버 개발) 관련 학습 10",
      "content"     : "에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지아래 내용은 개발자를 위한 시스템 반도체 SW개발 기초(디바이스 드라이버 개발) (https://comento.kr/) 강의 내용 중 일부에 해당함.1. 관련 설정 추가 및 source code 생성1.1 드라이버 디렉토리 생성 및 Makefile 에 해당 디렉토리 추가user@DESKTOP:~$ cd linux/driversuser@DESKTOP:~/linux/drivers$ mkdir comentouser@DESKTOP:~/linux/drivers$ vim Makefile...obj-$(CONFIG_DRM_ACCEL) += accel/obj-$(CONFIG_CDX_BUS) += cdx/obj-$(CONFIG_DPLL) += dpll/obj-$(CONFIG_S390) += s390/# 추가 내용oeeebj-y += comento/ 1.2 drivers Kconfig 에도 추가될 디렉토리 Kconfig 항목 추가user@DESKTOP:~/linux/drivers$ vim Kconfig...source \"drivers/cdx/Kconfig\"source \"drivers/dpll/Kconfig\"source \"drivers/comento/Kconfig\" # 추가 내용endmenu1.3 해당 디렉토리에 Kconfig 파일 추가user@DESKTOP:~/linux/drivers$ cd comentouser@DESKTOP:~/linux/drivers/comento$ vim Kconfig menu \"Comento Example Driver\"config COMENTO_EXAMPLE tristate \"Comento Example Dirver Module\" help This is an exampleendmenu config COMENTO_EXAMPLE : .config 파일에서는 CONFIG prefix 를 붙여 CONFIG_COMENTO_EXAMPLE 로 사용됨.1.4 해당 디렉토리 내 main.c 로 목적파일이 만들어 질 수 있도록 Makefile 추가user@DESKTOP:~/linux/drivers/comento$ vim Makefileobj-$(CONFIG_COMENTO_EXAMPLE) += comento.ocomento-objs += main.o1.5 linux kernel module 내용을 담은 소스 코드 main.c 작성user@DESKTOP:~/linux/drivers/comento$ vim main.c#include &lt;linux/module.h&gt;static int __init comento_module_init(void) { printk(KERN_DEBUG \"%s\\n\", __func__); return 0;}static void __exit comento_module_exit(void) { printk(KERN_DEBUG \"%s\\n\", __func__);}module_init(comento_module_init);module_exit(comento_module_exit);MODULE_AUTHOR(\"Hello&lt;hello@comento.com&gt;\");MODULE_DESCRIPTION(\"Example module\");MODULE_LICENSE(\"GPL v2\");모듈 초기화 및 종료 함수 __init 함수 (comento_module_init): 모듈이 커널에 로드될 때 자동으로 실행됨. __init 매크로는 이 함수가 초기화 코드에만 사용되며, 초기화 후에는 메모리에서 해제될 수 있음을 커널에 알린다. 이 예에서, printk 함수를 사용하여 커널 로그에 메시지 (__func__ 매크로는 현재 함수 이름의 문자열을 반환) 를 출력한다. __init 은 init 관련 함수임을 표시한 attribute 이다. __exit 함수 (comento_module_exit): 모듈이 커널에서 제거될 때 실행됨. __exit 매크로는 이 함수가 종료 코드에만 사용되며, 모듈이 커널에 계속 로드되어 있는 경우 메모리를 절약하기 위해 해제될 수 있음을 나타낸다. module_init 매크로 목적: 커널 모듈이 시스템에 로드될 때 실행될 초기화 함수를 지정 동작: 지정된 초기화 함수는 모듈이 커널에 삽입될 때(insmod 명령어 사용 시) 자동으로 호출된다. 이 함수 내에서는 모듈이 제대로 작동하기 위해 필요한 리소스 할당, 상태 초기화, 디바이스 등록 등의 작업을 수행한다. module_exit 매크로 목적: 커널 모듈이 시스템에서 제거될 때 실행될 종료 함수를 지정 동작: 지정된 종료 함수는 모듈이 커널에서 제거될 때(rmmod 명령어 사용 시) 자동으로 호출된다. 이 함수 내에서는 모듈의 정상적인 종료를 위해 할당된 리소스의 해제, 등록된 디바이스의 등록 해제 등의 작업을 수행한다. MODULE_AUTHOR: 모듈의 작성자. MODULE_DESCRIPTION: 모듈에 대한 간단한 설명. MODULE_LICENSE: 모듈의 라이선스 유형. “GPL v2”는, 모듈이 GNU General Public License 버전 2에 따라 배포됨을 나타낸다. 이는 모듈이 GPL 호환 코드와 함께 사용되어야 함을 의미한다.1.6 menuconfig 실행하여 항목 추가되었음을 확인하고 설정 반영user@DESKTOP:~/linux/drivers/comento$ cd ..user@DESKTOP:~/linux/drivers$ cd ..user@DESKTOP:~/linux$ ARCH=arm64 make menuconfigDevice Driver 항목 맨 아래 다음과 같이 추가되었음을 확인할 수 있다.2. kernel build2.1 kernel builduser@DESKTOP:~/linux$ ARCH=arm64 CROSS_COMPILE=/home/gon/gcc-arm-10.3-2021.07-x86_64-aarch64-none-linux-gnu/bin/aarch64-none-linux-gnu- make CALL scripts/checksyscalls.sh CC [M] drivers/comento/main.o LD [M] drivers/comento/comento.o ... CC [M] drivers/comento/comento.mod.o LD [M] drivers/comento/comento.ko ...해당 kernel 을 build 하면 위와 같이 사용자가 작성한 drivers/comento/main.o 가 gcc 에 의해 빌드되고, 해당 linker script 가 comento-objs += main.o 에 명시된 대로 main.o 를 모아서 obj-$(CONFIG_COMENTO_EXAMPLE) += comento.o 대로 drivers/comento/comento.o 을 생성한다.그리고 commento.o 가 모듈관련 목적 파일 drivers/comento/comento.mod.o 과 함께 link 되서 linker 가 drivers/comento/comento.ko 를 만든다.3. buildroot 이미지에 해당 ko 파일 추가 및 QEMU 에서 모듈 로드가 정상적으로 되었는지 확인3.1 buildroot 이미지에 해당 ko 파일 추가user@DESKTOP:~/linux$ sudo mount -o loop ../buildroot/output/images/rootfs.ext4 /mntuser@DESKTOP:~/linux$ sudo mkdir /mnt/usr/lib/modulesuser@DESKTOP:~/linux$ sudo cp drivers/comento/comento.ko /mnt/usr/lib/modulesuser@DESKTOP:~/linux$ syncuser@DESKTOP:~/linux$ sudo umount /mnt3.2 QEMU 실행user@DESKTOP:~/linux$ cd ..user@DESKTOP:~$ qemu-system-aarch64 -kernel linux/arch/arm64/boot/Image -drive format=raw,file=buildroot/output/images/rootfs.ext4,if=virtio -append \"root=/dev/vda console=ttyAMA0 nokaslr\" -nographic -M virt -cpu cortex-a72 -m 2G -smp 23.3 모듈 추가 확인# ls /usr/lib/modulescomento.ko해당 커널에서 삽입한 경로에 보면 comento.ko 이 정상적으로 추가되어 있음을 볼 수 있다.4. moudule load / unload4.1 load# insmod /usr/lib/moduels/comento.ko# dmesg -ccomento_module_initinsmod 하여 모듈을 삽입하고 dmesg 를 하면, main.c 에 작성 했던 comento_module_init() 에서 작성한 대로 함수명 (comento_module_init) 을 출력하게 된다. 아래와 같이 lsmod 명령어로 현재 로드된 모듈들을 볼 수도 있다.# lsmodModule Size Used bycomento 12288 04.2 unload# rmmod comento.ko# dmesg -ccomento_module_exitrmmod 를 통해 지정된 모듈을 제거 한다. 제거하면서 “comento_module_exit” 메세지가 출력되었음을 볼 수 있다.# lsmodModule Size Used bylsmod 로 보면 이제 로드된 모듈이 없음을 확인할 수 있다."
    } ,
  
    {
      "title"       : "GDB 를 사용 기초 및 systemcall GDB 적용",
      "category"    : "",
      "tags"        : "linux, systemcall, gdb-multiarch",
      "url"         : "./gdp01.html",
      "date"        : "2024-02-25 10:32:20 +0900",
      "description" : "개발자를 위한 반도체 SW개발 기초 (디바이스 드라이버 개발) 관련 학습 09",
      "content"     : "에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지아래 내용은 개발자를 위한 시스템 반도체 SW개발 기초(디바이스 드라이버 개발) (https://comento.kr/) 강의 내용 중 일부에 해당함.GDB 기초 GDB 사용을 위한 라이브러리 설치user@DESKTOP:~$ sudo apt-get install gdb-multiarch GDB 로 관찰할 systemcall 작성user@DESKTOP:~$ vi fact.c test 용 code#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;int factorial(int n) { int ret = 1; if (n &gt; 1) { ret *= n; ret *= factorial(n - 1); } return ret;}int main(int argc, char *argv[]) { int i = atoi(argv[1]); int result = factorial(i); printf(\"result: %d\\n\", result); return 0;} gcc builduser@DESKTOP:~$ gcc -g fact.c -o fact # -g : 컴파일된 실행 파일에 디버깅 정보를 포함# GDB를 사용할 때 소스 코드의 라인 번호, 변수 이름 등의 상세한 정보에 접근 가능 GDB 실행user@DESKTOP:~$ gdb-multiarch factGNU gdb (Ubuntu 12.1-0ubuntu1~22.04) 12.1Copyright (C) 2022 Free Software Foundation, Inc.License GPLv3+: GNU GPL version 3 or later &lt;http://gnu.org/licenses/gpl.html&gt;This is free software: you are free to change and redistribute it.There is NO WARRANTY, to the extent permitted by law.Type \"show copying\" and \"show warranty\" for details.This GDB was configured as \"x86_64-linux-gnu\".Type \"show configuration\" for configuration details.For bug reporting instructions, please see:&lt;https://www.gnu.org/software/gdb/bugs/&gt;.Find the GDB manual and other documentation resources online at: &lt;http://www.gnu.org/software/gdb/documentation/&gt;.For help, type \"help\".Type \"apropos word\" to search for commands related to \"word\"...Reading symbols from fact...(gdb)(gdb) start 10 # --- (1)Temporary breakpoint 1 at 0x11bd: file fact.c, line 14. # --- (2)Starting program: /home/gon/fact 10 [Thread debugging using libthread_db enabled] --- (3)Using host libthread_db library \"/lib/x86_64-linux-gnu/libthread_db.so.1\". # --- (4)Temporary breakpoint 1, main (argc=2, argv=0x7fffffffe108) at fact.c:1414 int i = atoi(argv[1]);(1) start 명령은 프로그램을 시작하고, 주어진 프로그램의 첫번째 인자(10)와 함께 메인 함수의 첫 번째 라인에서 일시적인 중단점을 설정. 이렇게 하면 프로그램이 실제로 실행되기 시작하며, 사용자가 프로그램의 초기 상태를 검사할 수 있게 된다.(2) 현재 중단점 code 상 line 의 위치와 메모리 주소. 즉 main 함수 내 첫번째 줄.(3) 멀티스레딩 프로그램을 디버깅하기 위해 libthread_db 라이브러리를 사용하고 있음을 표시(4) 호스트 시스템의 libthread_db 라이브러리를 사용하고 있음을 표시. 이 라이브러리는 스레드와 관련된 정보를 제공하여 디버거가 스레드를 효율적으로 관리할 수 있게 돕는다.QEME GDB 적용 Debug mode 로 빌드되도록 Linux kernel 설정 변경user@DESKTOP:~$ cd linuxuser@DESKTOP:~/linux$ ARCH=arm64 make menuconfig kernel hacking -&gt; Kernel debugging 선택 kernel hacking -&gt; Compile-time checks and compiler options -&gt; Debug information (Disable debug information) -&gt; Rely on the toolchain’s implicit default DWARF version 선택 re-builduser@DESKTOP:~/linux$ make -j&lt;cpu 수&gt; QEMU 실행user@DESKTOP:~/linux$ cd ..user@DESKTOP:~$ qemu-system-aarch64 -kernel linux/arch/arm64/boot/Image -drive format=raw,file=buildroot/output/images/rootfs.ext4,if=virtio -append \"root=/dev/vda console=ttyAMA0 nokaslr\" -nographic -M virt -cpu cortex-a72 -m 2G -smp 2 -s -S-s : gdb 가 붙을 수 있도록 1234 포트를 열어둠-S : QEMU 가 시작하자마자 멈춰있는 상태로 만듬. (break-point 를 걸수 있는 시점을 마련하기 위함)(실행시 -S 옵션으로 인해 멈춰있게 됨. 그래서 다른 cli 상에서 gdb-multiarch를 사용하여 linux/vmlinux 경로에 위치한 리눅스 커널 이미지를 디버깅 모드로 염)user@DESKTOP:~$ gdb-multiarch linux/vmlinuxFor help, type \"help\".Type \"apropos word\" to search for commands related to \"word\"...Reading symbols from kernel/vmlinux...(gdb)따라서 vmlinux 내 debugging 정보가 읽어지게 됨. 기존 buildroot 이미지에는 모든 정보가 담겨있는것이 아니라 kernel 을 실행할 수 있는 코드만 포함된 단순화된 파일이다. 따라서 해당 이미지 만으로 모든 디버깅 정보를 볼 수는 없는 환경이다. 그런데 vmlinux 파일의 경우, 커널의 디버깅 정보, 함수 및 변수 이름 정보, 코드 라인 정보 등이 모두 담긴 목적 파일이므로 gdb-multiarch linux/vmlinux 와 같이 해당 파일을 디버거 인자로 넘겨 주어야 한다.그리고 gdb prompt 창에 target remote :1234 를 입력하여 qemu 에서 열어둔 디버깅 포트 1234 에 접속한다. 연결된 이후, 원하는 break-point 를 걸 수 있다. 예를 들면,(gdb) break start_kernel 로 입력하면 리눅스 커널에서 제일 먼저 실행되는 c 함수에 중단점을 생성하고,(gdb)__do_sys_&lt;시스템콜 함수 이름&gt; 의 겅우 앞서 실습한 systemcall 을 디버깅 가능하다. 여기에서 __do_sys_ 접두사는 SYSCALL_DEFINE 매크로가 자동 생성한 것이다. QEMU 가 연 포트에 접근(gdb) set architecture aarch64(gdb) target remote :1234Remote debugging using :1234warning: Selected architecture i386:x86-64 is not compatible with reported target architecture aarch64warning: Architecture rejected target-supplied description0x0000000000000000 in fixed_percpu_data () # bootloader 의 첫 시작 주소 break-point 걸기start_kernel 이라는 가장 처음에 시작되는 함수에 break-point 걸기(gdb) break start_kernelBreakpoint 1 at 0xffffffff821889e0: file init/main.c, line 875.우리가 추가한 systemcall 함수 break-point 걸기(gdb) break __do_sys_new_syscallBreakpoint 2 at 0xffffffff811391c9: file kernel/new_syscall.c, line 6."
    } ,
  
    {
      "title"       : "systemcall 기초 1",
      "category"    : "",
      "tags"        : "linux, systemcall",
      "url"         : "./systemcall01.html",
      "date"        : "2024-02-24 10:32:20 +0900",
      "description" : "개발자를 위한 반도체 SW개발 기초 (디바이스 드라이버 개발) 관련 학습 08",
      "content"     : "에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지 에러방지아래 내용은 개발자를 위한 시스템 반도체 SW개발 기초(디바이스 드라이버 개발) (https://comento.kr/) 강의 내용 중 일부에 해당함.1. SYSCALL_DEFINE 매크로1.1 생성할 systemcall 이 추가될 linux 디렉토리 내 해당 source 추가user@DESKTOP:~$ cd linux/kerneluser@DESKTOP:~/linux/kernel$ vim new_syscall.c#include &lt;linux/kernel.h&gt; // kenel 에서 사용할 soruce code 에 필요한 라이브러리#include &lt;linux/syscalls.h&gt; // SYSCALL_DEFINE 매크로를 사용하기 위한 라이브러리SYSCALL_DEFINE1(new_syscall, int, code) // SYSCALL_DEFINE 매크로 + 1개 인자 (system call 이름, (첫번째)인자 타입, (첫번째)인자 이름){ printk(KERN_INFO \"Hello World~!!!! %d\\n\", code); // syscall 호출 확인을 위해 log 출력 \\n 로 종료해야 시스템이 해당 로그 message 가 종료 되었음을 인지함. (없으면 종료 상태가 결정되지 않아 원하는 시점에 출력 되지 않을 수 있음.) return code + 1; }1.2 Makefile 수정user@DESKTOP:~/linux/kernel$ vi Makefile해당 파일에 다음과 같이 반드시 실행되는 목적 파일들이 obj-y 로 나열되어 있다.obj-y = fork.o exec_domain.o panic.o \\ cpu.o exit.o softirq.o resource.o \\ sysctl.o capability.o ptrace.o user.o \\ signal.o sys.o umh.o workqueue.o pid.o task_work.o \\ extable.o params.o \\ kthread.o sys_ni.o nsproxy.o \\ notifier.o ksysfs.o cred.o reboot.o \\ async.o range.o smpboot.o ucount.o regset.o ksyms_common.o이 변수에 지정된 오브젝트 파일들은 커널 빌드 과정에서 항상 포함된다. 그 밖에,obj-m: 모듈로 빌드될 오브젝트 파일들을 지정한다. 이 변수에 지정된 항목들은 커널 모듈로 컴파일되며, 필요에 따라 동적으로 커널에 로드하거나 언로드할 수 있다.obj-n: 빌드에서 제외될 오브젝트 파일을 지정한다. 이는 해당 항목이 커널 빌드 과정에서 무시됨을 의미.obj-$(CONFIG명) 항목들의 경우, 관련 CONFIG 설정이 y 라면 실행되지만, 그렇지 않은 경우 실행되지 않는다.obj-$(CONFIG_USERMODE_DRIVER) += usermode_driver.oobj-$(CONFIG_MULTIUSER) += groups.oobj-$(CONFIG_VHOST_TASK) += vhost_task.o해당 항목의 config 값 설정을 보려면 .config 파일에서 찾아 볼 수 있다.user@DESKTOP:~/linux/kernel$ vim ../.config해당 파일을 열어보면, CONFIG_MULTIUSER=y 만 존재한다.이것은 곧, CONFIG_MULTIUSER 의 값은 y 로 obj-y로 설정, 빌드 및 실행에 적용되나, CONFIG_USERMODE_DRIVER, CONFIG_VHOST_TASK 는 존재하지 않으므로, obj- 상태이므로 kernel build 및 실행 시 영향이 없으므로 삭제하여도 동일한 상태임을 확인할 수 있다.해당 상태는 menuconfig 화면에서도 확인 가능하다.user@DESKTOP:~/linux/kernel$ cd ..user@DESKTOP:~/linux$ ARCH=arm64 make menuconfig화면에서 / 를 눌러서 찾게 모드 사용 (vi 와 동일). CONFIG_MULTIUSER 검색 시.해당 Symbol 설정이 =y 로 되어 있으나,CONFIG_USERMODE_DRIVER 의 경우 =n 임을 확인할 수 있다.위와 같이, obj-y 를 사용하여 새로 작성한 ‘new_syscall 을 Makefile` 에 추가해 준다.CFLAGS_stackleak.o += $(DISABLE_STACKLEAK_PLUGIN)obj-$(CONFIG_GCC_PLUGIN_STACKLEAK) += stackleak.oKASAN_SANITIZE_stackleak.o := nKCSAN_SANITIZE_stackleak.o := nKCOV_INSTRUMENT_stackleak.o := nobj-$(CONFIG_SCF_TORTURE_TEST) += scftorture.o# obj- 추가 가장 마지막 항목으로 신규 systemcall 추가obj-y += new_syscall.o$(obj)/configs.o: $(obj)/config_data.gztargets += config_data config_data.gz$(obj)/config_data.gz: $(obj)/config_data FORCE $(call if_changed,gzip)filechk_cat = cat $&lt;2. 커널에 새로운 소스 코드 추가2.1 systemcall 번호 할당linux/include/uapi/asm-generic/unistd.h 파일은 표준 시스템 호출 번호를 정의하는 파일이다. Linux 에서 systemcall 은 user 프로그램이 커널의 기능을 요청할 때 사용되는 메커니즘이다. 이러한 systemcall을 통해 파일 작업, 프로세스 관리, 통신 등의 작업을 수행할 수 있다.user@DESKTOP:~/linux$ vim include/uapi/asm-generic/unistd.h...__SYSCALL(__NR_futex_wait, sys_futex_wait)#define __NR_futex_requeue 456__SYSCALL(__NR_futex_requeue, sys_futex_requeue) // (1)#undef __NR_syscalls#define __NR_syscalls 457 // 기존 마지막 syscall 번호(1) __NR_futex_requeue : 정의된 시스템 호출의 고유 번호 sys_futex_requeue : 정의된 시스템 호출에 대응하는 커널 함수의 이름457 번 syscall 을 추가하고 마지막 번호를 458 로 변경한다....__SYSCALL(__NR_futex_wait, sys_futex_wait)#define __NR_futex_requeue 456__SYSCALL(__NR_futex_requeue, sys_futex_requeue)#define __NR_new_syscall 457__SYSCALL(__NR_new_syscall, sys_new_syscall) // SYSCALL_DEFINE macro 를 사용함#undef __NR_syscalls#define __NR_syscalls 458여기서 사용한 SYSCALL_DEFINE macro 의 내용은 syscall_wrapper.h 에 포함되어 있으며 architecture 마다 다르므로 아래 경로 파일에서 확인 가능하다.user@DESKTOP:~/linux$ vi arch/arm64/include/asm/syscall_wrapper.h#define COMPAT_SYSCALL_DEFINEx(x, name, ...) \\ asmlinkage long __arm64_compat_sys##name(const struct pt_regs *regs); \\ ALLOW_ERROR_INJECTION(__arm64_compat_sys##name, ERRNO); \\ static long __se_compat_sys##name(__MAP(x,__SC_LONG,__VA_ARGS__)); \\ static inline long __do_compat_sys##name(__MAP(x,__SC_DECL,__VA_ARGS__)); \\ asmlinkage long __arm64_compat_sys##name(const struct pt_regs *regs) \\ { \\ return __se_compat_sys##name(SC_ARM64_REGS_TO_ARGS(x,__VA_ARGS__)); \\ } \\ static long __se_compat_sys##name(__MAP(x,__SC_LONG,__VA_ARGS__)) \\ { \\ return __do_compat_sys##name(__MAP(x,__SC_DELOUSE,__VA_ARGS__)); \\ } \\ static inline long __do_compat_sys##name(__MAP(x,__SC_DECL,__VA_ARGS__))3. 커널에 새로운 시스템콜 추가3.1 build 진행 (이미지 생성)user@DESKTOP:~/linux$ ARCH=arm64 CROSS_COMPILE=/home/gon/gcc-arm-10.3-2021.07-x86_64-aarch64-none-linux-gnu/bin/aarch64-none-linux-gnu- make -j164. 새로운 시스템콜을 사용하는 응용프로그램 만들기4.1 응용 프로그램 추가user@DESKTOP:~$ vi hello.c#include &lt;stdio.h&gt;#include &lt;unistd.h&gt; // syscall 함수 포함#define __NR_new_syscall 457 // 커널 쪽 unistd.h 에는 추가하였으나, toolchaing 측 unistd.h 에는 추가히자 않았으며로 여기에서 명시해줌int main() { int ret = syscall(__NR_new_syscall, 15); printf(\"ret : %d\\n\", ret); return 0;}4.2 응용 프로그램 빌드여기서 빌드될 응용 프로그램은 앞에서 작업한 커널 이미지를 QEMU 를 통해 실행한 환경에서 사용할 것이므로 단순 gcc 아닌 해당 toolchain 을 사용하여 빌드해야 한다.user@DESKTOP:~$ gcc-arm-10.3-2021.07-x86_64-aarch64-none-linux-gnu/bin/aarch64-none-linux-gnu-gcc -o hello hello.c제대로 빌드되었는지 생서된 실행파일의 정보를 확인한다.user@DESKTOP:~$ file hellohello: ELF 64-bit LSB executable, ARM aarch64, version 1 (SYSV), dynamically linked, interpreter /lib/ld-linux-aarch64.so.1, for GNU/Linux 3.7.0, with debug_info, not stripped위와 같이 ARM aarch64 로 정상적으로 빌드되었음을 확인할 수 있다.5. 새로운 시스템콜 실행하기5.1 빌드한 프로그램을 rootfs 이미지 내로 (/usr/bin) 에 복사하기해당 작업은 mnt 디렉토리에 mount 하여 사용할 수 있다. 여깃 /mnt 는 일반적으로 임시적으로 mount 할 공간이 필요할 경우 사용되는 디렉토리이다.user@DESKTOP:~$ sudo mount -o loop buildroot/output/images/rootfs.ext4 /mnt -o loop : loop는 이 옵션의 인자로, 일반적인 파일 시스템이 아닌 파일(예: 이미지 파일)을 마운트할 때 사용되는 옵션. loop 장치를 사용하면, 파일을 마치 별도의 물리적 드라이브인 것처럼 마운트할 수 있다. buildroot/output/images/rootfs.ext4 : 리눅스 루트 파일 시스템 중 ext4 파일 시스템 포맷을 사용하는 이미지 /mnt : 이는 마운트 포인트를 지정 이러게 마우트된 파일 시스템에 앞에서 필드한 hello 를 복사한다.user@DESKTOP:~$ sudo cp hello /mnt/usr/binuser@DESKTOP:~$ syncsync 명령어는 리눅스 및 유닉스 계열 운영 시스템에서 사용되며, 메모리에 버퍼링된 파일 시스템의 쓰기 작업을 디스크에 강제로 동기화하는 역할을 한다. 시스템이 정상적으로 셧다운되기 전이나 중요한 파일 시스템 작업을 수행한 후 데이터의 손실을 방지하기 위해 사용된다.sync 명령어를 사용하면, 이러한 버퍼링된 모든 쓰기 작업이 완료되고 디스크에 안전하게 저장될 때까지 기다린다. 명령어는 별도의 출력 없이 실행되며, 명령이 완료되면 모든 변경 사항이 디스크에 반영된 상태가 된다.이렇게 작업이 hello 실행 파일을 이미지에 추가시킨 후 마우트 해제한다.user@DESKTOP:~$ sudo umount /mnt5.2 QEMU 실행하기user@DESKTOP:~$ qemu-system-aarch64 -kernel linux/arch/arm64/boot/Image -drive format=raw,file=buildroot/output/images/rootfs.ext4,if=virtio -append \"root=/dev/vda console=ttyAMA0 nokaslr\" -nographic -M virt -cpu cortex-a72 -m 2G -smp 2 buildroot 내에서 추가한 systemcall 동작 확인# helloHello World~!!!! 15ret : 16위와 같이, linux rootfs 에 추가한 hello 실행 파일을 바로 실행 시킬 수 있으며, 그 실행 과정에서 new_syscall 의 printk(KERN_INFO \"Hello World~!!!! %d\\n\", code); 가 실행되어 Hello World~!!!! 15 가 출력 되고, 다시 hello 의 printf(\"ret : %d\\n\", ret); 실행으로 ret : 16 가 출력됨을 확인할 수 있다.# dmesg...virtio_net virtio0 enp0s1: renamed from eth0random: crng init doneHello World~!!!! 15커널에서 프린트 되는 모든 로그 메세지 출력해보면, 해당 systemcall 이 실행되면서 출력된 로그값이 마지막에 존재하는 것을 확인할 수 있다."
    } ,
  
    {
      "title"       : "Buildroot 설치 및 Kernel build",
      "category"    : "",
      "tags"        : "linux, buildroot, kernel build",
      "url"         : "./buildroot-setting01.html",
      "date"        : "2024-02-22 10:32:20 +0900",
      "description" : "개발자를 위한 반도체 SW개발 기초 (디바이스 드라이버 개발) 관련 학습 06",
      "content"     : "아래 내용은 개발자를 위한 시스템 반도체 SW개발 기초(디바이스 드라이버 개발) (https://comento.kr/) 강의 내용 중 일부에 해당함.1. buildroot 다운로드 및 설치1.1 buildroot 다운로드root@:~$ git clone git://git.buildroot.net/buildroot1.2 qemu 설정root@:~$ sudo apt-get install libncurses-dev # 필수 라이브러리 설치root@:~$ cd buildrootroot@:~/buildroot$ ls configs # config 종류 확인root@:~/buildroot$ make qemu_aarch64_virt_defconfigroot@:~/buildroot$ make menuconfig다음과 같이 설정을 진행 system configuration -&gt; init system -&gt; systemd 선택 kernel -&gt; linux kernel 해제 target packages -&gt; text editors -&gt; vim -&gt; target packages -&gt; libaries -&gt; Crypto -&gt; openssl support 선택 -&gt; openssl binary 도 선택 Filesystem images -&gt; ext2/3/4 -&gt; ext4 -&gt; exact size -&gt; 128M host utilities -&gt; 모두 선택 해제 (해제 불가 항목은 그대로 둠) -&gt; 최종 exit -&gt; 저장root@:~/buildroot$ cat /proc/cpuinfo | grep processor | wc -l # cpu 갯수 확인root@:~/buildroot$ make -j&lt;cpu 수&gt;1.3 에러 처리다만 해당 실행 시 에러가 발생하였는데 관련 내용은 다음과 같다.root@:~/buildroot$ make -j&lt;cpu 수&gt;Your PATH contains spaces, TABs, and/or newline (\\n) characters.This doesn't work. Fix you PATH.make: *** [support/dependencies/dependencies.mk:27: dependencies] Error 1이 에러 메시지는 Linux 시스템의 PATH 환경 변수에 공백, 탭(TABs), 또는 줄바꿈 문자(newline, \\n)가 포함되어 있어서 발생한 것이다. make와 같은 빌드 시스템에서는 PATH 환경 변수를 사용하여 필요한 실행 파일들을 찾는다. 만약 PATH에 이러한 특수 문자가 포함되어 있다면, 빌드 프로세스가 제대로 실행 파일들을 찾지 못하게 되어 오류가 발생하게 된다.root@:~/buildroot$ echo $PATH이 명령어를 실행하면 PATH에 설정된 디렉토리들이 콜론(:)으로 구분되어 출력된다. 여기서 공백, 탭, 또는 줄바꿈 문자가 있는지 확인해보니 몇 군데 공백이 확인 되었다. 따라서, PATH에서 문제가 되는 문자를 아래와 같이 제거함.root@:~/buildroot$ export PATH=$(echo $PATH | tr -d ' \\t\\n')echo $PATH 로 제거가 되었는지 확인한 이후, 다시 make 실행에 unzip 이 설치되어 있지 않다고 에러가 발생하여 이를 설치하였다.root@:~/buildroot$ sudo apt-get updateroot@:~/buildroot$ sudo apt-get install unzip1.4 buildroot 설치그리고 최종적으로 make 를 실행하여 설치함 (20 여분 소요)해당 작업을 통해 Buildroot 는 위 설정에 따라 다음의 주요 작업을 진행, embedded system S/W stackt 을 빌드 한다. 구성 검증: Buildroot는 .config 파일이나 다른 구성 파일에 정의된 설정을 검증한다. 이 설정은 make menuconfig, make xconfig 또는 make nconfig와 같은 명령어를 통해 사전에 사용자에 의해 정의 것들 이다.. 툴체인(Toolchain) 빌드 또는 다운로드: 툴체인은 컴파일러, 링커, 라이브러리 등 임베디드 소프트웨어를 컴파일하기 위해 필요한 도구들의 집합이다. Buildroot는 선택된 설정에 따라 적절한 툴체인을 빌드하거나 사전에 빌드된 툴체인을 다운로드한다. 다만 현재의 설정에서 toolchain 빌드는 따로 진행된다. 리눅스 커널 빌드: 사용자가 지정한 버전의 리눅스 커널을 다운로드하고, 필요한 패치를 적용한 후 커널을 크로스 컴파일한다. 역시 현재의 설정에서 커널 빌드는 따로 진행된다. 루트 파일 시스템(Root Filesystem) 구성: Buildroot는 사용자가 선택한 모든 소프트웨어 패키지를 다운로드하고, 이들을 크로스 컴파일하여 루트 파일 시스템을 구성. 이 과정에는 라이브러리, 시스템 유틸리티, 애플리케이션 등이 포함된다. 부트로더(Bootloader) 빌드: 필요한 경우, 선택된 부트로더(예: U-Boot)를 빌드. 이미지 생성: 모든 빌드 과정이 완료되면, Buildroot는 이들을 통합하여 임베디드 시스템을 위한 최종 이미지(예: SD 카드 이미지, NAND 플래시 이미지)를 생성한다. 이 이미지는 실제 하드웨어에서 직접 부팅할 수 있다. 3 번과 마찬가지로 현재 설정에서 해당 과정은 별도로 커널 빌드 때 진행된다. 2. Kernel Build 다운로드 및 이미지 생성2.1 kernel download (https://kernel.org/)해당 사이트 git 주소 -&gt; “stable/linux” 검색 해서 나온 kernel/git/stable/linux.git 경로를 git clone 하여 다운 받음.root@:~/buildroot$ cd ..root@:~$ git clone https://git.kernel.org/pub/scm/linux/kernel/git/stable/linux.git/-&gt; linux 디렉토리에 해당 repository 파일 다운로드 완료2.2 kernel build 에 필요한 라이브러리 설치root@:~$ sudo apt-get install bison flex libelf-dev libssl-dev(각 라이브러리 들의 기능에 대한 이해는 부족한 상태임. 추가학습 필요) Bison 용도: bison은 GNU 프로젝트의 구문 분석기 생성기로, 커널 소스 코드 내의 구문을 분석하는 데 사용된다. 커널 빌드 과정에서는 특히 커널의 구성 설정 도구인 kconfig에 의해 사용됨. Flex 용도: flex는 텍스트 스캔을 위한 패턴 매칭을 수행하는 렉서(lexer) 또는 스캐너(scanner) 생성기. lex의 GNU 버전으로, 텍스트 입력 스트림에서 패턴을 인식하고 처리하는 프로그램을 생성한다. bison과 함께 kconfig에 의해 사용되며, 커널의 설정 옵션을 해석하고 처리하는 데 필요. libelf-dev 용도: libelf-dev는 ELF(Executable and Linkable Format) (참고 자료 : ELF 란?) 파일을 다루기 위한 개발 라이브러리. ELF 파일 포맷은 리눅스 시스템에서 실행 파일, 오브젝트 코드, 공유 라이브러리, 코어 덤프 등을 위해 사용. 커널 모듈과 같은 ELF 형식의 바이너리 파일을 생성하고 조작하는 데 사용되므로 커널 모듈을 빌드하고 분석하는 데 필수적. libssl-dev 용도: libssl-dev는 OpenSSL 라이브러리의 개발 버전 패키지. OpenSSL은 네트워크 연결에 대한 암호화 통신을 제공하는 라이브러리로, SSL(Secure Sockets Layer)과 TLS(Transport Layer Security) 프로토콜을 구현한다. 커널에서는 예를 들어, 보안 통신이 필요한 네트워크 기능을 개발할 때 이 라이브러리가 사용될 수 있다.2.3 buildroot 에 있는 config 복사 및 .config 파일 생성root@:~/linux$ cp ../buildroot/board/qemu/aarch64-virt/linux.config arch/arm64/configs/qemu_defconfigroot@:~/linux$ ARCH=arm64 make qemu_defconfig # 반환값으로 .config 생성2.4 kernel build 를 위한 toolchain download (https://developer.arm.com/)-&gt; Tools and Software -&gt; Compilers and Libraries -&gt; Arm GNU toolchain -&gt; GNU Toolchain releases for A-profile processors -&gt; GNU-A Downloads (https://developer.arm.com/downloads/-/gnu-a) -&gt; AArch64 GNU/Linux target (aarch64-none-linux-gnu) (gcc-arm-10.3-2021.07-x86_64-aarch64-none-linux-gnu.tar.xz) 다운로드(해당 작업을 wsl2 로 설치한 ubuntu 로 진행하는 경우 다운로드 파일은 windows file system) 내부로 들어오게 된다. 이것을 linux 로 복사하기 위해서는 다음과 같이 복사 및 압풀 해제를 진행한다.root@:~/linux$ cd ..root@:~$ cp /mnt/c/Users/&lt;사용자 이름&gt;/Downloads/gcc-arm-10.3-2021.07-x86_64-aarch64-none-linux-gnu.tar.xz .또는root@:~$ wget https://developer.arm.com/-/media/Files/downloads/gnu-a/10.3-2021.07/binrel/gcc-arm-10.3-2021.07-x86_64-aarch64-none-linux-gnu.tar.xz2.5 toolchain 압축 풀기root@:~$ tar xvf gcc-arm-10.3-2021.07-x86_64-aarch64-none-linux-gnu.tar.xz2.6 build 진행 (이미지 생성)root@:~$ cd linuxroot@:~/linux$ ARCH=arm64 CROSS_COMPILE=/home/gon/gcc-arm-10.3-2021.07-x86_64-aarch64-none-linux-gnu/bin/aarch64-none-linux-gnu- make -j16build 가 완료되면 위와 같이 vmlinux 를 생성하고 이것을 가지고 arch/arm64/boot/Image 가 생성된것을 확인할 수 있다.3. buildroot 이미지 실행3.1 QEMU 설치root@:~$ sudo apt install qemu-system-arm3.2 이미지 실행root@:~$ qemu-system-aarch64 \\ -kernel linux/arch/arm64/boot/Image \\ -drive format=raw,file=buildroot/output/images/rootfs.ext4,if=virtio \\ -append \"root=/dev/vda console=ttyAMA0 nokaslr\" \\ -nographic -M virt -cpu cortex-a72 \\ -m 2G \\ -smp 23.3 이미지 종료터미널 창을 별도로 열어서 kill 명령어로 종료kill -9 qemu-system-aarch64또는 qemu 내에서 shutdown 명령어로 종료shutdown -h now"
    } ,
  
    {
      "title"       : "Makefile 기본 문법 01",
      "category"    : "",
      "tags"        : "linux, bash, makefile, incremental build, suffix rule",
      "url"         : "./makfile01.html",
      "date"        : "2024-02-21 14:32:20 +0900",
      "description" : "개발자를 위한 반도체 SW개발 기초 (디바이스 드라이버 개발) 관련 학습 05",
      "content"     : "Makefile 변수 (macro) 사용의존성 부분은 일반적으로 매크로로 선언하여 사용함.매크로를 사용하여 값을 할당할 때, 여러가지 할당 방법이 존재= (Recursive Assignment)= 연산자는 재귀적 할당을 수행한다. 이는 매크로가 사용될 때마다 평가되어 확장된다. 매크로의 값이 다른 매크로를 참조하는 경우, 참조된 변수의 최종값에 따라 달라진다.FOO = ${BAR}BAR = bar_valueall: @echo $(FOO)해당 Makefile 을 실행하면 FOO 매크로는 BAR의 값을 참조한다. 따라서 실행될 때, BAR 의 값은 bar_value 이므로 bar_value 가 출력된다.:= (Simle Assignment):= 연산자를 사용한 단순할당의 경우, 매크로에 값이 할당될 때 시점의 값으로 바로 평가, 확장된다. 따라서 이후 참조하고 있는 매크로의 값이 변경되더라도, 최초에 할당된 값을 유지한다.BAR = bar_valueFOO := $(BAR)BAR = new_valueall: @echo $(FOO)이 경우, FOO 는 BAR 의 현재값인 bar_value 로 초기화 되고, 이후 BAR 의 값이 변경되더라도 FOO 의 값은 변하지 않는다. 따라서 해당 Makefile 을 실행하면 출력값은 bar_value 가 된다.+= (Append)기존 변수의 값에 값을 추가함. 만약 매크로가 정의되어 있지 않았었다면 해당 매크로를 생성한다.CFLAGS := -WallCFLAGS += -g # CFLAGS는 이제 \"-Wall -g\"?= (Conditional Assignment)매크로가 아직 값이 할당되어 있지 않을 경우에만 값을 할당. 이미 값이 있으면 할당하지 않음.CC ?= gcc # CC가 이전에 정의되지 않았다면 gcc를 사용$@ (Target Name)$@ : 현재 target 의 이름을 명시all: programprogram: program.o gcc -o $@ $^이 경우 program: program.o 에서 program 이 현재 target 이다. 따라서 $@ 는 program 으로 대체 된다.$&lt; (First Dependency)$&lt; 는 규치의 첫 번째 의존성을 나타냄.program.o: program.c gcc -c $&lt; -o $@여기서 $&lt; 는 program.c 을 의미하므로 gcc -c $&lt; -o $@ 는 gcc -c program.c -o program.o 를 의미한다.$^ (All Dependencies)현재 규칙의 모든 의존성 목록을 나타낸다. 중복된 의존성은 제거된다.program: main.o lib.o util.o gcc -o $@ $^여기서 $^ 는 main.o lib.o util.o 을 의미하므로 gcc -o $@ $^ 는 gcc -o program main.o lib.o util.o 를 의미한다.확장자 룰 (sffix rule) 과 패턴 규칙(pattern rule)Makefile 의 확장자 룰은 오래된 규칙으로, 파일 변환 규칙을 정의하는데 사용됨. 주로 한 종류의 파일을 다른 종류로 변환하는데 사용되며, 확장자만으로 이 변환 과정을 식별한다. .SUFFIXES 리스트에 정의된 확장자들을 사용하여, 소스파일에서 목적파일로 변환에 사용될 수 있다..SUFFIXES: .c .o.c.o: gcc -c $&lt; -o $@.c.o: 은 .c 파일을 .o 파일로 변환하는 규칙을 정의한 target 이다. 따라서 gcc -c $&lt; -o $@ 은 첫번째 의존성 .c 파일을 동일 파일 이름의 .o 파일로 compile 하라는 의미 이다. 그러나 현대의 Makefile 작성에서는 패턴 규칙을 사용하는 것이 더 권장된다. 확장자 규칙은 유연성과 명확성이 떨어질 수 있으며, GNU Make와 같은 최신 도구에서는 보다 강력하고 유연한 패턴 규칙을 사용할 수 있다. 패턴 규칙은 특정 파일 세트에 대해 적용할 수 있는 규칙을 정의할 때 % 와일드카드를 사용하여 보다 일반적인 규칙을 작성할 수 있게 해준다.%.o: %.c gcc -c $&lt; -o $@이는 앞의 확장자 룰과 동일한 명령을 수행하며, 좀더 명확하고 간결하게 표현된다.그러나 결론적으로 동일한 파일명의 소스파일에서 목적 파일을 생성하는 룰은 Makefile 에 기본으로 내장되어 있기 때문에 사용자가 정의하는 Makefile 에서는 해당 내용을 생략해도 실행된다.executable: distance.o main.o ld -o executable *.o /usr/lib/x86_64-linux-gnu/crt1.o -lm -lc -dynamic-linker=/lib64/ld-linux-x86-64.so.2distance.o : distance.c gcc -c -o distance.o distance.cmain.o : main.c gcc -c -o main.o main.c위 내용은 아래와 같이 명시적으로 작성하지 않아도,executable: distance.o main.o ld -o executable *.o /usr/lib/x86_64-linux-gnu/crt1.o -lm -lc -dynamic-linker=/lib64/ld-linux-x86-64.so.2최종 실행 파일 생성만 구현하고 make를 실행해도 이전과 동일하게 각 소스코드에서 목적파일이 생성되고 최종적으로 실행파일이 생성된다. 또한 점진적 빌드 (Incremental build) 도 정상적으로 동작한다.buildroot_download:"
    } ,
  
    {
      "title"       : "Shell Script 사용한 시스템 구축 01 (사용자 계정 생성)",
      "category"    : "",
      "tags"        : "linux, bash, shell scirpt",
      "url"         : "./shell-script04-systemsetting01-copy.html",
      "date"        : "2024-02-20 14:32:20 +0900",
      "description" : "개발자를 위한 반도체 SW개발 기초 (디바이스 드라이버 개발) 관련 학습 04",
      "content"     : "참고 자료 : 처음 배우는 셸 스크립트 8장 시스템 구축shell script 를 사용하여 사용자 개정을 생성하는 파일을 작성 및 실행프로세스 사용자 계정과 패스워드 입력 입력 정보가 없으면 에러 메세지를 보여주고, script 종료 여러명의 사용자 계정을 생성할 경우 반복문을 사용하여 순회 각 계정이 이미 사용자 계정에 포함되어 있는지 확인 포함되어있지 않다면, 계정을 생성하고 패스워드 설정 이미 존재하는 계정이라면, 이를 메세지로 보여줌.1. 다수의 사용자 계정 생성(1) if [[ -n $1 ]] &amp;&amp; [[ -n $2 ]]해당 script 실행시 매개 변수로 사용자 계정($1)과 패스워드($2)가 모두 입력 되었는지 확인(-n : 비워있지 않아야 함) 한다. $1 과 $2 모두 외부 입력값이므로 이중 중괄호 [[]] 를 사용한다.(2) IFS=' ' read -r -a UserList &lt;&lt;&lt; \"$1\" 입력된 매개변수 값을 공백을 기준으로 값을 slice 하여 배열의 형태로 shell script 변수로 저장함. IFS (Internal Field Separator) : IFS 는 shell scirpt 에서 사용하는 내부 필드 구분자. 이 변수는 문자열을 분리하여 배열이나 개별 변수로 읽을 때 사용하는 구분자을 정의한다. 기본값은 공백, 탭, 개행 문자. read : 표준 입력이나 파일로부터 입력을 읽어드림. 이 명령어를 사용하여 변수에 값을 할당할 수 있다. -r : read 옵션 중 백슬래시(\\) 가 이스케이프 문자로 처리되지 않고, 그대로 읽어드림. -a : read 명령어에 의히 읽힌 값을 배열로 저장. &lt;&lt;&lt; (Here String) : “$1” 로 받은 외부 입력 값을 UserList 변수 값으로 취할 수 있도록 redirection 해줌. (3) for (( i=0 ; i &lt; ${#UserList[@]}; i++ )) 배열 UserList 의 길이만큼 반복할 수 있도록 설정(4) if [[ $(cat /etc/passwd | grep -w ${UserList[$i]} | wc -l) == 0 ]] $(cat /etc/passwd 파일의 내용을 가져와서, UserList[$i] 의 값과 정확히 (-w)일치하는 사용자 계정을 찾고, wc (word count) 의 라인 수(-l) 을 출력, 해당 값이 0 아니라면, 동일 계정이 존재한다는 것을 의미함.(5) useradd ${UserList[$i]} 기존 계정이 존재하지 않는 경우, 해당 값 ${UserList{$i}} 의 계정을 생성함. (6) echo \"${UserList[$i]}:${Password[$i]}\" | chpasswd 새로 생성한 계정에 대한 패스워드 값을 사용하여 패스워드를 설정#!/bin/bash# 사용자 계정 및 패스워드가 입력되었는지 확인if [[ -n $1 ]] &amp;&amp; [[ -n $2 ]] # (1)then IFS=' ' read -r -a UserList &lt;&lt;&lt; \"$1\" # (2) IFS=' ' read -r -a Password &lt;&lt;&lt; \"$2\" # for 문을 이용하여 사용자 계정 생성 for (( i=0 ; i &lt; ${#UserList[@]}; i++ )) # (3) do # if문을 사용하여 사용자 계정이 있는지 확인 if [[ $(cat /etc/passwd | grep -w ${UserList[$i]} | wc -l) == 0 ]] # (4) then # 사용자 생성 및 패스워드 설정 useradd ${UserList[$i]} # (5) echo \"${UserList[$i]}:${Password[$i]}\" | chpasswd # (6) else # 사용자가 있다고 메세지를 보여줌 echo \"this user ${UserList[$i]} is existing.\" fi doneelse # 사용자가 계정과 패스워드를 입력하라는 메세지를 보여줌 echo -e 'Please input user id and password. \\nUsage: adduser-script.sh \"user01 user02\" \"pw01 pw02\"'fi해당 script 를 adduser-script.sh 에 저장하고 아래와 같이 실행gon@DESKTOP:~/book/ch08$ sudo bash adduser-script.sh \"user1 user2\" \"1111 2222\"여기에서 sh 가 아닌 bash 명령어를 사용한 이유는, 일부 리눅스 (ex. Ubuntu) shell 이 bash 가 아닌 dash 에서 실행되는 경우가 있다. 이런 경우, dash 에서 지원되지 않는 기능 (ex. redirection &lt;&lt;&lt;)을 shell script 내 사용한 경우, 다음과 같은 에러가 발생한다.gon@DESKTOP:~/book/ch08$ sudo sh adduser-script.sh \"user1 user2\" \"1111 2222\"adduser-script.sh: 7: Syntax error: redirection unexpected이를 해결하는 다른 방법으로, 해당 파일의 실행 권한을 아예 변경하고, 직접 실행 시키면 된다.gon@DESKTOP:~/book/ch08$ chmod +x adduser-script.shgon@DESKTOP:~/book/ch08$ ./adduser-script.sh \"user1 user2\" \"1111 2222\"최종적으로, 해당 실행이 정상적으로 동작했는지를 위해 /etc/passwd 파일 내용을 확인하면 아래 해당 user 가 추가된 것을 확인할 수 있다.gon@DESKTOP:~/book/ch08$ cat /etc/passwd...user1:x:1001:1001::/home/user1:/bin/shuser2:x:1002:1002::/home/user2:/bin/sh2. ssh 를 활용하여 다른 서버에 사용자 계정 생성#!/bin/bashfor server in \"host01 host02 host03\"do # 여러 대의 시스템에 사용자 생성 및 패스워드 설정 echo $server ssh root@$server \"useradd $1\" # (1) ssh root@$server \"echo $2:$1 | chpasswd\" done(1) ssh root@$server \"useradd $1\" ssh : SSH protocol 을 사용하여 원격 서버에 접속하가나 원격 서버에서 명령을 실행하기 위한 client 프로그램 root@$server : 사용자명@호스트명 형식으로 접속할 원격 서버의 최고 관리자 계정을 의미 \"useradd $1\" : ssh root 계정으로 해당 host 에 접속하여 사용자 계정 추가를 실행"
    } ,
  
    {
      "title"       : "Shell Script 기본 문법 03 (큰따옴표 작은 따음표)",
      "category"    : "",
      "tags"        : "linux, bash, shell scirpt, quates",
      "url"         : "./shell-script03-quates.html",
      "date"        : "2024-02-10 12:32:20 +0900",
      "description" : "개발자를 위한 반도체 SW개발 기초 (디바이스 드라이버 개발) 관련 학습 03",
      "content"     : "Bash 스크립트에서 큰따옴표(““)와 작은따옴표(‘‘)는 문자열을 묶는 데 사용되지만, 그들이 처리하는 방식에는 중요한 차이가 있다.큰따옴표(“”) 변수 확장(Expansion) 큰따옴표 안에 있는 변수는 그 값으로 확장됨. 예를 들어, “$VARIABLE”은 VARIABLE의 값을 나타냄. 명령어 치환(Command Substitution) 큰따옴표 안에서 명령어 치환. 예를 들어, “$(date)”는 현재 날짜와 시간으로 치환됨. 공백과 특수 문자 큰따옴표 안의 공백, 탭 등은 문자열의 일부로 유지됨. 이는 여러 단어나 공백을 포함하는 문자열을 하나의 인자나 값으로 처리해야 할 때 유용. 작은따옴표(‘’) 문자 그대로의 값 작은따옴표 안의 모든 문자는 그대로의 값으로 처리됨. 변수 확장이나 명령어 치환 같은 것은 일어나지 않는다. 예를 들어, ‘$VARIABLE’은 표기된 문자열 “$VARIABLE” 그 자체를 의미. 공백과 특수 문자 작은따옴표 안의 공백과 특수 문자도 문자열의 일부로 유지되며, 이 역시 여러 단어나 공백을 포함하는 문자열을 하나의 인자나 값으로 처리하고자 할 때 유용. 사용 예시 변수 확장이 필요한 경우 “Hello, $USER” (USER 변수에 해당하는 사용자 이름으로 확장.) 명령어 치환을 사용하는 경우 “Today is $(date)” (현재 날짜로 치환.) 문자 그대로의 값이 필요한 경우 ‘Data $5 not processed’ (문자열이 그대로 출력, 변수 확장이나 치환 없이.) 결론각각의 사용법은 스크립트에서 변수의 값이나 명령어의 결과를 어떻게 처리할지에 따라 달라진다. 문자열 내에서 변수의 값을 그대로 사용하고 싶지 않거나, 특수 문자를 명령어의 일부로 해석되지 않게 하고 싶을 때 작은따옴표를 사용한다. 반면, 변수의 값을 확장하거나 명령어의 결과를 사용하고자 할 때는 큰따옴표를 사용한다."
    } ,
  
    {
      "title"       : "Shell Script 기본 문법 02 (types)",
      "category"    : "",
      "tags"        : "linux, bash, shell scirpt",
      "url"         : "./shell-script02-types-copy.html",
      "date"        : "2024-02-10 08:32:20 +0900",
      "description" : "개발자를 위한 반도체 SW개발 기초 (디바이스 드라이버 개발) 관련 학습 02",
      "content"     : "Bash Shell Script에서는 다른 프로그래밍 언어들처럼 명시적인 데이터 타입 선언을 사용하지 않는다. Bash는 기본적으로 모든 변수를 문자열로 처리하지만, Bash 스크립트 내에서 다양한 형태의 데이터를 다룰 수 있으며, 이를 위해 특정 명령어나 구문을 사용하여 숫자, 문자열, 배열 등과 같은 다양한 “형태”의 데이터를 다루게 된다. 아래는 Bash에서 사용될 수 있는 주요 “데이터 타입”의 개념과 예시이다.문자열 (String)Bash에서 가장 기본적이고 자주 사용되는 데이터 타입. 변수에 값을 할당할 때 따옴표를 사용하지 않거나, 단일 따옴표(‘)나 이중 따옴표(“)를 사용하여 문자열을 할당.name=\"John Doe\"greeting='Hello, World!'정수(Integer)Bash에서는 declare -i 명령어를 사용하여 변수를 정수로 선언할 수 있다. 또한, 산술 연산에서 Bash는 변수를 자동으로 정수로 취급declare -i numbernumber=10echo $((number + 5)) # 15 출력배열(Array)Bash에서 배열은 여러 값을 저장할 수 있는 데이터 구조. 배열은 0부터 시작하는 인덱스를 가지며, ()를 사용하여 배열을 선언.arr=(1 2 \"hello\" \"world\")echo ${arr[0]} # 1 출력echo ${arr[3]} # world 출력 Bash 배열과 다른 프로그래밍 언어 배열 (ex. C)과 다른점 index &amp; mata-data Bash 배열의 구현은 C 배열과 달리 고수준에서 이루어지기 때문에, 원소가 저장된 메모리에 대한 접근 방법 등을 고려할 필요가 없다. Bash 배열은 각 원소애 대한 index 와 mata-data 를 내부적으로 유지하며, 여기에 원소의 위치, 길이 등이 포함될 수 있다. 동적 할당과 관리Bash는 필요에 따라 동적으로 메모리를 할당하고, 배열의 원소를 관리한다. 사용자가 배열에 원소를 추가하거나 제거할 때, Bash는 내부적으로 이러한 변경을 처리하고, 배열의 각 원소가 올바르게 접근될 수 있도록 한다. 추상화된 접근 방식사용자가 배열의 원소에 접근할 때, Bash는 추상화된 인터페이스(예: 인덱스를 사용-한 접근)를 제공ㄹ. 사용자는 인덱스를 통해 간단하게 원소에 접근할 수 있으며, Bash가 원소의 실제 메모리 위치와 경계를 관리한다. 연관 배열(Associative Arrays)ash 4 이상에서는 연관 배열(키-값 쌍을 저장하는 배열)을 사용할 수 있음. declare -A를 사용하여 연관 배열을 선언.declare -A fruitsfruits[apple]=\"red\"fruits[banana]=\"yellow\"echo ${fruits[apple]} # red 출력부동 소수점(Floating Point Numbers)Bash 자체는 부동 소수점 수를 직접 지원하지 않는다. 부동 소수점 연산을 수행하려면 bc나 awk와 같은 외부 도구를 사용해야 함.result=$(echo \"3.5 + 4.2\" | bc)echo $result # 7.7 출력환경 변수(Environment Variables)환경 변수는 운영 체제의 환경 설정을 포함하는 전역 변수. Bash 스크립트에서는 이러한 환경 변수를 읽고 설정할 수 있다.echo $PATHexport MY_VAR=\"SomeValue\""
    } ,
  
    {
      "title"       : "Shell Script 기본 문법 01",
      "category"    : "",
      "tags"        : "linux, shell scirpt",
      "url"         : "./shell-script01.html",
      "date"        : "2024-02-10 08:32:20 +0900",
      "description" : "개발자를 위한 반도체 SW개발 기초 (디바이스 드라이버 개발) 관련 학습 01",
      "content"     : "1. 간단한 함수를 사용한 script 1#!/bin/bash# 함수 정의: 두 인자를 받아 출력함add_inner_numbers() { echo \"첫 번째 숫자: $1\" echo \"두 번째 숫자: $2\" local sum=0 sum=$(( $1 + $2 )) echo \"두 수의 합: $sum\"}# 함수 호출: 5와 10을 인자로 전달add_inner_numbers 5 10 #!/bin/bash “shebang” (또는 “hashbang”) 해당 script를 실행할 때 사용할 interpreter 의 경로를 진행 여기서는 Bash shell 을 사용하여 실행되어야 함을 의미 subtract_num() {} script 함수를 정의할 때, 매개변수는 명시하지 않는다. 함수 내 $1, $2, $3 … 과 같이 함수 내부에 명시된 value 의 숫자값에 순서대로 매칭되어 입력된다. sum=$(( $1 + $2 )) 첫번째 괄호는 $() 로 연산 결과를 값으로 취함을 의미 두번째 괄호는 연산에 대한 괄호 띄어쓰기는 여기서는 결과에 영향을 미치지는 않지만 일반적인 작성 기준을 따름. 실행 결과root@DESKTOP:~$ ./example.sh첫 번째 숫자: 5두 번째 숫자: 10두 수의 합: 152. 간단한 함수를 사용한 script 2 (외부 입력)#!/bin/bash# 두수를 빼는 함수 정의subtract_num() { local sub=0 sub=$(( $2 - $1 )) echo \"두 수의 차: $sub\"}# 사용자로부터 두수 입력 받기read -p \"첫번째 수를 입력하세요: \" num1read -p \"두번째 수를 입력하세요: \" num2# 함수 호출subtract_num $num1 $num2 read -p \"첫번째 수를 입력하세요: \" num1 read 명령어로 표준입력 값을 받을 수 있다. -p 옵션으로 echo 명령어를 사용하지 않고 프롬프트 메세지를 보여줄 수 있다. 실행 결과root@DESKTOP:~$ ./example.sh첫번째 수를 입력하세요: 2두번째 수를 입력하세요: -5두 수의 차: -73. 간단한 함수를 사용한 script 3 (외부 입력, 조건문)외부 입력을 함수의 실행과 함께 받도록 아래와 같이 구현할 수 있다.#!/bin/bash# 두수를 빼는 함수 정의subtract_num() { local sub=0 sub=$(( $2 - $1 )) echo \"두 수의 차: $sub\"}if [ $# -ne 2 ]; then echo \"사용방법: $0 숫자1 숫자2\" exit 1fi# 함수 호출subtract_num $1 $2 if [ $# -ne 2 ]; then ... fi []; 내 조건이 참일 경우, then ... fi 내 명령어를 실행 if, [];, then 사이에는 띄어쓰기를 반드시 해야 함. $# -ne 2 $# 은 script 에 전달된 positional parameter 의 갯수. 위 예제의 경우, ./example.sh 1 2 와 같이 실행되는데, 이 때 $# 값은 2 이다. -ne 은 “not equal” 의 약자로, 두 값이 서로 다른지를 비교 2 는 비교 대상의 값 즉 해당 script 부분은 “입력된 positional parameter 갯수가 2개가 아니라면” 이라는 조건을 정의함. echo \"...\" exit 1 해당 조건일 때, 메세지를 출력하고 에러 상태로 script 를 종료 exit 0 인 경우, 정상적으로 작업이 성공되고 종료됨을 의미, 0 이 아닌 경우는, 에러나 특정 조건으로 인한 종료를 의미 실행 결과매개변수를 입력하지 않은 경우root@DESKTOP~$ ./example.sh사용방법: ./example.sh 숫자1 숫자2매개변수 값을 함께 입력한 경우root@DESKTOP:~$ ./example.sh 3 3두 수의 차: 04. 파일 입력 &amp; 반복문을 이용 script#!/bin/bash# 'list' 파일을 읽어와 line 변수에 저장while read -r line; do # 공백으로 구분된 값을 배열로 변환 IFS=' ' read -ra ADDR &lt;&lt;&lt; \"$line\" # 배열의 각 요소를 반복하여 출력 for i in \"${ADDR[@]}\"; do echo $i donedone &lt; \"list\"list 파일1 2 3 4 5 while read -r line: do ... done &lt; \"list\" list 파일로 부터 해당 내용을 줄별로 읽어와서 각 줄의 값을 line 변수의 값으로 생성한다. -r 옵션은 read 명령어가 \\ 을 이스케이프 문자가 아닌 데이터 원본 그대로 무결성을 유지한채로 값을 가질 수 있도록 조건을 부여한다. IFS=' ' read -ra ADDR &lt;&lt;&lt; \"$line\" IFS 는 “Internal Field Separator” 의 약자, Bash 에서 단어 경계를 정의하는데 사용되는 환경 변수. 이 구분에서 IFS 는 공백문자 ' ' 로 설정되어 단어의 구분을 공백으로 사용하겠다는 의미. -ra 에서 a 옵션은 입력된 data 를 배열로 변수 ADDR 에 저장함을 의미 &lt;&lt;&lt; 은 here string redirction 을 의미. here string 은 문자열 데이터를 명령어의 표준입력으로 직접 전달할 수 있게 해준다. 명령어 &lt;&lt;&lt; \"문자열\" 과 같은 형태로, redirection 을 뒤에 오는 문자열 값을 바로 가져와서 사용할 수 있게 해준다. 예를 들어, root@DESKTOP:~$ grep \"찾는\" &lt;&lt;&lt; \"여기에는 찾는 단어가 있을까요?\"여기에는 찾는 단어가 있을까요? 와 같이, 외부 파일 등에서 가져오는 것이 아니라 뒤에 명시된 문자열 값을 바로 redirection 하여 가져와 사용하게 된다. 따라서 해당 구문을 정리하면,(1). line 변수 값을 문자열로 생성한다.(2). (1) 번 값을 redirection 하여 가져오고, (3). \\ 를 별도 처리하지 않고, (4). 띄어쓰기(‘ ‘) 로 구분하여 생성된 배열 값을 (5). 배열 변수 ADDR 의 값으로 생성한다. for i in \"${ADDR[@]}\"; do ... done 반복문 for 는 배열 변수 ADDR 의 원소를 순회하면서 원소값 을 대입하여 do ... done 내 script 를 수행함. ADDR[@] 는 각 원소를 의미 \"\" 감싸 해당 원소값을 문자열로 변환, 혹시 문자열 내 다른 문자열을 포함한 경우 (ex. “값은 ${ADDR[@]}”) 다른 문자열과 배열 변수 값 부분을 명확히 구분하기 위해 ${} 로 감싸줌. 실행 결과root@DESKTOP:~$ ./example.sh12345"
    } ,
  
    {
      "title"       : "Phoenix Live Generator",
      "category"    : "",
      "tags"        : "phoenix, generator",
      "url"         : "./phonix-generator.html",
      "date"        : "2024-01-26 08:32:20 +0900",
      "description" : "Phoenix Live Generator 는 주어진 resource 에 대한 기본적인 CRUD code 생성을 도와주는 utility 이다. 이에 대해 알아보자.",
      "content"     : "(아래 내용은 programming-phoenix-liveview_B10.0 - chapter 3 Generators: Contexts and Schemas 를 정리한 것임을 밝힙니다.)Phoenix Live Generator 란?Phoenix Live Generator 는 주어진 resource 에 대한 기본적인 CRUD code 생성을 도와주는 utility 로 다음 작업에 대한 설정을 자동을 생성해준다. backend : schema, context frontend : routs, LiveView, templates다만 위에서 표현한 ‘code 생성’ 의 의미는 elixir 에서는 조금 다른 의미를 포함하고 있다. 이는 Generator 가 자체적으로 새로운 code 을 생성 해준다기보다, 이미 정의된 macro 를 사용하여 ‘code 를 생성하는 code’ 를 실행시킴으로써, 최종적으로 사용자가 정의한 code 를 얻을 수 있게 되는 것을 의미한다.결과적으로 Generator 를 사용하여, 작성자의 반복적 작업을 줄여 줌으로써, 작성자는 각 부분의 logic 및 공통적이지 않은 부분의 작업에 집중할 수 있도록 도와준다.Phoenix Live Generator 기본 구조간단한 예제로 상품에 대한 정보를 DB 에 저장하고, 상품 리스트를 화면에 보여주는 view 를 가진 application 을 개발한다고 가정해보면, 해당 application 의 구조를 아래와 같이 그려볼 수 있다. frontend: web 에서 /product GET 요청이 있을 때, 상품 리스트를 보여주는 tempalte 이 rendering 됨. backend : phoenix application 에서 live view 는 전체적으로 context 에 관리되며, core part 인 schema 를 감싸고 있다. 즉, context 는 frontend 및 DB 와 상호작용을 담당한다.Phoenix Live Generator 의 실행기본 원리와 개념 이해를 위해, 아래 command 를 실행하여, Generator 를 실행시킨다.mix phx.gen.live Catalog Product products name:string \\description:string unit_price:float sku:integer:unique그러면 자동으로 관련 migration, schema 를 포함한 context, template 파일들이 생성되며, command 속성값들의 의미는 다음과 같다. Catalog : boundary layer 인 context Product : applcation core 인 schema prodcuts: DB table name:string description:string unit_price:float sku:integer:unique : schema fields &amp; DB table columsGenerated Core 의 이해Generated Core (ex. Product) 는, 항상 동일한 입력에 대해 동일한 출력을 제공하는 순수함수이여야 한다. database 를 관리하며 상호작용 한다. 즉 database table 생성, data 관리/유지 작업, transaction 과 query 준비 작업을 담당한다.이와 관련된 파일들을 살펴보면 다음과 같다.The Product Migrationdatabase table 을 정의한 migration 파일을 pento/priv/repo/migrations/20230728120332_create_products.exs와 같이 생성되어 진다. 해당 code 를 살펴보면 아래와 같이 command 에서 명시한 table 이름, column 명, data type 이 생성되어 있다.defmodule Pento.Repo.Migrations.CreateProducts do use Ecto.Migration def change do create table(:products) do add :name, :string add :description, :string add :unit_price, :float add :sku, :integer timestamps() end create unique_index(:products, [:sku]) endend그리고 아래 command 실행을 통해 DB 에 해당 table 이 생성됨을 확인할 수 있다.mix ecto.migrateThe Product Schema아래 lib/pento/catalog/product.ex 생성된 파일 schema macro 구현부를 통해 Elixir 구조체와 databalse products table record 간 변환할 수 있게 해준다.defmodule Pento.Catalog.Product do use Ecto.Schema import Ecto.Changeset schema \"products\" do field :description, :string field :name, :string field :sku, :integer field :unit_price, :float timestamps()end관련 작업을 수행해주는 함수의 경우, macro 에 의해 자동 생성되며, 그 목록은 아래와 같다.iex&gt; alias Pento.Catalog.Productiex&gt; exports Product__changeset__/0 __schema__/1 __schema__/2 __struct__/0__struct__/1 changeset/2이중 schema 함수가 elixir 구조체를 생성해서 database table record 와 엮는 작업을 담당한다.해당 구조체 생성은 struct/1 로 생성하며, 이를 CLI 상태에서 실행하여, 직접 그 결과를 확인할 수 있다.iex&gt; Product.__struct__(name: \"Exploding Ninja Cows\")%Pento.Catalog.Product{ __meta__: #Ecto.Schema.Metadata&lt;:built, \"products\"&gt;, description: nil, id: nil, inserted_at: nil, name: \"Exploding Ninja Cows\", sku: nil, unit_price: nil, updated_at: nil}여기에서 id, inserted_at, updated_at field 의 경우, 자동 생성되는 field 로 record 관리에 필요한 data (ex. id 의 경우, 각 record 고유값으로 식별자 역할) 들을 저장한다.changeest 의 경우, 기존에 정리된 내용 참고. (changeset/2 in Ecto Library)Generated Boundary 의 이해boundary 영역에 대한 code 을 Context 라고 하며, 외부에서 입력된 data 를 sanitizing, validating 해서 변환된 data 를 cord 영역으로 넘겨주는 작업을 담당하며 이를 정리하면 아래와 같다. Access External Services : 외부 서비스에 대한 단일 접근 지점을 제공. application 에서 필요한 외부 data 나 기능을 통합하고, 이러한 서비스들과 상호 작용을 중앙에서 관리하게 해줌. Abstract Away Tedious Details : 반복적이거나 복잡한 작업등ㄹ을 숨김(추상화) 함으로써, 개발자가 보다 중요한 logic 에 집중할 수 있도록 함. 예를 들어, data formating 이나 네트워크 통신과 같은 작업을 사전에 처리 Handle uncertainty : {:ok, result} 또는 {:error, message} 와 같은 형태로 그 결과를 반환함으로써, 성공 또는 실패를 명확하게 함. 이를 통해, 오류 처리 및 예외 상황을 보다 효율적으로 처리할 수 있음. Present a single, common API : 하나의 database table 관련 service 들에 대해 단일 접근점을 제공하여 application 내 다양한 기능들을 일관된 방식으로 사용할 수 있게 해주며, 이를 통해 application 의 사용성과 유지보수서을 향상시킴.외부 service 로부터의 접근의 예database 의 접근은 applciation 입장에서 외부 service 에 대한 접근에 해당한다. 관련 Repo 작업은 Ecto library 함수를 사용하게 되며, 따라서 Ecto code 도 core 와 boundary 부분으로 나누어지게 된다. Ecto core : query build &amp; transaction 준비 작업 (외부 환경에 영향 없이 입력값과 내부 logic 에만 영향을 받아 결과가 항상 확정적이고 예측가능, ex. changeset) Ecto boundary : Ecto.Repo 작업의 경우, 외부 상황 (ex. DB server 연결 상태)에 따라 그 결과가 바뀔 수 있으므로, boundary 에 해당"
    } ,
  
    {
      "title"       : "(App 개발 03) Account context - users table 에 nickname 항목 추가",
      "category"    : "",
      "tags"        : "phoenix, liveview, migration, table_항목_추가, schema, changeset/2, applciation_개발1",
      "url"         : "./users-column-add.html",
      "date"        : "2024-01-25 10:32:20 +0900",
      "description" : "계정 정보에서 nickname 정보가 필요함에 따라, 이를 기존에 생성한 users table 에 추가하고, 계정 생성 시, nickname 을 입력하도록 함.",
      "content"     : "Phoenix LiveView Authrization 설정을 위해 lon in 기능을 활성화에 필요한 계정 생성 작업이 필요하다. 이 때, mix phx.gen.auth Accounts User users command 를 통해 사용자 email, password 정보를 저장하고 이를 사용하여 authrization, session 괸리를 위한 service code, template, token 저장 table 까지 모두 알아서 생성해 준다.매우 편리한 기능이지만, 해당 command 로 추가 정보를 저장/관리하는 기능을 함께 생성할 수는 없음을 확인하였다. 대신 추가 migration 생성 및 필요한 요소를 관련 code 에 직접 추가하여 사용 가능하였다.현재 작업하고 있는 application 에서 사용자 정보를 노출 시킬 때, email 보다 nickname 으로 보여지는 것이 좋다고 판단되어 이를 추가하고 실제 application 에 반영하는 작업을 정리해 보았다.1. migration 생성 및 실행다음의 command 를 실행하여 migration script 파일을 생성mix ecto.gen.migration add_nickname_to_users이를 실행하면 priv/repo/migrations/(생성일시)_add_nickname__to_users.exs 파일이 생성된다. 해당 파일에서 nickname column 을 추가할 code 를 작성한다.defmodule MyPjt1.Repo.Migrations.AddNicknameToUsers do use Ecto.Migration def change do alter table(:users) do add :nickname, :string end endend해당 파일을 아래의 command 로 실행하고, database 에 변경 사항이 반영되었는지 확인한다.mix ecto.migrate2. User module 에서 schema 및 changeset/2 수정아래와 같이 Usher module 에서 schema 에 field 를 추가시켜 준다. schema \"users\" do field :email, :string field :password, :string, virtual: true, redact: true field :hashed_password, :string, redact: true field :confirmed_at, :naive_datetime field :nickname, :string # field 추가 timestamps(type: :utc_datetime) end그러나, field 를 추가하고, 계정 등록 module (user_registration_live.ex) 에서 nickname 입력을 구현하여도 실제로 저장이 되지 않는다. 그 이유는 nickname 정보까지 모두 입력 후 저장 버튼을 누를 때, 입력 값의 유효성 검증이 우선 진행되며, 검증을 통과된 경우, db 에 저장 및 authorization 작업이 진행되게 된다.그런데, 관련 유효성 검증 작업, 즉 changeset/2 code 를 확인하면 def registration_changeset(user, attrs, opts \\\\ []) do user |&gt; cast(attrs, [:email, :password]) |&gt; validate_email(opts) |&gt; validate_password(opts) end여기에서 cast(attrs, [:email, :password]) 함수는 매개변수로 입력된 key 들 (:email, :password) 에 대한 value 값이 변경되었을 때, 해당 항목에 대한 changeset 을 반환하는 함수이다. 즉 해당 항목에 :nickname 을 추가해 주어야 함께 changeset 으로 변환되어, 유효성을 검증하고, 다음 작업을 진행할 수 있게 된다. (:nickname에 대한 vaildation 은 필요하지 않아서 추가하지 않았음.) def registration_changeset(user, attrs, opts \\\\ []) do user |&gt; cast(attrs, [:email, :password, :nickname]) # :nickname 추가 |&gt; validate_email(opts) |&gt; validate_password(opts) end3. 계정 생성 시 nickname 추가 화면 구현user_registration_live.ex render/2 내 아래와 같이 nickname 항목을 추가하면 최종적으로 계정 생성시 nickname 정보까지 입력해야 조건을 만들어 줄 수 있다.... &lt;.simple_form ... &gt; ... &lt;.input field={@form[:email]} type=\"email\" label=\"Email\" required /&gt; &lt;.input field={@form[:password]} type=\"password\" label=\"Password\" required /&gt; &lt;.input field={@form[:nickname]} label=\"Nickname\" required /&gt; ... &lt;/.simple_form&gt;...users table"
    } ,
  
    {
      "title"       : "(App 개발 02) root.html.heex 과 app.html.heex 에 대해",
      "category"    : "",
      "tags"        : "phoenix, liveview, root.html.heex, app.html.heex, applciation_개발1",
      "url"         : "./root-and-app.html",
      "date"        : "2024-01-25 08:32:20 +0900",
      "description" : "Phoenix LiveView 에서 기본 <head> 설정 및 공통으로 rendering 될 요소를 넣을 수 있는 root.html.heex 과 app.html.heex 에 대해 각각의 용도를 확인하고 이를 수정 사용하는 작업 방법 확인함",
      "content"     : "현재 Phoenix LiveView application 작업을 진행하면서, 아래와 같이 page 최상단에 메뉴바를 띄우고자 한다.다만 / 과 /games url 에 대해서는 메뉴바가 있고, /games/:id url 에 대해서는 메뉴바가 없도록 구성하고 싶다. 해당 작업을 진행하면 root.html.heex 와 app.html.heex 파일을 수정하고, 수정된 파일을 어떻게하면 적절하게 이용할 수 있을지 위에서의 고민을 토대로 각 파일에 대해 알아본다.root.html.heex 역할이 파일은 전체 Phoenix 애플리케이션의 최상위 레이아웃을 정의하며, 다른 템플릿들은 이 안에 삽입되어 최종 HTML 문서를 형성한다. 일반적으로 전체 애플리케이션에 걸쳐 공통적으로 사용되는 HTML 요소를 포함한다.(&lt;head&gt; 태그 내의 meta data, stylesheet link, javascript 파일 등)router.ex 에서 pipeline :browser 를 통해 주입되며, 모든 정적 html와 LiveView는 이 파일의 구조 안에서 렌더링된다.만약 root1.html.heex 파일에서 해당 메뉴바를 구현하고, root2.html.heex 에는 메뉴바를 구현하지 않고, 이렇게 두 개의 파일을 만들어서 pipeline :browser1 , pipeline :browser2 를 각각 정의하여 이를 각각 필요한 url 에 맞게 사용하고자 시도하였으나, 이런 경우, 동일한 매개변수를 가지는 live_session macro 가 두번 정의되어야 한다. 이는 다음의 에러가 발생시킨다.** (RuntimeError) attempting to redefine live_session :require_authenticated_user.live_session routes must be declared in a single named block.따라서 동일한 scope macro 에서 정의되어야 하는 url page 에 대해서는 동일한 root.html.heex 가 적용되어야 한다.app.html.heex 역할app.html.heex는 root.html.heex 내에 삽입되는, 특정 부분의 레이아웃을 정의하는 파일로, 주로 애플리케이션의 주요 컨텐츠를 포함하며, 특정 페이지나 섹션에 대한 레이아웃을 정의하는 데 사용된다. 예를 들어, header, footer, sidebar 등 페이지의 주요 부분을 구성할 수 있으며, 페이지 별로 다른 내용을 표시하는데 사용된다.따라서 url 별로 header 적용 여부를 다르게 하고 싶다면 app.html.heex 파일을 각각 만들어서 각 page mdoule 에서 다른 template 을 가져오면 된다.구현기존에 작성한 header 는 root.html.heex 에 있었다. 그래서 해당 code 를 app.html.heex 로 이동시키고, header 가 없은 app_no_header.html.heex 를 추가 생성하였다.그리고 app_no_header.html.heex 을 liveview 에서 가져올 수 있도록 my_pjt_web.ex 에 callback 함수를 추가해주었다.defmodule MyPjt1Web do ... # 기존 app.html.heex 를 layout 로 사용하는 함수 def live_view do quote do use Phoenix.LiveView, layout: {MyPjt1Web.Layouts, :app} unquote(html_helpers()) end end # 추가된 함수. app_no_header.html.heex 를 layout 로 사용 def live_view_no_header do quote do use Phoenix.LiveView, layout: {MyPjt1Web.Layouts, :app_no_header} unquote(html_helpers()) end end ...end다음으로 각 url 대한 module 에서 use macro 를 사용하여 앞에서 정의한 callback 을 맞게 가져옴defmodule MyPjt1Web.GameLive.Index do use MyPjt1Web, :live_view ...enddefmodule MyPjt1Web.GameLive.Show do use MyPjt1Web, :live_view_no_header ...end마지막으로 남은 것은 get \"/\", PageController, :home 에서 가져오는 module 만 처리해주면 된다. 그런데, 분명 my_pjt1_webmodule controller callback 에 layout: {MyPjt1Web.Layouts, :app} 이 정의되어 있음에도 불구하고, application 실행시 app.html.heex 의 header 가 표시되어지지 않았다. 그래서 어쩔수 없이 home.html.heex 에 동일한 header 를 추가하여 자체적으로 header 를 rendering 하도록 구현하였다."
    } ,
  
    {
      "title"       : "(App 개발 01) Phoenix LiveView 에서 사용자 정의 JS code 사용 방법",
      "category"    : "",
      "tags"        : "phoenix, liveview, custom javascript, node.js, applciation_개발1",
      "url"         : "./custom-js-phoenix.html",
      "date"        : "2024-01-24 08:32:20 +0900",
      "description" : "Phoenix LiveView 에서 사용자 정의 JS code 구현 및 적용을 위한 Node.js 설정 및 render/1 에 적용하는 과정",
      "content"     : "Phoenix LiveView 를 사용하여 아래와 같이 버튼 클릭시 번갈아가며 버튼의 배경색과 내용이 바뀌는 toggle button 을 사용하고자 하였다. 그런데 기존의 Phoenix LiveView 제공 html tag 및 css 로 이를 생성할 수 없었으며, 따라서 자체적으로 JS 를 작성하여 기존 button 에 적용해야 하는 상황이다. 해당 과정에서 필요한 설정 및 render/1에 적용하기까지의 과정을 정리하고자 한다. 1. Node module 설치 및 관련 package 설치(1) package.json 생성cd assetsnpm init만약 package.json 파일이 없다면, 새로 생성해야 한다. 이를 위해 npm init 명령어를 실행하여 새로운 package.json 파일을 생성할 수 있다. 이 과정에서 프로젝트에 대한 기본 정보를 입력해야 한다.(2) npm init 작업을 위한 기본 정보 입력npm init 을 실행하면 프로젝트 이름, 버전, 설명, 진입점(주로 index.js), 테스트 명령어, 저장소, 키워드, 라이선스 등을 입력을 요청 받는다. 입력을 완료하면 package.json 이 생성되며, 여기서 해당 내용 등을 수정, 추가할 수 있다. 해당 script 은 다음과 같다.{ \"name\": \"***\", \"version\": \"1.0.0\", \"description\": \"phoenix liveview project\", \"main\": \"tailwind.config.js\", \"scripts\": { \"test\": \"echo \\\"Error: no test specified\\\" &amp;&amp; exit 1\", }, \"author\": \"***\", \"license\": \"ISC\", \"repository\": { \"type\": \"git\", \"url\": \"git+https://github.com/***/***.git\" }, \"keywords\": [ \"phoenix\" ], \"bugs\": { \"url\": \"https://github.com/***/***/issues\" }, \"homepage\": \"https://github.com/***/***#readme\"}(3) Webpack 설치 전 설정 추가package.json scripts 섹션에 deploy 스크립트를 추가해야 웹팩을 사용하여 build 할 수 있다. script 섹션 설정을 포함한 다음 코드를 package.json 에 추가한다. \"scripts\": { ..., \"deploy\": \"webpack --mode production\" }Webpack 을 설치할 때, 진입점이 필요하다. assets/src 위치에 index.js 파일을 생성하고 프로젝트에 필요한 기본 JavaScript 코드나 모듈 가져오기(import)를 추가한다.// 예시: assets/src/index.jsimport \"phoenix_html\";// 다른 필요한 JavaScript 코드나 모듈 import(4) Webpack 설정 config 파일 추가assets 디렉토리 내에 webpack.config.js을 생성하고 진입점(entry point)으로 index.js 을 설정해준다. 그 밖에 output, loader 등을 포함하여 다음과 같이 생성한다.const path = require('path');module.exports = { // 진입점 설정 entry: './js/app.js', // 이 경로는 프로젝트에 맞게 조정해야 합니다 // 출력 설정 output: { path: path.resolve(__dirname, '../priv/static/assets'), // 출력 디렉토리 filename: 'app.js', // 출력 파일명 }, // 모듈 설정 module: { rules: [ { test: /\\.js$/, // .js 파일에 대한 처리 exclude: /node_modules/, // node_modules 디렉토리 제외 use: { loader: 'babel-loader', // Babel 로더 사용 options: { presets: ['@babel/preset-env'], // Babel 프리셋 설정 }, }, }, // 추가적인 로더 설정(예: CSS, 이미지 파일 등) ], },};2. Node 모듈 설치 및 Node.js 의존성 설정(1) Node 모듈 설치assets 디렉토리로 이동하여 npm install을 실행한다. 이 명령어는 package.json에 정의된 모든 Node 의존성을 설치한다. Phoenix 프로젝트의 경우,phoenix, phoenix_html, phoenix_live_view 패키지들은 자동으로 package.json에 추가되어 있어야 한다.cd assetsnpm install(2) Node.js 필수 Package 설치- Webpack assets (HTML, CSS, JavaScript 파일, 이미지, 폰트 등 웹 애플리케이션을 구성하는 모든 정적 파일들) 을 bundling (여러 개의 파일을 하나 또는 소수의 파일로 결합하는 과정. 이를 통해 네트워크 요청 최소화, application 최적화, 의존성 관리의 이점이 있음) 하기 위해 필요npm install webpack webpack-cli --save-dev- Babel JavaScript 코드를 변환하기 위한 컴파일러. ES6 이상의 코드를 이전 버전의 JavaScript로 변환하는데 사용.npm install @babel/core @babel/preset-env babel-loader --save-dev- CSS 관련 packageCSS를 처리하기 위해 필요한 패키지들npm install css-loader style-loader mini-css-extract-plugin --save-dev- Tailwind CSSnpm install tailwindcss postcss autoprefixer --save-dev(3) Node.js Package 중 Phoenix LiveView 관련 설치phoenix, phoenix_live_view, phoenix_html package 를 설치하기 전, assets/js/app.js 다음 코드가 없다면 추가해준다.(phoenix_live_view 0.20.1 기준 기본적으로 추가되어 있음.)import \"phoenix_html\";import { Socket } from \"phoenix\";import { LiveSocket } from \"phoenix_live_view\";assets 디렉토리에서 해당 package 를 추가해준다.npm install --save phoenix phoenix_html phoenix_live_view제대로 설치되었다면, 앞에서 설치한 Node.js Package 디렉토리가 assets/node_modules에 생성된다.3. JavaScript 파일 작성앞의 과정에서 사용자 정의 JavaScript 를 사용할 수 있도록 관련 설정을 완료하였으므로, 이제 프로젝트의 assets/js 디렉토리 안에 사용자 정의 JavaScript 파일을 생성 (ex. assets/js/custom.js) 한다.export function toggleButton(btn) { btn.classList.toggle('bg-blue-500'); btn.classList.toggle('bg-gray-600'); if (btn.innerText === 'READY !!') { btn.innerText = 'WAIT ...... '; } else { btn.innerText = 'READY !!'; }}4. Phoenix 프로젝트에 JavaScript 통합(1) app.js에서 사용자 정의 custom.js 가져오기.assets/js/app.js 파일을 열고, 만들어진 custom.js 을 가져올 수 있도록 import 해준다.// assets/js/app.jsimport { toggleButton } from \"./custom\";window.toggleButton = toggleButton;이렇게 하면 customFunction을 전역 변수로 설정하여, HTML에서 접근할 수 있게 된다.(2) Webpack build지금까지의 변경사항을 적용하기 위해 assets 디렉토리에서 npm run deploy를 실행하여 JavaScript 파일을 빌드한다.5. LiveView에서 JavaScript 사용(1) LiveView 템플릿에 스크립트 적용LiveView의 render/1 함수에서 해당 JavaScript 함수를 사용하는 HTML을 반환def render(assigns) do ~H\"\"\" ... ... &lt;button type=\"button\" onclick=\"window.toggleButton(this)\" class=\"text-white bg-blue-500 font-medium rounded-lg text-sm px-5 py-2.5 me-2 mb-2\"&gt; READY !! &lt;/button&gt; ... ... \"\"\"end결론 위 작업이 정상적으로 완료되었다면 의도한대로 사용자 정의 toggle button 이 동작하는 것을 확인 할 수 있다."
    } ,
  
    {
      "title"       : "impl attribute",
      "category"    : "",
      "tags"        : "elixir, impl, attribute",
      "url"         : "./impl_attribute.html",
      "date"        : "2024-01-23 15:32:20 +0900",
      "description" : "impl attribute",
      "content"     : "elixir code 를 작성할 때, behaviour 나 macro 의 callback 의 구현체를 정의하는 구조는 일반 함수와 동일하다. 이를 구별하기 위해 @impl true를 사용하는 것이 좋다. 사용하지 않을 경우, 작업에 문제가 발생하지는 않으나 IDE 나 complier 가 아래 내용의 warning 이 나타날 수 있다.module attribute @impl was not set for function init/1 callback (specified in GenServer). This either means you forgot to add the \"@impl true\" annotation before the definition or that you are accidentally overriding this callback아울러 해당 attribute 를 사용했을 때의 장점은 다음과 같다. 명확성: @impl true는 해당 함수가 특정 행위(behaviour)의 callback 함수임을 명확히 함. 따라서 가독성이 높아질 수 있음. 컴파일러 검증: @impl true를 사용하면 Elixir compiler가 해당 함수가 실제로 지정된 행위의 callback 함수인지를 검증함으로 써, 잘못된 callback 함수일 경우, compile 단계에서 이를 감지할 수 있어짐 문서화: @impl true를 사용하면 ExDoc과 같은 문서화 도구에서 해당 함수가 콜백 함수임을 자동으로 식별하여 문서화할 수 있음. 유지보수 용이성: 코드의 유지보수를 담당하는 다른 개발자들에게 해당 함수의 역할과 중요성을 쉽게 전달할 수 있음. 예시defmodule ImplAttribute do use GenServer ... ... @impl true def init(list) do {:ok, list} end @impl true def handle_call(:view, _from, list) do {:reply, list, list} end ... ...end만약 callback 이 아닌 일반 함수에 해당 attribute 를 사용할 경우 다음과 같은 warning 이 발생한다.defmodule ImplAttribute do use GenServer ... ... @impl true def start_link() do GenServer.start_link(__MODULE__, []) end @impl true def view(pid) do GenServer.call(pid, :view) end ... ...endgot \"@impl true\" for function add/2 but no behaviour specifies such callback. The known callbacks are: ... ...그렇다면 다른 @impl attribute 는?@impl Module: 여기서 Module은 특정 행위를 나타내는 모듈. 이 형식은 함수가 특정 행위의 일부임을 더 명시적으로 나타내는 데 사용된다. 예를 들어, @impl GenServer는 해당 함수가 GenServer 행위의 callback임을 나타낸다.defmodule MyGenServer do use GenServer # Client API def start_link(args) do GenServer.start_link(__MODULE__, args, name: __MODULE__) end def add(pid, value) do GenServer.cast(pid, {:add, value}) end # Server Callbacks @impl GenServer def init(args) do {:ok, args} end @impl GenServer def handle_cast({:add, value}, state) do new_state = state + value {:noreply, new_state} endend@impl GenServer attribute는 init/1 및 handle_cast/2 함수가 GenServer의 callback임을 명시"
    } ,
  
    {
      "title"       : "Elixir GenServer",
      "category"    : "",
      "tags"        : "elixir, genserver, pubsub",
      "url"         : "./genserver.html",
      "date"        : "2024-01-23 10:32:20 +0900",
      "description" : "Elixir GenServer",
      "content"     : "Elixir의 GenServer는 OTP(Open Telecom Platform) behaviour 중 하나로, 서버 프로세스를 구현하기 위한 추상화를 제공한다. GenServer는 클라이언트-서버 관계에서 서버 부분을 담당하며, 상태를 유지하고, 요청을 동기적 또는 비동기적으로 처리할 수 있다. 이는 Elixir/Erlang 시스템에서 병렬처리와 상태 관리를 용이하게 하는 강력한 도구이다.GenServer 의 다양한 macro callback 중 주요한 것을을 사용하여 통신 moudule 을 구현하고자 한다. 해당 module 의 구조는 다음과 같다. module 내 구성은 크게 client 와 server 구현 부분으로 구분 된다. client 는 경우, 해당 module 이 실행되는 application 자체 또는 일부 process 에서 실행될 code 이며, 해당 code 를 통해 server process 를 생성, 동기/비동기 작업 요청 및 응답, 종료 등의 작업을 정의한다.server 부분의 경우, client 작업 요청에 대응하는 작업에 대한 code 를 정의한다. 위에 언급된 GenServer callback 들의 경우, 모두 GenServer behaviour의 구현체이다.client-server 에 각 callback 들에 대해 간단하게 설명하면 다음과 같다. Server 생성 start_link/3: 새로운 GenServer 프로세스를 시작하고 연결 init/1: start_link/3 요청에 의해 GenServer가 시작될 때 호출되며, 초기 상태를 설정 비동기 요청/응답 cast/2: 비동기적 통신에 사용. client 는 server 에 메시지를 보내고 즉시 반환됨. 이 메소드는 서버의 handle_cast/2 callback을 trigger. handle_cast/2: 비동기적 요청을 처리. 클라이언트는 응답을 기다리지 않음. 동기 요청/응답 call/3: 동기적 통신에 사용. client는 server에 요청을 보내고, server가 응답할 때까지 기다리며, server의 handle_call/3s callback을 trigger. handle_call/3: 동기적 요청을 처리하고 그 결과를 clientd에게 응답. Server 종료 stop/3: GenServer 프로세스를 안전하게 종료하기 위해 사용. 이 함수는 종료 이유(ex. 'normal', 'shutdown', 'kill' 등)와 타임아웃(default : 5 sec)을 지정할 수 있으며, 서버의 terminate/2 callback을 trigger. terminate/2: server가 종료되기 전에 호출되는 callback GenServer 프로세스가 정상적으로 종료될 때 호출되며, 종료 전에 필요한 정리 작업(ex.종료되기 전에 상태를 저장하거나 열려 있는 리소스를 닫는 등의 작업 등)을 수행할 수 있습니다. 예제 코드 defmodule ShopingList do use GenServer # ------ client API -------- def start_link() do GenServer.start_link(__MODULE__, []) end def add(pid, item) do GenServer.cast(pid, item) end def view(pid) do GenServer.call(pid, :view) end def remove(pid, item) do GenServer.cast(pid, {:remove, item}) end def stop(pid) do GenServer.stop(pid, :normal, :infinity) end # ----- server callback ----- def init(list) do {:ok, list} end def handle_cast({:remove, item}, list) do updated_list = Enum.reject(list, fn(i) -&gt; i == item end) {:noreply, updated_list} end def handle_cast(item, list) do updated_list = [item|list] {:noreply, updated_list} end def handle_call(:view, _from, list) do {:reply, list, list} end def terminate(_reason, list) do IO.puts(\"This Server is termniated.\") IO.inspect(list) endend실행 결과iex(1)&gt; {:ok, pid} = ShoppingList.start_link(){:ok, #PID&lt;0.422.0&gt;}ShoppingList.start_link() 를 통해 server process 를 생성한다. server 측 init(list) 함수 callback 이 실행되어 server process 를 초기화 하고 그 결과 및 pid 를 client 에게 반환한다.iex(2)&gt; ShoppingList.add(pid, \"eggs\") :okiex(3)&gt; ShoppingList.add(pid, \"milk\") :okiex(4)&gt; ShoppingList.add(pid, \"cheese\") :okiex(5)&gt; ShoppingList.view(pid) [\"cheese\", \"milk\", \"eggs\"]ShoppingList.add(pid, \"eggs\") 등의 함수를 통해 server process 비동기 작업을 요청한다. :ok 응답은 server 작업의 완료와 관계없이 반환된다. handle_cast(item, list)가 작업을 하여 server 자체 list 에 client 가 보낸 메세지를 list 에 추가한다.ShoppingList.view(pid) 를 통해 동기화된 작업을 요청한다. 해당 요청으로 handle_call(:view, _from, list) callback 이 trigger 된다. 해당 callback 반환값 튜플{:reply, list, list}의 각 요소는 다음의 의미를 가진다. :reply: client 에게 동기적으로 응답을 보내야 함을 의미 list: client 에게 보낼 실제 응답 data list: 해당 callback 작업 이후 server 가 가질 dataiex(6)&gt; ShoppingList.remove(pid, \"cheese\") :okiex(7)&gt; ShoppingList.view(pid)[\"milk\", \"eggs\"]ShoppingList.remove(pid, \"cheese\") 의 경우 앞에서 사용한 ShoppingList.add(pid, \"eggs\") 와 동일하게 비동기 작업을 요청하지만 함수 다형성(polymorphism) 을 적용하여 별도로 정의된 handle_cast({:remove, item}, list) callback 을 trigger 한다.iex(8)&gt; ShoppingList.stop(pid) This Server is termniated.[\"milk\", \"eggs\"]:okserver process 을 종료 요청을 보내고 triggering 된 terminate(_reason, list) 작업을 진행하고 해당 process 는 종료된다.Phoenix PubSub 과 GenServer Phoenix PubSub은 내부적으로 GenServer를 사용하여 구축된다. Phoenix PubSub은 Elixir 어플리케이션 내에서 프로세스 간의 메시징을 쉽게 구현할 수 있도록 해주는 시스템입니다. 이는 주로 Phoenix framework 내에서 실시간 웹 기능을 구현하는 데 사용되며, 웹소켓을 통해 client-server 간의 메시지를 효율적으로 교환할 수 있게 해준다. 그 주요 역할은 다음과 같다. 상태 관리: 각 PubSub 서버는 구독 정보와 같은 상태를 유지 관리. 메시지 처리: 발행된 메시지는 GenServer 프로세스를 통해 구독자들에게 전달. 동기화 및 제어: GenServer callback을 통해 메시지 전송 및 구독 관리를 제어.참고 문헌 - ElixirCasts - #12: Intro to GenServer"
    } ,
  
    {
      "title"       : "changeset/2 in Ecto Library",
      "category"    : "",
      "tags"        : "ecto, changeset/2",
      "url"         : "./changeset.html",
      "date"        : "2024-01-15 10:32:20 +0900",
      "description" : "changeset/2 in Ecto Library",
      "content"     : "Phoenix LiveView 에서 DB 처리 작업은 Ecto library 를 사용하여 작업이 진행된다. 이와 관련하여, Ecto 의 기능과 구성요소에 대해 알아보고, 여기에서 changeset/2 함수에 대해 좀더 알아 본다. Ecto 란?Phoenix LiveView 에서 사용하는 Ecto library 는 Elixir 언어를 위한 database wrapper 이다. 주로 Elixir web-framewor 인 Phoenix 와 함께 사용되며, 데이터베이스 상호작용을 효율적으로 만들어 준다.구성요소 Repo (Repository) 데이터베이스와의 모든 상호작용(CRUD)을 처리 데이터베이스에 query를 보내고 결과를 반환 받음 여러 Repo 를 지원 할 수 있어, 다양한 데이터베이스와 동시에 작업 가능 Schema 데이터베이스 table 과 Elixir 구조체 간 mapping 을 정의 각 field 는 Elixir data type 으로 선언됨 schema 는 data 유효성 검사와 제약 조건도 함께 정의함 Changeset data 를 삽입하거나 업데이트하기 전에 데이터를 검증하고 변환하는 역할 유효성 검사, 제약 조건 확인, filtering, 형식 변환 등을 처리 Query Elixir 의 구문을 사용하여 database query 를 생성 또는 사용자 정의 query 구현 가능하도록 함 query 는 Ecto.Query module 을 사용하여 작성됨 query 는 compile 타임에 생성되므로, 효율적인 성능을 발휘함 Ecto 의 특징 Database Adapter : PostgreSQL, MySQL, SQLite 등 다양한 데이터베이스를 지원 Migration : 데이터베이스 schema 변경을 위한 migration 을 쉽게 관리 Transaction: 데이터베이스 transaction을 통해 데이터 일관성을 보장 Multi-Tenancy : 필요한 경우, 동일한 app 내에서 여러 데이터베이스를 다룰 수 있음changset/2changset/2의 역할 cast/3를 사용하여 비 구조체 type 의 user data 를 구조체 형태로 변환하여 Ecto 데이터베이스 schema 와 안전한 상태로 mapping 될 수 있도록 변환 관련 feild 값을 capture 하여 데이터베이스에 저장된 값과 비교, 변경 여부를 확인 현재 작업 중이 값이 유효한지를 검증한다. 변경된 값이 query 를 통해 데이터베이스에 값이 저장 또는 수정되기 전에, 유효성 (field type, 길이, 값의 범위, 존재 여부 등) 을 확인하여 잘못된 형식 또는 잘못된 값이 아닌지를 먼저 판단한다. 해당 과정은 각 field 에 대해 항상 동일한 규칙과 조건을 적용한다. (consistent rule) 유효성 확인의 결과로 :ok 또는 :error 상태를 반환하여 context 가 query 작업을 진행할지 여부에 대한 state 를 제공한다.예제 codedef changeset(product, attrs) do product |&gt; cast(attrs, [:name, :description, :unit_price, :sku]) |&gt; validate_required([:name, :description, :unit_price, :sku]) |&gt; unique_constraint(:sku) |&gt; validate_number(:unit_price, greater_than: 0.0)end cast/3 를 통해 attr key-values 중 product 구조체의 field ([:name, :description, :unit_price, :sku]) 에 해당하는 값이 있는지 확인하고 해당하는 값을 product 구조체로 변환 validate/2, unique_constraint/2, validate_number/2 함수들을 통해 유효성 검사를 진행 최종으로 해당 값이 존재하고, 유효성에 문제가 없으면 :ok 아니면 :error 상태를 반환한다. 참고 문헌 - programming-phoenix-liveview_B10.0"
    } ,
  
    {
      "title"       : "Lazy Collection 과 Stream library",
      "category"    : "",
      "tags"        : "elixir, lazy collection, elixir stream",
      "url"         : "./lazy-collection.html",
      "date"        : "2024-01-07 10:32:20 +0900",
      "description" : "Lazy Collection 과 Stream library",
      "content"     : "Lazy CollectionLazy Colleciton 은 Elixir와 같은 함수형 프로그래밍 언어에서 중요한 개념 중 하나로 데이터가 실제로 필요할 때까지 그 처리를 연기하는 방식으로 작동한다. 이 방식은 특히 대용량 데이터를 다룰 때 메모리 사용을 최소화하고 성능을 향상시킬 수 있다.stream = Stream.map(1..10000, &amp;(&amp;1 * &amp;1))이 코드는 1부터 10,000까지의 숫자 각각에 대해 제곱을 하는 스트림을 생성한다. 그러나 실제 제곱 연산은 스트림을 열거하는 시점, 예를 들어 Enum.to_list(stream)을 호출할 때까지 수행되지 않는다.특징비동기 처리: lazy collection은 데이터의 전체 집합을 메모리에 한 번에 로드하지 않는다. 대신, 요소들은 필요할 때, 즉 실제로 열거(enumerate)하거나 접근할 때 처리된다.효율성: lazy collection은 메모리 사용을 최적화한다. 큰 데이터셋을 한 번에 처리하는 대신, 작은 조각으로 나누어 필요한 부분만 처리한다. 이는 특히 파일 읽기, 외부 API 호출, 대규모 계산과 같은 상황에서 유용하다.Function Chaining: lazy collection은 여러 함수를 연결(chaining)하여 복잡한 데이터 처리 파이프라인을 구축할 수 있다. 각 함수는 이전 함수의 출력을 입력으로 받아 처리한다.(아래 보충 설명 참조)Stream Module: Elixir에서 lazy collection을 구현하는 데 사용되는 주요 모듈은 Stream이다. Stream 모듈은 다양한 지연 처리 함수를 제공한다. 예를 들어, Stream.map/2은 컬렉션의 각 요소에 주어진 함수를 적용하지만, 실제 계산은 스트림을 열거할 때까지 연기된다.즉시 연산 vs 지연 연산아래 두 예제의 경우, 반환값은 동일하지만, 아래와 같이 다른 기능적 특징을 가진다.Stream.map(1..10000, &amp;(&amp;1 * &amp;1))지연 연산: Stream.map은 연산을 즉시 수행하지 않고, 각 요소에 대한 연산을 정의하는 스트림을 반환한다. 이 스트림은 실제로 열거되기 전까지는 어떤 연산도 수행하지 않는다.메모리 효율성: 큰 데이터셋을 처리할 때 Stream.map은 모든 요소를 한 번에 메모리에 로드하지 않는다. 대신, 스트림을 열거할 때 각 요소를 개별적으로 처리한다. 이는 대규모 데이터셋을 다룰 때 메모리 사용을 최소화한다.적용 예: 위 code 에서 Enum.to_list(stream) 또는 다른 Enum 함수를 사용하여 스트림을 열거할 때까지 실제 연산이 연기된다.Enum.map(1..10000, &amp;(&amp;1 * &amp;1))즉시 연산: Enum.map은 함수가 호출되는 즉시 모든 요소에 대해 연산을 수행한다. 연산 결과는 즉시 계산되고 반환된다.메모리 사용: 이 방식은 연산을 수행한 전체 결과를 메모리에 저장한다. 큰 데이터셋을 처리할 경우, 이는 상당한 양의 메모리를 사용할 수 있다.적용 예: 연산 결과가 즉시 필요하고 데이터셋이 메모리에 들어갈 수 있을 정도로 작을 때 유용.*****Function Chaining 상태에서의 Lazy Collection앞에서 관련 장점을 설명했으나, 다양한 함수를 연속적으로 사용하는 function chaining 에서 항상 해당 장점이 발휘되는 것은 아니다.예를 들면,1..10000|&gt; Enum.map(&amp;(&amp;1 * 2))|&gt; Stream.filter(&amp;(&amp;1 &lt; 100))|&gt; Enum.to_list()의 처리 과정을 보면,chaining 과정에서 Stream 모듈의 함수 뒤에 Enum 모듈의 함수가 오면, 스트림에 대한 모든 연산이 Enum 함수 호출 시점에 즉시 수행된다. 이는 Enum 함수가 실제 데이터를 필요로 하기 때문이다.반대로, Enum 함수 다음에 Stream 함수가 오면, Enum 함수는 즉시 실행되고, 그 결과는 Stream 함수에 의해 다시 지연 처리된다.이 경우, Enum.map은 즉시 모든 요소에 대해 연산을 수행한다. 이어서 Stream.filter는 지연 처리 스트림을 생성하지만, 최종적으로 Enum.to_list에 의해 이 스트림이 즉시 열거되어 모든 데이터 처리가 완료된다.결론적으로, 예제에서 Stream.filter(&amp;(&amp;1 &lt; 100))는 결국 체인의 마지막에 있는 Enum.to_list() 함수 때문에 즉시 연산 처리된다.chaining된 함수들 중 하나라도 즉시 연산을 수행하는 Enum 모듈의 함수를 포함하고 있고, 이것이 체인의 마지막에 위치한다면, 체인의 모든 연산은 결국 즉시 수행된다. 이는 Enum 모듈의 함수가 실제 데이터를 필요로 하기 때문에, 지연된 연산들도 강제로 실행되어 결과를 산출한다.*****"
    } ,
  
    {
      "title"       : "Elixir 의 Map, Struct 등은 왜 immutable data types 인가?",
      "category"    : "",
      "tags"        : "elixir, map, struct, immutable data type",
      "url"         : "./immutable-data-type.html",
      "date"        : "2024-01-03 10:32:20 +0900",
      "description" : "Elixir 의 immutable data types (Map, Struct)",
      "content"     : "Elixir 에서 Map 은 immutable type 이다. 따라서 Map.delete/2, Map.put/3, Map.update/4 등과 같은 함수는 실제로 기존 map data 를 수정하는 것이 아니라, 수정되된 값으로 새로운 map data 를 만들고 이것을 재할당 하는 것이다.Struct 의 경우도, 한번 생성된 instance 의 내부 field 값을 변경하고자 하는 경우, 이는 수정이 아닌, 새로운 data 생성 및 이를 재할당 하는 것이다. 그런데 list, map 과 같이 많은 데이터를 포함하고 있는 경우, 그중 하나의 값이 바뀔 때마다 매번 모든 부분에 대한 재할당을 진행한다면, 메모리 사용이나 성능상 단점이 매 커보인다.그렇다면, immutable data type 으로 처리할 때 어떤 이점이 있을 수 있으며, 예상되는 문제점은 어떻게 해결할까?구조적 공유(Structural Sharing): 변경 불가능한 데이터 구조에서는 종종 구조적 공유 작업이 필요하다. 즉, 새로운 맵을 생성할 때 전체 구조를 복사하는 대신, 변경되지 않은 부분은 기존 구조를 재사용하여 필요한 메모리 양과 복사 작업이 크게 줄인다. (결국 immutable data type 이라도 매번 모든 data 에 대한 memory 할당 및 쓰기 작업이 진행되지는 않는다.)예측 가능성과 안정성: 데이터의 불변성은 함수의 부작용을 줄여준다. 이는 프로그램의 동작을 예측하기 쉽게 만들고, 디버깅과 유지보수를 용이하게 한다. 병렬 처리: 데이터가 변경 불가능하면 여러 스레드나 프로세스에서 동시에 데이터에 접근해도 안전하므로, 병렬 처리와 동시성 프로그래밍에서 큰 이점을 제공한다.최적화: 현대의 가비지 컬렉션(GC) 시스템은 변경 불가능한 데이터 구조를 효율적으로 처리할 수 있도록 설계되어 있다. 따라서 새로운 구조를 생성하는 오버헤드는 종종 생각보다 작다."
    } ,
  
    {
      "title"       : "slot attribute 사용",
      "category"    : "",
      "tags"        : "phoenix, liveview, slop",
      "url"         : "./phoenix-slot.html",
      "date"        : "2024-01-01 10:32:20 +0900",
      "description" : "slot attribute 사용",
      "content"     : "Phoenix LiveView 에서 동적인 component 를 삽입 하고자 하는 경우, 해당 component attribute 로 `slot` 을 정의하고 이를 사용해 주어야 한다. 사용 방법slot :블록명, required: truedef 컴포넌트명(assigns) do ~H\"\"\" &lt;동적으로 구현할 컴포넌트 태그&gt; &lt;&gt;..사용자 구현...&lt;&gt; &lt;%= render_slot(@블록명) %&gt; &lt;/동적으로 구현할 컴포넌트 태그&gt; \"\"\"end Slot 정의slot :블록명 : 컴포넌트 내부에 동적으로 콘텐츠를 삽입할 수 있는 블록명이라는 이름의 슬롯을 정의.required: true: 이 슬롯이 반드시 제공되어야 함을 의미. 이 컴포넌트를 사용할 때는 블록명 슬롯에 대한 내용을 제공해야 한다.컴포넌트 정의def 컴포넌트명(assigns) do ... end : 컴포넌트를 정의하는 함수. 이 함수 내에서 HTML 태그와 Elixir의 템플릿 언어를 사용하여 컴포넌트의 구조를 정의한다.동적 콘텐츠의 삽입 위치&lt;%= render_slot(@블록명) %&gt; : 구문은 정의된 블록명 슬롯에 전달된 콘텐츠를 해당 위치에 렌더링.이 위치는 \"동적으로 구현할 컴포넌트 태그\" 내부로 이 태그 안에서 블록명 슬롯에 제공된 콘텐츠가 렌더링됨.사용자 구현사용자는 이 컴포넌트를 사용할 때 블록명 슬롯에 원하는 콘텐츠를 제공할 수 있다. 이 콘텐츠는 다양한 HTML 요소, 다른 LiveView 컴포넌트, 또는 동적인 데이터를 포함할 수 있다.실제 코드 예시attr :view_box, :stringslot :inner_block, required: truedef canvas(assigns) do ~H\"\"\" &lt;svg viewBox={ @view_box }&gt; &lt;defs&gt; &lt;%!-- 위에 정의된 point component 사용하여 정사각형 생성 --%&gt; &lt;rect id=\"point\" width=\"10\" height=\"10\" /&gt; &lt;/defs&gt; &lt;%= render_slot(@inner_block) %&gt; &lt;/svg&gt; \"\"\"end"
    } ,
  
    {
      "title"       : "Elixir - intance 생성",
      "category"    : "",
      "tags"        : "elixir, instance, struct",
      "url"         : "./create-instance.html",
      "date"        : "2023-12-29 13:32:20 +0900",
      "description" : "Elixir - intance 생성",
      "content"     : "Elixir 문범에서 struct 에 대한 instace를 생성하는 방법은 아래와 같이 두가지가 존재한다. (ChatGPT 가 설명한 그 용도의 차이점에 대해서.. 아직 잘 모르겠다. 내눈에는 그냥 동일한 용도로 사용되는 것 처럼 보인다. ;;)__MODULE__ 사용사용법: %__MODULE__{} 구문은 주로 모듈 내부에서 해당 모듈의 구조체 인스턴스를 생성할 때 사용. 이 경우, 모듈 내부에서 직접 %__MODULE__{field1: value1, field2: value2}와 같이 구조체 인스턴스를 생성할 수 있다.예시: 모듈 내부에서 def new() 함수를 정의하고, 이 함수 안에서 %__MODULE__{}를 사용하여 인스턴스를 생성할 수 있다.def new(field \\\\ []), do: __struct__(field) 정의사용법: 이 방법은 모듈 외부에서 인스턴스를 생성할 때 사용합니다. 여기서 new 함수는 외부에서 호출할 수 있는 공개 인터페이스를 제공하고, __struct__ 호출을 통해 내부적으로 구조체 인스턴스를 생성한다.예시: 다른 모듈에서 ModuleName.new(field_values)를 호출하여 구조체 인스턴스를 생성할 수 있다. 여기서 field_values는 인스턴스의 필드를 초기화하기 위해 사용됨.결론두 방식 모두 Elixir에서 구조체 인스턴스를 생성하는 방법. __MODULE__ 방식은 주로 모듈 내부에서 사용되며, def new(field \\\\ []), do: __struct__(field) 방식은 모듈 외부에서 구조체 인스턴스를 생성할 때 사용되는 공개 함수를 제공한다. 두 경우 모두, 모듈명.new(field 값)과 같은 형태로 호출하여 인스턴스를 생성할 수 있다."
    } ,
  
    {
      "title"       : "struct - instance 에 대해 (Elixir vs OOP languages)",
      "category"    : "",
      "tags"        : "oop, instance, struct, phoenix, liveview, elixir",
      "url"         : "./instance-with-elixir.html",
      "date"        : "2023-12-29 10:32:20 +0900",
      "description" : "struct - instance 에 대해 (Elixir vs OOP languages)",
      "content"     : "elixir 에서의 구조체는 상속, 다형성 등이 지원되지 않고 한번 정의되면 구조체 내부 field 값을 변경할 수 없는, 내부에 field 가 존재하는 사용자 정의 type 이며, 해당 구조체 type 에 실제 data 를 가지게 하고 이를 변수 매칭 시킨것이 elixir instance 이다. 유사점데이터 캡슐화: Elixir의 구조체와 Java나 Python의 인스턴스 모두 데이터를 캡슐화. 여러 데이터를 하나의 구조로 묶어 관리할 수 있다.필드 정의: 두 언어에서는 자료구조에 필드(데이터 요소)를 정의할 수 있으며, 이러한 필드는 각각의 자료구조에 속한 정보를 나타냄.타입 안정성: Elixir의 구조체와 Java의 객체는 둘 다 특정 타입에 속하는 데이터를 담는데, 이는 데이터 타입에 대한 안정성과 예측 가능성을 제공.차이점불변성(Immutability) vs 가변성(Mutability): Elixir의 구조체는 불변성을 가짐. 한 번 생성되면 그 상태를 변경할 수 없음. 반면, Java나 Python의 객체는 가변적이며, 객체의 상태(필드 값 등)를 변경할 수 있음.함수형 vs 객체지향: Elixir는 함수형 프로그래밍 패러다임을 따르기 때문에, 데이터와 함수가 분리되어 있음. 구조체는 단지 데이터를 담는 용도로 사용되며, 모든 작업은 순수 함수를 통해 처리됨. 반면, Java나 Python에서는 객체가 데이터와 그 데이터를 조작하는 메소드를 모두 포함.상속과 다형성: Java나 Python에서는 클래스 상속과 다형성이 중요한 특징으로 객체는 부모 클래스의 속성과 메소드를 상속받을 수 있으며, 인터페이스나 추상 클래스를 통해 다형성을 구현할 수 있음. 반면, Elixir의 구조체는 이런 상속 메커니즘이나 다형성을 지원하지 않음.메소드와 함수: Java나 Python에서 객체는 자신의 메소드를 가지고 있으며, 이를 통해 객체의 상태를 변경하거나 정보를 얻을 수 있음. Elixir에서는 모든 작업이 함수를 통해 이루어지며, 이 함수들은 구조체의 데이터에 대한 연산을 수행하지만, 구조체 내부에 정의되지 않음.결론Elixir의 구조체는 Java나 Python의 객체와 유사하게 데이터를 캡슐화하는 역할을 하지만, 불변성, 함수형 패러다임, 상속 및 다형성 부재, 메소드와 함수의 차이라는 측면에서 분명한 차이점이 있다. 이러한 차이점들은 Elixir가 가진 함수형 프로그래밍의 특징을 반영한다."
    } ,
  
    {
      "title"       : "tail recursion",
      "category"    : "",
      "tags"        : "tail recursion, elixir",
      "url"         : "./tail-recursion.html",
      "date"        : "2023-12-27 15:32:20 +0900",
      "description" : "tail recursion",
      "content"     : "일반 재귀 (Regular Recursion) 예제defmodule RegularRecursion do def sum([]), do: 0 def sum([head | tail]), do: head + sum(tail)end이 예제에서 `sum/1` 함수는 리스트의 첫 번째 요소를 취하고, 나머지 리스트에 대해 재귀적으로 `sum/1`을 호출한 다음, 결과에 첫 번째 요소를 더한다. 여기서 중요한 점은 재귀 호출 후에 추가 작업(더하기)이 수행된다는 것.꼬리 재귀 (Tail Recursion) 예제다음 예제에서 `sum/2` 보조 함수는 누적된 합계를 유지하면서 재귀적으로 호출된다. 각 재귀 호출은 누적된 합계에 현재 요소를 더한 값과 함께 호출되며, 이는 꼬리 호출 최적화를 가능하게 한다.defmodule TailRecursion do def sum(list), do: sum(list, 0) defp sum([], total), do: total defp sum([head | tail], total) do sum(tail, head + total) endend차이점일반 재귀에서는 각 재귀 호출 후에 추가적인 계산 필요(예: head + sum(tail)).꼬리 재귀에서는 재귀 호출이 함수의 마지막 연산이며, 추가 계산이 없음(예: sum(tail, head + total)).일반 재귀는 호출 스택에 각 호출의 컨텍스트를 저장해야 하므로 메모리 사용이 더 많고, 깊은 재귀에서 스택 오버플로우를 일으킬 수 있다. 반면, 꼬리 재귀는 최적화를 통해 이러한 문제를 피할 수 있으며, 깊은 재귀 호출에서도 효율적으로 작동한다.(Regular) Recursion vs Tail Recursion - 성능 &amp; stack 사용 비교 꼬리 재귀 (Tail Recursion)Elixir에서 꼬리 재귀는 꼬리 호출 최적화(Tail-Call Optimization, TCO)라는 기술을 통해 최적화된다. 꼬리 재귀 함수에서는 재귀 호출이 함수의 마지막 작업으로, Elixir 컴파일러가 현재의 스택 프레임을 재사용할 수 있게 한다. 이러한 최적화는 새로운 스택 프레임을 추가하는 대신 현재의 프레임을 재사용함으로써 메모리 사용량을 최소화한다. 대규모 작업이나 대량의 데이터 처리에 특히 메모리 효율이 좋으며, 스택 오버플로우 위험을 피할 수 있다.일반 재귀 (Regular Recursion)반면, Elixir에서 일반 재귀는 각 함수 호출마다 새로운 스택 프레임을 추가한다. 이는 특히 깊은 재귀 또는 큰 리스트를 다룰 때 메모리 사용량을 증가시킬 수 있으며, 각 재귀 호출이 자체 스택 프레임을 요구하기 때문에 성능 문제나 극단적인 경우 스택 오버플로우를 일으킬 수 있다.성능적 영향일반적으로 꼬리 재귀는 Elixir에서 더 빠르고 메모리 효율적이며, 특히 리스트 축소나 대규모 데이터 처리에 유리하다. 하지만 모든 경우에 꼬리 재귀가 우월한 것은 아니다. 특정 상황, 특히 함수가 리스트를 축소하지 않고 단순히 매핑하는 경우, 일반 재귀가 더 효율적일 수 있다. 예를 들어, 리스트의 숫자를 두 배로 하는 함수는 일반 재귀를 사용하는 것이 더 빠를 수 있다.다른 언어의 logic 처리 (iteration) 과 Tail Recursion 비교Elixir에서 꼬리 재귀를 사용하는 것이 다른 언어에서의 일반적인 반복문(iteration)을 사용하는 것과 유사한 수준의 성능과 메모리 사용을 제공할 수 있다. 꼬리 재귀의 주요 장점 중 하나는 꼬리 호출 최적화(tail-call optimization, TCO)로 인해 메모리 사용이 최소화된다는 것. 이 최적화는 재귀 호출 시 새로운 스택 프레임을 생성하는 대신 현재 스택 프레임을 재사용하게 해, 깊은 재귀 호출에서도 스택 오버플로우 위험을 줄여준다.꼬리 재귀와 반복문의 성능 비교메모리 사용량: 꼬리 재귀를 사용하는 Elixir 함수는 일반 반복문을 사용하는 다른 언어의 함수들과 유사하게, 낮은 메모리 사용량을 가질 수 있다. 각 재귀 호출이 새로운 스택 프레임을 추가하지 않기 때문에, 깊은 재귀 수준에서도 메모리 사용량이 제한적이다. 성능: 꼬리 재귀 최적화 덕분에 Elixir의 꼬리 재귀 함수는 일반 반복문을 사용하는 함수들과 비슷한 성능을 낼 수 있다. 반복문은 일반적으로 CPU 사이클을 덜 사용하고, 반복 로직이 명시적이기 때문에 일부 경우에서 더 효율적일 수 있다. 하지만 꼬리 재귀는 이러한 성능 차이를 상당 부분 줄일 수 있다."
    } ,
  
    {
      "title"       : "Phoenix Presence (by ChatGPT)",
      "category"    : "",
      "tags"        : "phoenix presence, phoenix, liveview",
      "url"         : "./phoenix-presence.html",
      "date"        : "2023-12-26 10:32:20 +0900",
      "description" : "Phoenix Presence (by ChatGPT)",
      "content"     : "Phoenix Presence는 Elixir 언어를 사용하는 Phoenix 프레임워크의 한 부분으로, 실시간으로 사용자의 연결 상태를 추적하고 관리하는 기능을 제공합니다. 이 기능은 주로 채팅 애플리케이션, 게임, 라이브 이벤트 등에서 유용하게 사용됩니다.Phoenix Presence의 핵심은 분산 시스템에서도 사용자의 현재 상태를 효과적으로 관리할 수 있다는 점입니다. 이를 위해, Phoenix는 CRDT(Conflict-Free Replicated Data Type)라는 데이터 타입을 사용하여 네트워크의 다양한 노드 간에 사용자 상태 정보를 동기화합니다. 이를 통해 서버 간의 일관성을 유지하면서도, 네트워크 분할이나 다른 이슈들이 발생해도 사용자의 상태를 정확하게 추적할 수 있습니다.Phoenix Presence를 사용하면 어떤 사용자가 온라인인지, 어느 채널에 있는지 등의 정보를 실시간으로 확인할 수 있습니다. 또한, 이 기능은 Elixir의 가벼운 프로세스와 메시지 전달 시스템을 활용하여 높은 성능을 제공합니다. 따라서 많은 수의 사용자가 동시에 접속하는 환경에서도 안정적으로 작동합니다.Phoenix Presence를 활용하면 다음과 같은 기능을 구현할 수 있습니다사용자가 어떤 채널에 접속했는지 실시간으로 보여주기.사용자의 상태 변화(예: 온라인, 오프라인, 바쁨 등)를 추적하여 다른 사용자에게 알려주기.게임이나 다른 실시간 애플리케이션에서 사용자간의 상호 작용을 촉진하기.이 기능을 활용하려면, Phoenix 프레임워크에 대한 이해뿐만 아니라, Elixir의 동시성과 분산 시스템에 대한 지식도 필요합니다. 이미 Elixir를 공부하고 계신다면, Phoenix Presence는 백엔드 엔지니어로서의 여러분의 역량을 한층 더 향상시킬 수 있는 좋은 도구가 될 것입니다.CRDT(Conflict-Free Replicated Data Type) (by ChatGPT)CRDT(Conflict-Free Replicated Data Type)는 분산 시스템에서 데이터의 일관성을 유지하는 데 사용되는 데이터 타입입니다. 이 기술의 주요 목표는 네트워크의 다른 노드에서 동일한 데이터를 독립적으로 업데이트하고, 나중에 이러한 변경 사항들을 합쳐도 데이터의 일관성을 보장하는 것입니다.CRDT의 특징:Conflict-Free: CRDT는 다수의 노드에서 동시에 발생하는 업데이트 사이의 충돌을 자동으로 해결합니다. 이는 각 노드가 네트워크의 다른 부분과 일시적으로 연결이 끊겨도 안정적으로 작동할 수 있게 해줍니다.Replicated: 데이터는 네트워크 내의 여러 노드에 복제됩니다. 이는 각 노드가 로컬 데이터에 대해 독립적으로 작업할 수 있게 하며, 네트워크 연결이 복구되면 변경 사항을 다시 합칩니다.Data Types: CRDT는 다양한 데이터 타입을 지원합니다, 예를 들어 세트(set), 카운터(counter), 맵(map) 등이 있으며, 이러한 데이터 타입들은 분산 시스템에서 자동으로 동기화됩니다.실시간 트래픽 관리에 대한 CRDT의 기여:고가용성 및 내결함성: CRDT는 네트워크 장애나 일부 노드의 실패에도 불구하고 데이터의 가용성과 일관성을 유지합니다. 이는 실시간 트래픽이 많은 애플리케이션에서 중요합니다.실시간 데이터 동기화: 실시간 애플리케이션에서 사용자 상태나 메시지와 같은 정보는 여러 노드에 걸쳐 신속하게 동기화되어야 합니다. CRDT는 이러한 실시간 동기화를 자연스럽게 지원합니다.탄력적인 트래픽 관리: 분산 시스템에서 트래픽 부하가 한 노드에서 다른 노드로 이동할 수 있습니다. CRDT를 사용하면, 이러한 부하 이동이 데이터 일관성에 영향을 미치지 않습니다.확장성: CRDT는 시스템이 확장됨에 따라 새로운 노드를 쉽게 추가할 수 있게 해주며, 데이터의 일관성을 유지하면서도 시스템의 확장성을 지원합니다.CRDT는 Phoenix Presence와 같은 실시간 애플리케이션에서 사용자의 상태를 관리하는 데 매우 유용합니다. 사용자가 여러 노드에 걸쳐 있거나, 네트워크 상태가 변동적일 때도, 사용자의 상태(예: 온라인, 오프라인)는 모든 노드에 걸쳐 일관성 있게 유지됩니다.* CRDT 학습 자료 : CRDT Resources - crdt.tech."
    } ,
  
    {
      "title"       : "복합 쿼리를 데이터베이스에 실행할 때 발생하는 과정",
      "category"    : "",
      "tags"        : "complex query, database, phoenix, liveview",
      "url"         : "./complex-query.html",
      "date"        : "2023-12-24 13:32:20 +0900",
      "description" : "복합 쿼리의 logic 실행은 client 측에서 진행되는가, 아니면 database server 측에서 진행되는가?",
      "content"     : "복합 쿼리의 logic 실행은 client 측에서 진행되는가, 아니면 database server 측에서 진행되는가?복합 쿼리를 데이터베이스에 실행할 때 발생하는 과정은 다음과 같다.쿼리의 구성: 클라이언트 측(여기서는 Elixir/Ecto를 사용하는 서버)에서 Ecto 쿼리를 작성하고, 이는 SQL 쿼리로 변환된다. 이 변환 과정은 Ecto가 처리하며, 작성된 Ecto 쿼리를 데이터베이스가 이해할 수 있는 SQL 쿼리로 변환한다.SQL 쿼리의 전송: 변환된 SQL 쿼리는 데이터베이스 서버로 전송. 이 때, 클라이언트 측에서는 복잡한 로직을 처리하지 않고, 데이터베이스에 대한 쿼리 요청만 전송한다.데이터베이스의 처리: 데이터베이스 서버에서는 받은 SQL 쿼리를 실행. 데이터베이스 관리 시스템(DBMS)은 쿼리를 분석하고 최적화하여 적절한 방식으로 데이터를 검색한다.결과의 반환: 데이터베이스는 쿼리 결과를 클라이언트 측으로 다시 보냄. 이 결과는 요청된 조건과 매칭되는 데이터를 포함한다.복합 쿼리의 처리클라이언트 측 로직: 클라이언트는 쿼리를 구성하고 최적화하는 로직을 처리하지 않는다. 클라이언트의 역할은 적절한 쿼리를 작성하고 요청하는 것.데이터베이스 측 최적화: 실제 쿼리의 실행과 최적화는 데이터베이스 서버에서 처리됨. 데이터베이스는 쿼리 플랜을 생성하고 실행하여, 요청된 작업을 최적화된 방식으로 처리한다.요약따라서, 복합 쿼리의 로직 처리와 최적화는 주로 데이터베이스 서버에서 이루어지며, 클라이언트 측에서는 쿼리를 작성하고 요청하는 역할을 한다. 이 과정은 데이터베이스 시스템의 성능과 효율성을 보장하기 위해 필요하다.대용량 서비스에 구현에서의 Database 병목 발생과 복합 쿼리의 관계대용량 데이터베이스 서버 환경에서는 데이터베이스 서버의 처리 능력에 한계가 있으며, 이는 종종 시스템의 병목 지점이 될 수 있다. 복잡한 쿼리 로직의 처리가 데이터베이스 서버에서 이루어지는 것은 사실이지만, 이는 서비스 운영 측면에서 효율성에 영향을 미칠 수 있다. 이에 대해 몇 가지 중요한 점을 고려해볼 필요가 있다데이터베이스 서버의 병목 현상대용량 처리: 대규모 데이터와 복잡한 쿼리는 데이터베이스 서버에 상당한 부하를 주고, 성능 저하의 원인이 될 수 있다.자원 관리: 데이터베이스 서버는 한정된 자원(메모리, CPU)을 사용하기 때문에, 효율적인 쿼리 최적화와 자원 관리가 필수적.대용량 서비스에 구현에서의 Database 병목 발생과 복합 쿼리의 관계쿼리 최적화: 클라이언트 측에서 쿼리를 가능한 한 효율적으로 작성하는 것이 중요. 불필요한 데이터 로드를 피하고, 필요한 데이터만 정확히 요청하는 것이 중요하다.로드 분산: 데이터베이스에 가해지는 부하를 줄이기 위해 캐싱, 읽기 전용 복제본 사용, 데이터 분할 등의 전략을 사용할 수 있다.서비스 운영 측면에서의 고려사항스케일링: 데이터베이스 서버의 성능을 향상시키기 위해 하드웨어 스케일업(더 강력한 서버 사용), 스케일아웃(여러 서버로 작업 분산).쿼리 성능 분석: 정기적인 쿼리 성능 분석과 최적화를 통해 데이터베이스 서버의 부하를 관리.비즈니스 로직과 데이터베이스 로직의 분리: 가능하면 복잡한 비즈니스 로직을 애플리케이션 레벨에서 처리하고, 데이터베이스는 데이터 저장과 간단한 조회에 집중하게 하는 것이 바람직할 수 있다.결론데이터베이스 서버에서의 복잡한 쿼리 처리는 효율성을 저해할 수 있으며, 이를 관리하기 위해서는 쿼리 최적화, 적절한 인프라 선택, 그리고 애플리케이션 설계의 최적화가 필요. 이러한 전략들은 서비스의 규모와 요구사항에 따라 달라질 수 있다."
    } ,
  
    {
      "title"       : "Open-Closed Principle (OCP)",
      "category"    : "",
      "tags"        : "elixir, polymorphism, open-closed principle, overloading, behaviour",
      "url"         : "./open-closed-principal.html",
      "date"        : "2023-12-21 10:32:20 +0900",
      "description" : "Open-Closed Principle (OCP)",
      "content"     : "Elixir에서 오픈-클로즈드 원칙(Open-Closed Principle, OCP)은 소프트웨어 엔지니어링의 SOLID 원칙 중 하나로, 클래스, 모듈, 함수 등이 확장에는 열려 있으나, 수정에는 닫혀 있어야 한다는 개념. 이 원칙의 목적은 기존의 코드를 변경하지 않으면서도 시스템의 기능을 확장할 수 있게 하는 것이다.Elixir는 함수형 언어이며, 모듈과 함수를 사용하여 이 원칙을 적용할 수 있다. Elixir에서 OCP를 적용하는 몇 가지 방법은 다음과 같다:1. 다형성(Polymorphism)을 사용하는 방법Elixir에서는 프로토콜(Protocol)을 사용하여 다형성을 구현할 수 있다. 프로토콜은 서로 다른 데이터 타입에 대해 동일한 인터페이스를 제공하며, 새로운 타입을 추가할 때 기존 코드를 변경하지 않고도 기능을 확장할 수 있다.아래 예제와 같이 `great/1` 의 경우, 모두 동일한 parameter 갯수를 갖지만 각각 type 이 다르므로 각각 함수 요청을 구분하여, 해당 함수가 실행되도록 한다.defmodule PolymorphismExample do # 인자가 맵이고 키 :name을 가진 경우 def greet(%{name: name}), do: \"Hello, #{name}!\" # 인자가 문자열일 경우 def greet(name) when is_binary(name), do: \"Hello, #{name}!\" # 위의 경우에 모두 해당하지 않을 때 def greet(_), do: \"Hello, there!\" end2. 함수 오버로딩함수 오버로딩을 통해 같은 이름의 함수에 대해 다양한 패턴을 정의할 수 있다. 이를 통해 새로운 경우를 처리하기 위해 기존 함수를 수정하는 대신 새로운 함수 정의를 추가할 수 있다.다음의 경우, parameter 갯수가 다름에 따라 각 함수는 구분되어진다.defmodule OverloadingExample do def sum(a, b), do: a + b # 두 개의 인자를 받는 함수 def sum(list) when is_list(list), do: Enum.sum(list) # 리스트를 인자로 받는 함수end3. 행위(Behaviour)를 정의하는 방법Elixir에서는 행위(behaviour)를 정의하여 모듈이 특정 콜백을 구현하도록 할 수 있다. **(아직 이해가 부족하므로 추가 학습 필요)** 이를 통해 동일한 인터페이스를 가진 다양한 구현을 제공할 수 있으며, 새로운 구현을 추가해도 기존 모듈을 수정할 필요가 없다.****** Behaviour 에 대하여Elixir 는 함수형 언어이므로 JAVA, 나 Python 과 같은 객체에 대한 개념이 존재 하지 않으므로, 상속 또한 존재하지 않는다. 그러나 약간 유사하게 동일한 함수 signiture 를 정의하여, 이를 필요한 상황에 맞춰 callback 함수를 구현할 수 있는 기능이 있으며, 이것이 곧 behaviour 이다. (OOP 에서 부모 객체 'animal' 에서 울음소리에 대한 함수를 구현하고, 자식 객체 'cat', 'dog' 에서 각각 함수를 상속 받아 내용을 다르게 구현하는 것과 유사한 기능을 사용할 수 있음.)아래의 예제를 보면, defmodule Worker do @callback work(data :: any) :: String.t()enddefmodule FileWorker do @behaviour Worker def work(data) do \"Processing file: #{data}\" endenddefmodule DatabaseWorker do @behaviour Worker def work(data) do \"Processing database entry: #{data}\" endend `Worker` module 에서 `work/1` callback 함수를 정의한다. 이 때, 함수명, parameter &amp; return type 에 대해서만 정의한다.그리고 함수의 내용은 다른 module 에서 해당 함수를 필요할 때, `@behaviour Worker` 로 callback 을 정의 하고, 함수를 구현하여 사용하므로, 각 module 에서 필요한 logic 을 맞추어 사용할 수 있다. [공식 문서 behaviour 설명] *****4. 컨피규레이션을 통한 확장(추후학습 예정)시스템을 구성하는 요소들을 컨피규레이션을 통해 정의하고, 새로운 구성 요소를 추가하여 기능을 확장할 수 있다.(아직 이해가 부족하므로 추가 학습 필요) 이 방법은 기존 시스템의 코드를 변경하지 않고도 새로운 기능을 추가할 수 있게 한다.결론오픈-클로즈드 원칙을 적용하면, 시스템의 유지보수성과 확장성이 향상되며, 기존 코드의 안정성을 유지하면서 새로운 기능을 추가할 수 있다."
    } ,
  
    {
      "title"       : "LiveView preload/1 에 대해",
      "category"    : "",
      "tags"        : "preload/1, phoenix, liveview",
      "url"         : "./preload.html",
      "date"        : "2023-12-20 13:32:20 +0900",
      "description" : "LiveView - preload/1",
      "content"     : "Consider the preload/1 Callback (by ChatGPT)live_component/1이 처음 호출될 때, LiveView는 일반적으로 mount/1, update/2, 그리고 render/1 콜백을 순서대로 호출합니다. 하지만 이 콜백들만으로는 충분하지 않은 상황이 발생할 수 있습니다. 특히, 성능 문제, 예를 들어 N + 1 문제를 방지하기 위해 preload/1이라는 추가 콜백이 필요할 수 있습니다.N + 1 문제란? 이는 데이터베이스 쿼리와 관련된 성능 문제로, 한 번의 큰 쿼리 대신 작은 쿼리가 여러 번 발생하여 전체적인 성능이 저하되는 현상을 말합니다.preload/1 콜백은 mount/1이나 render/1 전에 호출됩니다. 이렇게 함으로써 필요한 데이터를 사전에 로드하고, 성능 저하를 방지할 수 있습니다.마운트/렌더 워크플로우의 경우, LiveView는 preload/1을 호출한 다음, mount/1, update/2, 그리고 마지막으로 render/1을 호출합니다.변경 관리 워크플로우에서는 mount/1은 생략되지만, preload/1, update/2, 그리고 render/1의 순서는 유지됩니다.preload/1 콜백의 작동 방식과 N + 1 문제와의 관계Phoenix LiveView에서 preload/1 콜백은 컴포넌트의 라이프사이클에서 중요한 역할을 합니다. 이 콜백은 컴포넌트가 마운트되기 전에 필요한 데이터를 미리 로드하는데 사용됩니다. 예를 들어, 여러 컴포넌트에 필요한 데이터를 한 번의 배치로 미리 로드하여, 각각의 컴포넌트가 마운트될 때 필요한 데이터를 제공할 수 있습니다. 이 과정은 preload(list_of_assigns) -&gt; mount(socket) -&gt; update(assigns, socket) -&gt; render(assigns)의 순서로 진행됩니다​​.preload/1 콜백의 주요 목적은 N + 1 문제를 해결하는 것입니다. 이 문제는 여러 데이터 레코드에 대한 의존성 있는 쿼리를 반복적으로 실행하여 발생하는 성능 저하 문제를 말합니다. preload/1를 사용함으로써 필요한 모든 데이터를 한 번에 로드할 수 있으며, 이는 데이터베이스에 대한 불필요한 접근을 줄이고 전체적인 성능을 향상시킵니다.Phoenix LiveView 문서에서는 preload/1과 관련된 구체적인 콜백 목록이나 사용 방법에 대해 자세히 설명하지 않지만, preload/1 콜백의 사용이 컴포넌트 라이프사이클에서 중요한 역할을 하고, 성능 최적화에 기여한다는 점은 분명합니다​​.이 정보를 바탕으로, preload/1 콜백이 데이터 처리를 mount/1 또는 update/2와 분리하여 실행함으로써 성능 최적화에 기여한다는 것을 이해할 수 있습니다. mount/1 이전에는 초기 로딩에 필요한 모든 데이터를 로드하고, update/2 이전에는 변경된 데이터에 대해서만 로드하는 방식으로 성능을 최적화합니다."
    } ,
  
    {
      "title"       : "기본적인 LiveView Authentication 적용",
      "category"    : "",
      "tags"        : "authentication, phoenix, liveview",
      "url"         : "./authentication.html",
      "date"        : "2023-12-18 13:32:20 +0900",
      "description" : "LiveView 라이브러리가 제공하는 Authentication 을 적용",
      "content"     : "Authentication Generator 사용을 위한 phx.gen 추가&gt; mix phx.gen이 중 auth 관련 generator 사용&gt; mix phx.gen.auth Accounts User uersAuthentication Generator 사용을 위한 phx.gen 추가&gt; mix phx.gen이 중 auth 관련 generator 사용&gt; mix phx.gen.auth Accounts User uers1. Context ('Accounts') Context는 Phoenix에서 도메인 특정 로직을 캡슐화하는 모듈. 이는 데이터베이스와의 상호작용을 관리하고, 애플리케이션의 나머지 부분에 서비스 API를 제공한다. \"Accounts\"는 이 예제에서 생성될 context의 이름으로 이 context는 인증과 관련된 모든 함수와 로직을 포함하게 된다.2. Schema ('User') Schema는 데이터베이스 테이블의 구조를 설명하는 Elixir 모듈. 이는 테이블의 각 열에 해당하는 필드와 그 타입을 정의한다. \"User\"는 사용자 데이터를 나타내는 schema의 이름으로 이 schema는 사용자 데이터를 저장하고 쿼리하는 데 사용된다.3. Plural name of the schema ('users') 이것은 데이터베이스 내에서 사용될 테이블의 이름. Phoenix는 일반적으로 schema 이름의 복수형을 테이블 이름으로 사용한다. \"users\"는 \"User\" schema에 대응하는 데이터베이스 테이블의 이름.&gt; mix deps.getRun Migration&gt; mix ecto.migrate해당 설정 이후 기존 `live \"/guess\", WrongLive` 를 :require_authenticated_user plug 를 실행하는 scope 로 옮겨서 추가해준다.따라서 해당 경로 접속은 Authentication 이 필요하며, 해당 인증은 LiveView 에서 재공하는 login / signup page 를 사용하여 회원 등록을 손쉽게 적용할 수 있게 된다."
    } 
  
]
