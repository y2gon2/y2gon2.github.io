<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2024-05-07T15:58:22+09:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Gon’s Tech Jurnal</title><subtitle>The Record of Backend Development</subtitle><author><name>Yong gon Yun</name></author><entry><title type="html">DDPG(Deep Deterministic Policy Gradient) Algorithm 이해</title><link href="http://localhost:4000/DDPG1.html" rel="alternate" type="text/html" title="DDPG(Deep Deterministic Policy Gradient) Algorithm 이해" /><published>2024-05-07T09:32:20+09:00</published><updated>2024-05-07T09:32:20+09:00</updated><id>http://localhost:4000/DDPG1</id><content type="html" xml:base="http://localhost:4000/DDPG1.html"><![CDATA[<style>
    summary::-webkit-details-marker {
        display: none;
    }
    summary {
        list-style: none;
    }
</style>

<details><summary></summary>
에러방지  에러방지 에러방지  에러방지 에러방지  에러방지 에러방지  에러방지
에러방지  에러방지 에러방지  에러방지 에러방지  에러방지 에러방지  에러방지
에러방지  에러방지 에러방지  에러방지 에러방지  에러방지 에러방지  에러방지
에러방지  에러방지 에러방지  에러방지 에러방지  에러방지 에러방지  에러방지
에러방지  에러방지 에러방지  에러방지 에러방지  에러방지 에러방지  에러방지
에러방지  에러방지 에러방지  에러방지 에러방지  에러방지 에러방지  에러방지
에러방지  에러방지 에러방지  에러방지 에러방지  에러방지 에러방지  에러방지
에러방지  에러방지 에러방지  에러방지 에러방지  에러방지 에러방지  에러방지
에러방지  에러방지 에러방지  에러방지 에러방지  에러방지 에러방지  에러방지
에러방지  에러방지 에러방지  에러방지 에러방지  에러방지 에러방지  에러방지
에러방지  에러방지 에러방지  에러방지 에러방지  에러방지 에러방지  에러방지
에러방지  에러방지 에러방지  에러방지 에러방지  에러방지 에러방지  에러방지
</details>

<ul>
  <li>해당 내용은 다음의 강의 내용을 개인적으로 재학습 하기 위해 작성됨. <br />
<a href="https://www.inflearn.com/course/%EC%9C%A0%EB%8B%88%ED%8B%B0-%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D-%EC%97%90%EC%9D%B4%EC%A0%84%ED%8A%B8-%EA%B8%B0%EC%B4%88">인프런 - 유니티 머신러닝 에이전트 완전정복 (기초편) | 민규식</a></li>
</ul>

<h3 id="1-기존-dqn-의-한계">1. 기존 DQN 의 한계</h3>

<p>선택하는 action 이 이산적인 행동(ex. 상, 하, 좌, 우)환경에만 적용 가능. 따라서 로봇 팔의 움직임, 로콧의 엔진 분출량 조절과 같은 연속적인 선택의 환경에서 적용 불가</p>

<h3 id="2-deep-deterministic-policy-gradient-ddpg">2. Deep Deterministic Policy Gradient (DDPG)</h3>

<ul>
  <li>Actor-Critic 기반 강화학습 알고리즘</li>
  <li>DPG(Deterministic Policy Gradient) 알고리즘을 신경망 network 에 적용</li>
  <li>연속적인 값 중에서 한가지 행동 값을 출력</li>
  <li>행동을 선택하는 actor 와 해당 행동을 실제로 수행했을 때 다음 상태에서의 q 값을 확인하는 critic 으로 강화학습을 구현</li>
</ul>

<h3 id="3-ddpg-알고리즘-기법">3. DDPG 알고리즘 기법</h3>

<h4 id="31-경험-리플레이-experience-replay">3.1 경험 리플레이 (Experience Replay)</h4>

<p>DQN 에서 사용한 바와 같이, 학습을 수행하면서 경험하는 정보를 일정랑 보관하고, 해당 데이터를 임의의 Batch 크기만큼씩 가져와서 훈련시 사용. 데이터간 상관관계 문제를 해결</p>

<h4 id="32-타겟-네트워크-target-network---soft-target-update-기법">3.2 타겟 네트워크 (Target Network) - Soft Target Update 기법</h4>

<p>기존 DQN 에서는 Target Network 의 경우, 매 step 마다 업데이트하는 경우, Target 애 매 학습마다 변화하는 문제를 발생시키기 때문에, Target Network 는 고정시킨 상태로 학습을 진행. 일정 주기마다 학습 Network 와 동기화 시켜 사용하였다.</p>

<p>그러나 연속적인 선택에서 이러한 Target Network update 는 맞지 않아 Soft Target Update 기법을 사용하여 매 step update 를 진행함.</p>

<ul>
  <li>지수이동평균(Exponential Moving Average, EMA) 과 같은 방법을 통한 업데이트</li>
</ul>

<center><img src="assets\img\posts\2024-05-07-DDPG1\1.png" width="420" /></center>

<ul>
  <li>θ  : 학습을 통해 산출된 파라미터</li>
  <li>
    <p>θ- : Target Network 파라미터</p>
  </li>
  <li>0 &lt;=  τ &lt;=  1 값을 통해 기존 Target Network Parameters 업데이트 수준을 조절.
    <ul>
      <li>τ == 0    : 학습된 파라미터로 완전 업데이트 (기존 DQN 방식)</li>
      <li>0 &lt; τ &lt; 1 : 일정 비율로 비례해서 학습된 파라미터 값을 기존 타겟 네트워크 파라미터에 반영</li>
    </ul>
  </li>
</ul>

<h4 id="33--ou-noise-를-사용한-탐험">3.3  OU Noise 를 사용한 탐험</h4>

<ul>
  <li>역시 연속된 행동 환경에서 선택 가능한 행동의 수가 무한이므로 기존의 epsilon-greedy 기법을 사용할 수 없음.</li>
  <li>실수 범위에서 행동을 선택하여 탐험할 수 있는 랜덤 평균 회귀 노이즈 생성</li>
</ul>

<center><img src="assets\img\posts\2024-05-07-DDPG1\2.png" width="530" /></center>

<ul>
  <li>1 번 식을 통해 현재 상태값 Xt 에서 다음 상태 Xt+1 로 변경시키는 그 변위 dx 는 2번 식과 같은 형태로 구성된다.</li>
  <li>2 번 식의 우변 값을 결정하는 요소들은 다음과 같다.
    <ul>
      <li>θ   : 평균 회귀 속도, 즉 변수가 평균 값 𝜇로 돌아가려는 속도</li>
      <li>μ   : 평균 값으로, 시스템이 장기적으로 안정되려는 목표 상태</li>
      <li>σ   : 노이즈의 크기 또는 강도, 시스템의 변동성을 결정</li>
      <li>dt  : 시간 증분, 일반적으로 미분 방정식을 시뮬레이션할 때 사용되는 시간의 단위</li>
      <li>dWt : 위너 과정(Wiener process) 또는 브라운 운동으로부터 파생된 임의의 충격. dt 시간 동안의 무작위 움직임을 표현</li>
    </ul>

    <p>즉,  μ − Xt 는 Xt 가 𝜇로 회귀하려는 정도 또는 현재 위치에서 목표 위치까지의 차이를 의미한다. 그리고 그 회귀가 얼마나 빠른가는 θ 에 비례한다. 다만 σdWt (노이즈 * dt 시간 동안의 무작위 움직임) 가 항상 더해지고 있으므로, 목표값에 도달하더라도 일정 수준의 연속적인 변동이 발생한다.</p>
  </li>
</ul>

<p>​<center><img src="assets\img\posts\2024-05-07-DDPG1\3.png" width="650" /></center>
<a href="https://www.inflearn.com/course/%EC%9C%A0%EB%8B%88%ED%8B%B0-%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D-%EC%97%90%EC%9D%B4%EC%A0%84%ED%8A%B8-%EA%B8%B0%EC%B4%88">이미지 출처</a></p>

<h4 id="34-critic-network-update">3.4 Critic Network Update</h4>

<p>DQN 과 동일하게 벨만 방정식을 사용하여 Q(x) 가 최대인 값을 타겟값으로 업데이트 한다. 
​<center><img src="assets\img\posts\2024-05-07-DDPG1\4.png" width="580" /></center></p>

<p><br />
손실함수의 경우도 DQN 과 동일한, 차이 제곱 평균 (MSE) 적용
​<center><img src="assets\img\posts\2024-05-07-DDPG1\5.png" width="260" /></center>
<br />
actor network update 는 목표 함수값를 최대하하는 방향으로 정책을 업데이트</p>

<p>​<center><img src="assets\img\posts\2024-05-07-DDPG1\6.png" width="650" /></center>
<a href="https://www.inflearn.com/course/%EC%9C%A0%EB%8B%88%ED%8B%B0-%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D-%EC%97%90%EC%9D%B4%EC%A0%84%ED%8A%B8-%EA%B8%B0%EC%B4%88">이미지 출처</a>
<br />
목표 함수를 최대화 하는 방향 계산을 위한 gradient (아래 유도 과정은 아직 이해 X ;;)</p>

<p>​<center><img src="assets\img\posts\2024-05-07-DDPG1\7.png" width="650" /></center>
<a href="https://www.inflearn.com/course/%EC%9C%A0%EB%8B%88%ED%8B%B0-%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D-%EC%97%90%EC%9D%B4%EC%A0%84%ED%8A%B8-%EA%B8%B0%EC%B4%88">이미지 출처</a>
<br /></p>

<h3 id="4-ddpg-알고리즘을-사용한-network-학습-프로세스">4. DDPG 알고리즘을 사용한 network 학습 프로세스</h3>

<p>​<center><img src="assets\img\posts\2024-05-07-DDPG1\8.png" width="650" /></center>
<a href="https://www.inflearn.com/course/%EC%9C%A0%EB%8B%88%ED%8B%B0-%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D-%EC%97%90%EC%9D%B4%EC%A0%84%ED%8A%B8-%EA%B8%B0%EC%B4%88">이미지 출처</a></p>

<ol>
  <li>Agent 가 환경과 상호작용 (상태 전이)</li>
  <li>상호작용시 Agent 의 행동을 결정하는 것은 Actor Network 
(input: 현재 상태 s -&gt; output : 행동 a)
다만 이때, 행동은 연속적며, 이런 연속적 행동 선택에서 OU noise 를 추가하여 탐험을 수행</li>
  <li>2번으로 선택된 행동을 환경에 적용, 다음 단계의 상태 (경험) 을 생성.</li>
  <li>경험 데이터를 replay memory 에 저장</li>
  <li>(경험 데이터가 일정량 이상 쌓이 이후), mini batch data 를 sampling 하여 학습을 수행</li>
  <li>critic network 학습 (input : 상태, 행동 -&gt; output : Q(s, a) 값)
    <ul>
      <li>6.1 (일반) Critic Network (input : s, a -&gt; output: q)</li>
      <li>6.2 Traget Critic Network (input : s’, a’ -&gt; output: q’)</li>
      <li>6.3 6.1 6.2 결과값의 차이를 통해 손실값을 계산</li>
      <li>6.4 손실값이 최소화 되도록 critic network 를 update</li>
      <li>6.5 매 step 마다 soft target update 로 critic network 를 통해 target critic network 를 update</li>
    </ul>
  </li>
  <li>Critic Network 의 q 값을 최대화하는 방향으로 Policy Gradient 를 통해 Actor Network 을 학습시킴.</li>
  <li>6.5 와 동일하게 매 step 마다 (일반) soft target update 로 actor network 를 통해 target actor network 를 update</li>
</ol>]]></content><author><name>Yong gon Yun</name></author><category term="DDPG" /><category term="Deep Deterministic Policy Gradient" /><category term="DQN" /><summary type="html"><![CDATA[DDPG(Deep Deterministic Policy Gradient) Algorithm 이해]]></summary></entry><entry><title type="html">Deep Q-Network + ML-agents 구현</title><link href="http://localhost:4000/DQN_ml_agents.html" rel="alternate" type="text/html" title="Deep Q-Network + ML-agents 구현" /><published>2024-05-03T09:32:20+09:00</published><updated>2024-05-03T09:32:20+09:00</updated><id>http://localhost:4000/DQN_ml_agents</id><content type="html" xml:base="http://localhost:4000/DQN_ml_agents.html"><![CDATA[<style>
    summary::-webkit-details-marker {
        display: none;
    }
    summary {
        list-style: none;
    }
</style>

<details><summary></summary>
에러방지  에러방지 에러방지  에러방지 에러방지  에러방지 에러방지  에러방지
에러방지  에러방지 에러방지  에러방지 에러방지  에러방지 에러방지  에러방지
에러방지  에러방지 에러방지  에러방지 에러방지  에러방지 에러방지  에러방지
에러방지  에러방지 에러방지  에러방지 에러방지  에러방지 에러방지  에러방지
에러방지  에러방지 에러방지  에러방지 에러방지  에러방지 에러방지  에러방지
에러방지  에러방지 에러방지  에러방지 에러방지  에러방지 에러방지  에러방지
에러방지  에러방지 에러방지  에러방지 에러방지  에러방지 에러방지  에러방지
에러방지  에러방지 에러방지  에러방지 에러방지  에러방지 에러방지  에러방지
에러방지  에러방지 에러방지  에러방지 에러방지  에러방지 에러방지  에러방지
에러방지  에러방지 에러방지  에러방지 에러방지  에러방지 에러방지  에러방지
에러방지  에러방지 에러방지  에러방지 에러방지  에러방지 에러방지  에러방지
에러방지  에러방지 에러방지  에러방지 에러방지  에러방지 에러방지  에러방지
</details>

<ul>
  <li>
    <p>해당 내용은 다음의 강의 내용을 개인적으로 재학습 하기 위해 작성됨. <br />
<a href="https://www.inflearn.com/course/%EC%9C%A0%EB%8B%88%ED%8B%B0-%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D-%EC%97%90%EC%9D%B4%EC%A0%84%ED%8A%B8-%EA%B8%B0%EC%B4%88">인프런 - 유니티 머신러닝 에이전트 완전정복 (기초편) | 민규식</a></p>
  </li>
  <li>
    <p>DQN 알고리즘의 전체 흐름</p>
  </li>
</ul>

<center><img src="assets\img\posts\2024-05-03-DQN_ml_agents\0.png" width="600" /></center>
<p><a href="https://www.inflearn.com/course/%EC%9C%A0%EB%8B%88%ED%8B%B0-%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D-%EC%97%90%EC%9D%B4%EC%A0%84%ED%8A%B8-%EA%B8%B0%EC%B4%88">이미지 출처</a></p>

<h3 id="0-전체-코드-요약">0. 전체 코드 요약</h3>

<p>전체 코드는 다음의 내용으로 구성된다.</p>

<ol>
  <li>프로그램 기본 설정
    <ul>
      <li>필요한 파이썬 라이브러리 가져오기</li>
      <li>파라미터 설정</li>
      <li>유니티 연결 환경 설정</li>
      <li>학습된 모델 저장/불러오기</li>
      <li>연산장치 (CPU or GPU) 선택<br /><br /></li>
    </ul>
  </li>
  <li>Deep Q-Network class 정의
    <ul>
      <li>Layer 구현 (입/출력, Convolution layer 정의)</li>
      <li>신경망 함수<br /><br /></li>
    </ul>
  </li>
  <li>DQNAgent class 정의
    <ul>
      <li>Agent 구현 환경 정의(ex. network, optimizer, memory)</li>
      <li>network 를 통한 action 선택 함수</li>
      <li>replay memory 에 데이터 추가 함수</li>
      <li>network parameter 학습 시키는 함수</li>
      <li>target_network update 함수</li>
      <li>모델 저장 함수</li>
      <li>tensorboard 기록 함수  <br /><br /></li>
    </ul>
  </li>
  <li>프로그램 동작 구현 (main)
    <ul>
      <li>unity 와 상호 작용이 가능한  UnityEnvironment 인스턴스(env) 생성</li>
      <li>env 로 부터 관측/target 공간 정보, step 진행 후 정보 및 구동 환경(time scale) 설정</li>
      <li>반복문을 통해  run_step + test_step 동안 학습을 진행시킴
        <ul>
          <li>(run_step 마지막 단계에서 모델을 저장하고 test_mode 로 전환)</li>
          <li>전처리: 시각적 관측 정보와 목적지 관측 정보를 전처리하여 state 로 저장</li>
          <li>agent 를 통해 action 을 결정하고, 해당 action 으로 unity 에서 다음 step 을 진행시킴</li>
          <li>진행된 현재 step 정보 가져옴</li>
          <li>종료(termination) 확인 및 next_step -&gt; next_state 정보로 전처리</li>
          <li>(train mode 일 경우) next_state 를 replay memory 에 저장</li>
          <li>충분히 메모리에 state 정보가 차 있다면, 모델 학습으로 손실값을 계산하고, 일정 주기로 target_model 을 update 함.</li>
          <li>episode 종료 시, 필요한 설정값을 조정하고, tensorboard 에 보상/손실 값을 기록, 필요 조건마다 훈련된 모델 저장</li>
        </ul>
      </li>
    </ul>
  </li>
</ol>

<h3 id="1-프로그램-기본-설정">1. 프로그램 기본 설정</h3>
<h4 id="11-필요한-파이썬-라이브러리-가져오기">1.1 필요한 파이썬 라이브러리 가져오기</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="n">random</span>
<span class="kn">import</span> <span class="n">copy</span>
<span class="kn">import</span> <span class="n">datetime</span>
<span class="kn">import</span> <span class="n">platform</span> <span class="c1"># system (OS) 관련
</span><span class="kn">import</span> <span class="n">torch</span>
<span class="kn">import</span> <span class="n">torch.nn.functional</span> <span class="k">as</span> <span class="n">F</span>
<span class="kn">from</span> <span class="n">troch.utils.tensorboard</span> <span class="kn">import</span> <span class="n">SummaryWriter</span>
<span class="kn">from</span> <span class="n">collections</span> <span class="kn">import</span> <span class="n">deque</span>
<span class="kn">from</span> <span class="n">mlagetns_envs.environment</span> <span class="kn">import</span> <span class="n">UnityEnvironment</span><span class="p">,</span> <span class="n">ActionTuple</span> <span class="c1"># (1)
</span><span class="kn">from</span> <span class="n">malagents_envs.side_channel.engine_configuration_channel</span> <span class="kn">import</span> <span class="n">EngineConfigurationChannel</span> <span class="c1"># (2)
</span></code></pre></div></div>
<p>(1) 유니티 환경 클래스, 액션을 환경에 전달하기 위한 환경 객체 <br />
(2) 유니티 환경 조건을 조정하기 위한 라이브러리 (ex. 타임 스케일 조절)</p>

<h4 id="12-파라미터-설정">1.2 파라미터 설정</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">state_size</span> <span class="o">=</span> <span class="p">[</span><span class="mi">3</span><span class="o">*</span><span class="mi">2</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">84</span><span class="p">]</span> <span class="c1"># goal-plus RGB + goal-ex RGB =&gt; 6 채널 * h * w (아래 이미지 참조)
</span><span class="n">action_size</span> <span class="o">=</span> <span class="mi">4</span> <span class="c1"># 오른쪽, 왼쪽, 위, 아래
</span>
<span class="n">load_model</span> <span class="o">=</span> <span class="bp">False</span> <span class="c1"># 모델 불러오기 여부
</span><span class="n">train_mode</span> <span class="o">=</span> <span class="bp">True</span>  <span class="c1"># 모델 학습 여부 (True : 학습모드, False: 평가모드)
</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">32</span>
<span class="n">mem_maxlen</span> <span class="o">=</span> <span class="mi">10000</span>  <span class="c1"># replay memory 최대 크기
</span><span class="n">discount_factor</span> <span class="o">=</span> <span class="mf">0.9</span> <span class="c1"># 미래에 대한 보상 감가율
</span><span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.00025</span> <span class="c1"># 네트워크 학습률
</span>
<span class="n">run_step</span> <span class="o">=</span> <span class="mi">50000</span> <span class="k">if</span> <span class="n">train_mode</span> <span class="k">else</span> <span class="mi">0</span> <span class="c1"># 학습모드에서 진행할 스텝 수 설정 (평가 모드 = 0)
</span><span class="n">test_step</span> <span class="o">=</span> <span class="mi">5000</span>         <span class="c1"># 평가 모드에서 진행할 스텝 수
</span><span class="n">train_start_step</span> <span class="o">=</span> <span class="mi">5000</span>  <span class="c1"># 학습 시작 전에 리플레이 메모리에 충분한 데이터를 모으기 위해 몇 스텝동안 임의의 행동으로 게임 진행할 것인지 설정
</span><span class="n">target_update_step</span> <span class="o">=</span> <span class="mi">500</span> <span class="c1"># 타겟 네트워크를 몇 스텝 주기로 업데이트 할지 설정
</span>
<span class="n">print_interval</span> <span class="o">=</span> <span class="mi">10</span>     <span class="c1"># 학습 진행 상황을 텐서보드에 기록할 주기
</span><span class="n">save_interval</span> <span class="o">=</span> <span class="mi">100</span>     <span class="c1"># 학습 모델을 저장할 에피스드 주기 설정
</span>
<span class="n">epsilon_eval</span> <span class="o">=</span> <span class="mf">0.05</span>     <span class="c1"># 평가모드의 eps 값
</span><span class="n">epsilon_init</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="k">if</span> <span class="n">train_mode</span> <span class="k">else</span> <span class="n">epsilon_eval</span> <span class="c1"># eps 초기값
</span><span class="n">epsilon_min</span> <span class="o">=</span> <span class="mf">0.1</span>       <span class="c1"># 학습구간에서의 eps 최소값
</span><span class="n">explore_step</span> <span class="o">=</span> <span class="n">run_step</span> <span class="o">*</span> <span class="mf">0.8</span> <span class="c1"># eps 이 감소되는 구간
</span><span class="n">eplsilon_data</span> <span class="o">=</span> <span class="p">(</span><span class="n">epsilon_init</span> <span class="o">-</span> <span class="n">epsilon_min</span><span class="p">)</span> <span class="o">/</span> <span class="n">explore_step</span> <span class="k">if</span> <span class="n">train_mode</span> <span class="k">else</span> <span class="mf">0.05</span>
                        <span class="c1"># 한스텝당 감소하는 eps 변화량
</span>
<span class="c1"># 다음의 파라미터 값들은 실제 데이터를 가리키는 인덱스, 즉 enum 과 유사한 개념으로 사용됨.
</span><span class="n">VISUAL_OBS</span> <span class="o">=</span> <span class="mi">0</span>  <span class="c1"># 시각적 관측 데이터. 에이전트가 이미지 형태로 관측하는 정보를 가리키는 인덱스 
</span><span class="n">GOAL_OBS</span> <span class="o">=</span> <span class="mi">1</span>    <span class="c1"># 목적지 관측 데이터. 에이전트가 목표를 달성하는데 필요한 정포를 가리키는 인덱스
</span><span class="n">VECTOR_OBS</span> <span class="o">=</span> <span class="mi">2</span>  <span class="c1"># 수치적 관측 인덱스. 에이전트가 벡터 형태로 관측하는 정보를 가리키는 인덱스
</span><span class="n">OBS</span> <span class="o">=</span> <span class="n">VISUAL_OBS</span> <span class="c1"># DQN 에서는 시각적 관측 인덱스를 사용
</span></code></pre></div></div>

<ul>
  <li>state_size = [3*2, 64, 84] 관련 이미지</li>
</ul>

<center><img src="assets\img\posts\2024-05-03-DQN_ml_agents\1.png" width="600" /></center>
<p><a href="https://www.inflearn.com/course/%EC%9C%A0%EB%8B%88%ED%8B%B0-%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D-%EC%97%90%EC%9D%B4%EC%A0%84%ED%8A%B8-%EA%B8%B0%EC%B4%88">이미지 출처</a></p>

<ul>
  <li>epsilon-greedy 를 적용한 학습에서 각 파라미터들의 사용 그래프</li>
</ul>
<center><img src="assets\img\posts\2024-05-03-DQN_ml_agents\2.png" width="600" /></center>
<p><a href="https://www.inflearn.com/course/%EC%9C%A0%EB%8B%88%ED%8B%B0-%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D-%EC%97%90%EC%9D%B4%EC%A0%84%ED%8A%B8-%EA%B8%B0%EC%B4%88">이미지 출처</a></p>

<h4 id="13-유니티-연결-환경-설정">1.3 유니티 연결 환경 설정</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">game</span> <span class="o">=</span> <span class="sh">"</span><span class="s">GridWorld</span><span class="sh">"</span>          <span class="c1"># 환경 빌드명 
</span><span class="n">os_name</span> <span class="o">=</span> <span class="n">platform</span><span class="p">.</span><span class="nf">system</span><span class="p">()</span> <span class="c1"># 현재 사용 OS
</span><span class="k">if</span> <span class="n">os_name</span> <span class="o">==</span> <span class="sh">'</span><span class="s">Windows</span><span class="sh">'</span><span class="p">:</span>
    <span class="n">env_name</span> <span class="o">=</span> <span class="sa">f</span><span class="sh">"</span><span class="s">../envs/</span><span class="si">{</span><span class="n">game</span><span class="si">}</span><span class="s">_</span><span class="si">{</span><span class="n">os_name</span><span class="si">}</span><span class="s">/</span><span class="si">{</span><span class="n">game</span><span class="si">}</span><span class="sh">"</span> <span class="c1"># 불러올 유니티 환경 경로
</span><span class="k">elif</span> <span class="n">os_name</span> <span class="o">==</span> <span class="sh">'</span><span class="s">Darwin</span><span class="sh">'</span><span class="p">:</span> <span class="c1"># Mac OS
</span>    <span class="n">env_name</span> <span class="o">=</span> <span class="sa">f</span><span class="sh">"</span><span class="s">../envs/</span><span class="si">{</span><span class="n">game</span><span class="si">}</span><span class="s">_</span><span class="si">{</span><span class="n">os_name</span><span class="si">}</span><span class="sh">"</span>

</code></pre></div></div>

<h4 id="14-학습된-모델-저장불러오기">1.4 학습된 모델 저장/불러오기</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">date_time</span> <span class="o">=</span> <span class="n">datetime</span><span class="p">.</span><span class="n">datetime</span><span class="p">.</span><span class="nf">now</span><span class="p">().</span><span class="nf">strftime</span><span class="p">(</span><span class="sh">"</span><span class="s">%Y%m%d%H%M%S</span><span class="sh">"</span><span class="p">)</span>
<span class="n">save_path</span> <span class="o">=</span> <span class="sa">f</span><span class="sh">"</span><span class="s">./saved_models/</span><span class="si">{</span><span class="n">game</span><span class="si">}</span><span class="s">/DQN/</span><span class="si">{</span><span class="n">date_time</span><span class="si">}</span><span class="sh">"</span> <span class="c1"># 모델 파일일 저장될 경로
</span><span class="n">load_path</span> <span class="o">=</span> <span class="sa">f</span><span class="sh">"</span><span class="s">./saved_models/</span><span class="si">{</span><span class="n">game</span><span class="si">}</span><span class="s">/DQN/20240503201212</span><span class="sh">"</span> <span class="c1"># 불러올 모델 파일 경로
</span></code></pre></div></div>

<h4 id="15-연산장치-cpu-or-gpu-선택">1.5 연산장치 (CPU or GPU) 선택</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">device</span><span class="p">(</span><span class="sh">"</span><span class="s">cuda</span><span class="sh">"</span> <span class="k">if</span> <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="nf">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="sh">"</span><span class="s">cpu</span><span class="sh">"</span><span class="p">)</span> <span class="c1"># 연산 장치 (CPU or GPU)
</span></code></pre></div></div>

<h3 id="2-deep-q-network-class-정의">2. Deep Q-Network class 정의</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">DQN</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="c1"># 2.1 Layer 구현 (입/출력, Convolution layer 정의)
</span>    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">(</span><span class="n">DQN</span><span class="p">,</span> <span class="n">self</span><span class="p">).</span><span class="nf">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">Conv2d</span><span class="p">(</span>
            <span class="n">in_channels</span><span class="o">=</span><span class="n">state_size</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">out_channels</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">4</span>
            <span class="p">)</span>
        <span class="n">dim1</span> <span class="o">=</span> <span class="p">((</span><span class="n">state_size</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="mi">8</span><span class="p">)</span><span class="o">//</span><span class="mi">4</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="p">(</span><span class="n">state_size</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">-</span> <span class="mi">8</span><span class="p">)</span><span class="o">//</span><span class="mi">4</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
        
        <span class="n">self</span><span class="p">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">Conv2d</span><span class="p">(</span>
            <span class="n">in_channels</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">out_channels</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span>
            <span class="p">)</span>
        <span class="n">dim2</span> <span class="o">=</span> <span class="p">((</span><span class="n">dim1</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="mi">4</span><span class="p">)</span><span class="o">//</span><span class="mi">2</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="p">(</span><span class="n">dim1</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="mi">4</span><span class="p">)</span><span class="o">//</span><span class="mi">2</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
        
        <span class="n">self</span><span class="p">.</span><span class="n">conv3</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">Conv2d</span><span class="p">(</span>
            <span class="n">in_channels</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">out_channels</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span>
            <span class="p">)</span>
        <span class="n">dim3</span> <span class="o">=</span> <span class="p">((</span><span class="n">dim2</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="mi">3</span><span class="p">)</span><span class="o">//</span><span class="mi">1</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="p">(</span><span class="n">dim2</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="mi">3</span><span class="p">)</span><span class="o">//</span><span class="mi">1</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>

        <span class="n">self</span><span class="p">.</span><span class="n">flat</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">Flatten</span><span class="p">()</span> <span class="c1"># 전체 텐서를 1차원을 변환
</span>        <span class="n">self</span><span class="p">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="mi">64</span><span class="o">*</span><span class="n">dim3</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="n">dim3</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">512</span><span class="p">)</span> <span class="c1"># 완전 연결 레이어를 만들어 주기 위함. 
</span>        <span class="n">self</span><span class="p">.</span><span class="n">q</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="n">action_size</span><span class="p">)</span>

    <span class="c1"># 2.2 신경망 함수
</span>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="nf">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span> <span class="c1"># 데이터 차원 순서  변환 input : unity data (H, W, Ch) -&gt; pytorch data (Ch, H, W)
</span>        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="nf">relu</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="nf">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="nf">relu</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="nf">conv2</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="nf">relu</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="nf">conv3</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">flat</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="nf">relu</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="nf">fc1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="nf">q</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

</code></pre></div></div>
<h4 id="21-layer-구현-입출력-convolution-layer-정의">2.1 Layer 구현 (입/출력, Convolution layer 정의)</h4>

<p>ML-Agents 를 사용하여 unity 부터 상태 정보를 받을 때, agent 에 설정된 카메라를 통한 이미지를 받아 사용하거나, 해당 환경에서의 좌표값 (vector) 값을 사용할 수 있다. 해당 모델에서는 이미지를 사용하여 처리할 것이므로, 이미지 처리에 적합한 convolution layer 를 사용하여 처리하는 것으로 구현되었다.</p>

<ul>
  <li>convolution layer + flattent layer + linear layer 의 연결 이미지</li>
</ul>
<center><img src="assets\img\posts\2024-05-03-DQN_ml_agents\3.png" width="600" /></center>
<p><a href="https://www.inflearn.com/course/%EC%9C%A0%EB%8B%88%ED%8B%B0-%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D-%EC%97%90%EC%9D%B4%EC%A0%84%ED%8A%B8-%EA%B8%B0%EC%B4%88">이미지 출처</a></p>

<h4 id="22-신경망-함수">2.2 신경망 함수</h4>

<p>일반적으로 PyTorch 에서 신경망 모델 구현 클래스는 torch.nn.Module 을 상속받아 사용한다. 해당 부모 class 에 <code class="language-plaintext highlighter-rouge">__call__</code> 메서드 상 정의에 의해 해당 class 명으로 요청 (ex. <code class="language-plaintext highlighter-rouge">DQN()</code>)시 <code class="language-plaintext highlighter-rouge">forward</code> 메서드가 실행 요청된다.</p>

<ul>
  <li>구현된 신경망 모델 개념도</li>
</ul>

<center><img src="assets\img\posts\2024-05-03-DQN_ml_agents\4.png" width="600" /></center>
<p><a href="https://www.inflearn.com/course/%EC%9C%A0%EB%8B%88%ED%8B%B0-%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D-%EC%97%90%EC%9D%B4%EC%A0%84%ED%8A%B8-%EA%B8%B0%EC%B4%88">이미지 출처</a></p>

<h3 id="3-dqnagent-class-정의">3. DQNAgent class 정의</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">DQNAgent</span><span class="p">:</span>
    <span class="c1"># 3.1 Agent 구현 환경 정의(ex. network, optimizer, memory)
</span>    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">network</span> <span class="o">=</span> <span class="nc">DQN</span><span class="p">().</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">target_network</span> <span class="o">=</span> <span class="n">copy</span><span class="p">.</span><span class="nf">deepcopy</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">network</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">optim</span><span class="p">.</span><span class="nc">Adam</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">network</span><span class="p">.</span><span class="nf">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">memory</span> <span class="o">=</span> <span class="nf">deque</span><span class="p">(</span><span class="n">maxlen</span><span class="o">=</span><span class="n">mem_maxlen</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">epsilon</span> <span class="o">=</span> <span class="n">epsilon_init</span>
        <span class="n">self</span><span class="p">.</span><span class="n">writer</span> <span class="o">=</span> <span class="nc">SummaryWriter</span><span class="p">(</span><span class="n">save_path</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">load_model</span> <span class="o">==</span> <span class="bp">True</span><span class="p">:</span> 
            <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">... Load Model from </span><span class="si">{</span><span class="n">load_path</span><span class="si">}</span><span class="s">/ckpt</span><span class="sh">"</span><span class="p">)</span>
            <span class="n">checkpoint</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">load</span><span class="p">(</span><span class="n">load_path</span><span class="o">+</span><span class="sh">'</span><span class="s">/ckpt</span><span class="sh">'</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="n">device</span><span class="p">)</span> 
            <span class="n">self</span><span class="p">.</span><span class="n">network</span><span class="p">.</span><span class="nf">load_state_dict</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">[</span><span class="sh">"</span><span class="s">network</span><span class="sh">"</span><span class="p">])</span>
            <span class="n">self</span><span class="p">.</span><span class="n">target_network</span><span class="p">.</span><span class="nf">load_state_dict</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">[</span><span class="sh">"</span><span class="s">network</span><span class="sh">"</span><span class="p">])</span>
            <span class="n">self</span><span class="p">.</span><span class="n">optimizer</span><span class="p">.</span><span class="nf">load_state_dict</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">[</span><span class="sh">"</span><span class="s">optimizer</span><span class="sh">"</span><span class="p">])</span>

    <span class="c1"># 3.2 network 를 통한 action 선택 함수
</span>    <span class="k">def</span> <span class="nf">get_action</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>

        <span class="n">self</span><span class="p">.</span><span class="n">network</span><span class="p">.</span><span class="nf">train</span><span class="p">(</span><span class="n">training</span><span class="p">)</span> 
        <span class="n">epsilon</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">epsilon</span> <span class="k">if</span> <span class="n">training</span> <span class="k">else</span> <span class="n">epsilon_eval</span>

        <span class="k">if</span> <span class="n">epsilon</span> <span class="o">&gt;</span> <span class="n">random</span><span class="p">.</span><span class="nf">random</span><span class="p">():</span>
            <span class="n">action</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">action_size</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">state</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">))</span> 
        <span class="k">else</span><span class="p">:</span>
            <span class="n">q</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">network</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nc">FloatTensor</span><span class="p">(</span><span class="n">state</span><span class="p">).</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">))</span>
            <span class="n">action</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">argmax</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="bp">True</span><span class="p">).</span><span class="n">data</span><span class="p">.</span><span class="nf">cpu</span><span class="p">().</span><span class="nf">numpy</span><span class="p">()</span> 
        <span class="k">return</span> <span class="n">action</span>
        
    <span class="c1"># 3.3 replay memory 에 데이터 추가 함수
</span>    <span class="k">def</span> <span class="nf">append_sample</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">next_state</span><span class="p">,</span> <span class="n">done</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">memory</span><span class="p">.</span><span class="nf">append</span><span class="p">((</span><span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">next_state</span><span class="p">,</span> <span class="n">done</span><span class="p">))</span>

    <span class="c1"># 3.4 network parameter 학습 시키는 함수
</span>    <span class="k">def</span> <span class="nf">train_model</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="n">batch</span> <span class="o">=</span> <span class="n">random</span><span class="p">.</span><span class="nf">sample</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">memory</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>
        <span class="n">state</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">stack</span><span class="p">([</span><span class="n">b</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">b</span>  <span class="ow">in</span> <span class="n">batch</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">action</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">stack</span><span class="p">([</span><span class="n">b</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">b</span>  <span class="ow">in</span> <span class="n">batch</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">reward</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">stack</span><span class="p">([</span><span class="n">b</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="k">for</span> <span class="n">b</span>  <span class="ow">in</span> <span class="n">batch</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">next_state</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">stack</span><span class="p">([</span><span class="n">b</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span> <span class="k">for</span> <span class="n">b</span>  <span class="ow">in</span> <span class="n">batch</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">done</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">stack</span><span class="p">([</span><span class="n">b</span><span class="p">[</span><span class="mi">4</span><span class="p">]</span> <span class="k">for</span> <span class="n">b</span>  <span class="ow">in</span> <span class="n">batch</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

        <span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">next_state</span><span class="p">,</span> <span class="n">done</span> <span class="o">=</span> <span class="nf">map</span><span class="p">(</span>
            <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="nc">FloatTensor</span><span class="p">(</span><span class="n">x</span><span class="p">).</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="p">[</span><span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">next_state</span><span class="p">,</span> <span class="n">done</span><span class="p">]</span>
        <span class="p">)</span>

        <span class="n">eye</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">eye</span><span class="p">(</span><span class="n">action_size</span><span class="p">).</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">one_hot_action</span> <span class="o">=</span> <span class="n">eye</span><span class="p">[</span><span class="n">action</span><span class="p">.</span><span class="nf">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">).</span><span class="nf">long</span><span class="p">()]</span> 

        <span class="n">q</span> <span class="o">=</span> <span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="nf">network</span><span class="p">(</span><span class="n">state</span><span class="p">)</span> <span class="o">*</span> <span class="n">one_hot_action</span><span class="p">).</span><span class="nf">sum</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

        <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="nf">no_grad</span><span class="p">():</span>
            <span class="n">next_q</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">target_network</span><span class="p">(</span><span class="n">next_state</span><span class="p">)</span>
            <span class="n">target_q</span> <span class="o">=</span> <span class="n">reward</span> <span class="o">+</span> <span class="n">next_q</span><span class="p">.</span><span class="nf">max</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="bp">True</span><span class="p">).</span><span class="n">values</span> <span class="o">*</span> <span class="p">((</span><span class="mi">1</span> <span class="o">-</span> <span class="n">done</span><span class="p">)</span> <span class="o">*</span> <span class="n">discount_factor</span><span class="p">)</span>

        <span class="n">loss</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="nf">smooth_l1_loss</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">target_q</span><span class="p">)</span>
 
        <span class="n">self</span><span class="p">.</span><span class="n">optimizer</span><span class="p">.</span><span class="nf">zero_grad</span><span class="p">()</span>  
        <span class="n">loss</span><span class="p">.</span><span class="nf">backward</span><span class="p">()</span>             
        <span class="n">self</span><span class="p">.</span><span class="n">optimizer</span><span class="p">.</span><span class="nf">step</span><span class="p">()</span>      
        <span class="n">self</span><span class="p">.</span><span class="n">epsilon</span> <span class="o">=</span> <span class="nf">max</span><span class="p">(</span><span class="n">epsilon_min</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">epsilon</span> <span class="o">-</span> <span class="n">eplsilon_data</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">loss</span><span class="p">.</span><span class="nf">item</span><span class="p">()</span>
    
    <span class="c1"># 3.5 target_network update 함수
</span>    <span class="k">def</span> <span class="nf">update_target</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">target_network</span><span class="p">.</span><span class="nf">load_state_dict</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">network</span><span class="p">.</span><span class="nf">state_dict</span><span class="p">())</span>

    <span class="c1"># 모델 저장 함수
</span>    <span class="k">def</span> <span class="nf">save_model</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">... Save Model to </span><span class="si">{</span><span class="n">save_path</span><span class="si">}</span><span class="s">/ckpt ...</span><span class="sh">"</span><span class="p">)</span>
        <span class="n">torch</span><span class="p">.</span><span class="nf">save</span><span class="p">({</span>
            <span class="sh">"</span><span class="s">network</span><span class="sh">"</span> <span class="p">:</span> <span class="n">self</span><span class="p">.</span><span class="n">network</span><span class="p">.</span><span class="nf">state_dict</span><span class="p">(),</span>   
            <span class="sh">"</span><span class="s">optimizer</span><span class="sh">"</span> <span class="p">:</span> <span class="n">self</span><span class="p">.</span><span class="n">optimizer</span><span class="p">.</span><span class="nf">state_dict</span><span class="p">(),</span>
        <span class="p">},</span> <span class="n">save_path</span><span class="o">+</span><span class="sh">'</span><span class="s">/ckpt</span><span class="sh">'</span><span class="p">)</span>

    <span class="c1"># tesorboard 기록 
</span>    <span class="k">def</span> <span class="nf">write_summary</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">score</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">epsilon</span><span class="p">,</span> <span class="n">step</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">writer</span><span class="p">.</span><span class="nf">add_scalar</span><span class="p">(</span><span class="sh">"</span><span class="s">run/score</span><span class="sh">"</span><span class="p">,</span> <span class="n">score</span><span class="p">,</span> <span class="n">step</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">writer</span><span class="p">.</span><span class="nf">add_scalar</span><span class="p">(</span><span class="sh">"</span><span class="s">model/loss</span><span class="sh">"</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">step</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">writer</span><span class="p">.</span><span class="nf">add_scalar</span><span class="p">(</span><span class="sh">"</span><span class="s">model/epsilon</span><span class="sh">"</span><span class="p">,</span> <span class="n">epsilon</span><span class="p">,</span> <span class="n">step</span><span class="p">)</span>
</code></pre></div></div>

<h4 id="31-agent-구현-환경-정의ex-network-optimizer-memory">3.1 Agent 구현 환경 정의(ex. network, optimizer, memory)</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">network</span> <span class="o">=</span> <span class="nc">DQN</span><span class="p">().</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span> <span class="c1"># (1)
</span>        <span class="n">self</span><span class="p">.</span><span class="n">target_network</span> <span class="o">=</span> <span class="n">copy</span><span class="p">.</span><span class="nf">deepcopy</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">network</span><span class="p">)</span> <span class="c1"># (2)
</span>        <span class="n">self</span><span class="p">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">optim</span><span class="p">.</span><span class="nc">Adam</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">network</span><span class="p">.</span><span class="nf">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">memory</span> <span class="o">=</span> <span class="nf">deque</span><span class="p">(</span><span class="n">maxlen</span><span class="o">=</span><span class="n">mem_maxlen</span><span class="p">)</span> <span class="c1"># (3)
</span>        <span class="n">self</span><span class="p">.</span><span class="n">epsilon</span> <span class="o">=</span> <span class="n">epsilon_init</span> <span class="c1"># (4)
</span>        <span class="n">self</span><span class="p">.</span><span class="n">writer</span> <span class="o">=</span> <span class="nc">SummaryWriter</span><span class="p">(</span><span class="n">save_path</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">load_model</span> <span class="o">==</span> <span class="bp">True</span><span class="p">:</span> <span class="c1"># (5)
</span>            <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">... Load Model from </span><span class="si">{</span><span class="n">load_path</span><span class="si">}</span><span class="s">/ckpt</span><span class="sh">"</span><span class="p">)</span>
            <span class="n">checkpoint</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">load</span><span class="p">(</span><span class="n">load_path</span><span class="o">+</span><span class="sh">'</span><span class="s">/ckpt</span><span class="sh">'</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="n">device</span><span class="p">)</span> 
            <span class="n">self</span><span class="p">.</span><span class="n">network</span><span class="p">.</span><span class="nf">load_state_dict</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">[</span><span class="sh">"</span><span class="s">network</span><span class="sh">"</span><span class="p">])</span>
            <span class="n">self</span><span class="p">.</span><span class="n">target_network</span><span class="p">.</span><span class="nf">load_state_dict</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">[</span><span class="sh">"</span><span class="s">network</span><span class="sh">"</span><span class="p">])</span>
            <span class="n">self</span><span class="p">.</span><span class="n">optimizer</span><span class="p">.</span><span class="nf">load_state_dict</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">[</span><span class="sh">"</span><span class="s">optimizer</span><span class="sh">"</span><span class="p">])</span>
</code></pre></div></div>

<p>(1) self.network = DQN().to(device)<br />
    훈련에 사용할 network 를 DQN 인스턴스를 생성하여 연산 device 메모리에 넣는다.</p>

<p>(2) self.target_network = copy.deepcopy(self.network)<br />
    초기 Target_network 설정은 훈련용과 동일하게 설정되므로 그대로 깊은 복사하여 사용</p>

<p>(3) self.memory = deque(maxlen=mem_maxlen) <br />
    replay memory 로 사용될 자료 구조는 FIFO 구조인 deque 를 사용</p>

<p>(4) self.epsilon = epsilon_init<br />
    초기 설정 epsilon 값으로 사용되며, 훈련이 반복되면서 앞에서 언급된 그래프의 형태와 같이 epsilon 값을 작게 하여 무작위 요소를 점차 줄여 나간다.</p>

<p>(5) if load_model == True:<br />
    만약 기존에 저장된 model 을 사용하고자 할 경우, 해당 조건문 실행으로 기존 모델을 가져와서 실행</p>

<h4 id="32-network-를-통한-action-선택-함수">3.2 network 를 통한 action 선택 함수</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    <span class="k">def</span> <span class="nf">get_action</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>

        <span class="n">self</span><span class="p">.</span><span class="n">network</span><span class="p">.</span><span class="nf">train</span><span class="p">(</span><span class="n">training</span><span class="p">)</span> 
        <span class="n">epsilon</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">epsilon</span> <span class="k">if</span> <span class="n">training</span> <span class="k">else</span> <span class="n">epsilon_eval</span>

        <span class="k">if</span> <span class="n">epsilon</span> <span class="o">&gt;</span> <span class="n">random</span><span class="p">.</span><span class="nf">random</span><span class="p">():</span>
            <span class="n">action</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">action_size</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">state</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">))</span> 
        <span class="k">else</span><span class="p">:</span>
            <span class="n">q</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">network</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nc">FloatTensor</span><span class="p">(</span><span class="n">state</span><span class="p">).</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">))</span>
            <span class="n">action</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">argmax</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="bp">True</span><span class="p">).</span><span class="n">data</span><span class="p">.</span><span class="nf">cpu</span><span class="p">().</span><span class="nf">numpy</span><span class="p">()</span> 
        <span class="k">return</span> <span class="n">action</span>
</code></pre></div></div>

<p>다음과 같이 epsilon-greedy 방법을 사용하여 무작위 값 또는 가장 큰 q값을 가진 idx 행동을 선택</p>

<center><img src="assets\img\posts\2024-05-03-DQN_ml_agents\5.png" width="400" /></center>
<p><a href="https://www.inflearn.com/course/%EC%9C%A0%EB%8B%88%ED%8B%B0-%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D-%EC%97%90%EC%9D%B4%EC%A0%84%ED%8A%B8-%EA%B8%B0%EC%B4%88">이미지 출처</a></p>

<h4 id="33-replay-memory-에-데이터-추가-함수">3.3 replay memory 에 데이터 추가 함수</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    <span class="k">def</span> <span class="nf">append_sample</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">next_state</span><span class="p">,</span> <span class="n">done</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">memory</span><span class="p">.</span><span class="nf">append</span><span class="p">((</span><span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">next_state</span><span class="p">,</span> <span class="n">done</span><span class="p">))</span>
</code></pre></div></div>

<p>replay momory 에 각 상태 값들을 추가</p>

<h4 id="34-network-parameter-학습-시키는-함수">3.4 network parameter 학습 시키는 함수</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">train_model</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="n">batch</span> <span class="o">=</span> <span class="n">random</span><span class="p">.</span><span class="nf">sample</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">memory</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span> <span class="c1"># (1)
</span>        <span class="n">state</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">stack</span><span class="p">([</span><span class="n">b</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">b</span>  <span class="ow">in</span> <span class="n">batch</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="c1"># (2)
</span>        <span class="n">action</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">stack</span><span class="p">([</span><span class="n">b</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">b</span>  <span class="ow">in</span> <span class="n">batch</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">reward</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">stack</span><span class="p">([</span><span class="n">b</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="k">for</span> <span class="n">b</span>  <span class="ow">in</span> <span class="n">batch</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">next_state</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">stack</span><span class="p">([</span><span class="n">b</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span> <span class="k">for</span> <span class="n">b</span>  <span class="ow">in</span> <span class="n">batch</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">done</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">stack</span><span class="p">([</span><span class="n">b</span><span class="p">[</span><span class="mi">4</span><span class="p">]</span> <span class="k">for</span> <span class="n">b</span>  <span class="ow">in</span> <span class="n">batch</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

        <span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">next_state</span><span class="p">,</span> <span class="n">done</span> <span class="o">=</span> <span class="nf">map</span><span class="p">(</span>
            <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="nc">FloatTensor</span><span class="p">(</span><span class="n">x</span><span class="p">).</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="p">[</span><span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">next_state</span><span class="p">,</span> <span class="n">done</span><span class="p">]</span>
        <span class="p">)</span> <span class="c1"># (3)
</span>
        <span class="n">eye</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">eye</span><span class="p">(</span><span class="n">action_size</span><span class="p">).</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span> <span class="c1"># (4)
</span>        <span class="n">one_hot_action</span> <span class="o">=</span> <span class="n">eye</span><span class="p">[</span><span class="n">action</span><span class="p">.</span><span class="nf">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">).</span><span class="nf">long</span><span class="p">()]</span> <span class="c1"># (5) 
</span>
        <span class="n">q</span> <span class="o">=</span> <span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="nf">network</span><span class="p">(</span><span class="n">state</span><span class="p">)</span> <span class="o">*</span> <span class="n">one_hot_action</span><span class="p">).</span><span class="nf">sum</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span> <span class="c1"># (6)
</span>
        <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="nf">no_grad</span><span class="p">():</span> <span class="c1"># (7)
</span>            <span class="n">next_q</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">target_network</span><span class="p">(</span><span class="n">next_state</span><span class="p">)</span> <span class="c1"># (8)
</span>            <span class="n">target_q</span> <span class="o">=</span> <span class="n">reward</span> <span class="o">+</span> <span class="n">next_q</span><span class="p">.</span><span class="nf">max</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="bp">True</span><span class="p">).</span><span class="n">values</span> <span class="o">*</span> <span class="p">((</span><span class="mi">1</span> <span class="o">-</span> <span class="n">done</span><span class="p">)</span> <span class="o">*</span> <span class="n">discount_factor</span><span class="p">)</span> <span class="c1">#(9)
</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="nf">smooth_l1_loss</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">target_q</span><span class="p">)</span> <span class="c1"># (10)
</span>
        <span class="c1"># model update
</span>        <span class="n">self</span><span class="p">.</span><span class="n">optimizer</span><span class="p">.</span><span class="nf">zero_grad</span><span class="p">()</span>  <span class="c1"># 기울기 초기화
</span>        <span class="n">loss</span><span class="p">.</span><span class="nf">backward</span><span class="p">()</span>             <span class="c1"># 역전파를 통해 gradient 계산
</span>        <span class="n">self</span><span class="p">.</span><span class="n">optimizer</span><span class="p">.</span><span class="nf">step</span><span class="p">()</span>       <span class="c1"># model parameter update
</span>        <span class="c1"># eps 감소 (훈련이 진행됨에 따라 무작위 적용 확률를 차츰 줄여나감)
</span>        <span class="n">self</span><span class="p">.</span><span class="n">epsilon</span> <span class="o">=</span> <span class="nf">max</span><span class="p">(</span><span class="n">epsilon_min</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">epsilon</span> <span class="o">-</span> <span class="n">eplsilon_data</span><span class="p">)</span> 

        <span class="k">return</span> <span class="n">loss</span><span class="p">.</span><span class="nf">item</span><span class="p">()</span>
</code></pre></div></div>

<p>(1) batch = random.sample(self.memory, batch_size)<br />
replay memory 에 저장된 값들 중 임의의 값을 가져옴으로써, 가져오는 데이터들 간 상관 관계가 존재하지 않게되어, 과적합 또는 선형 근사가 발생하는것을 방지 한다.</p>

<p>아래 이미지는 하나의 episode 또는 근방에서 훈련된 step 간 동일 색으로 표현하였다. 그림과 같이 근방의 step 끼리 학습을 진행하면 전체 데이터에 대한 근사 함수가 아닌 각각에 근접한 step 에 대한 함수로 각각 근사되게 된다.</p>

<center><img src="assets\img\posts\2024-05-03-DQN_ml_agents\6.png" width="480" /></center>
<p><a href="https://www.inflearn.com/course/%EC%9C%A0%EB%8B%88%ED%8B%B0-%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D-%EC%97%90%EC%9D%B4%EC%A0%84%ED%8A%B8-%EA%B8%B0%EC%B4%88">이미지 출처</a></p>

<p>따라서 해당 문제를 막기 위해 한번에 학습되는 step 들을 무작위 분포에서 추출해야 아래와 같이 전체에 대한 근사함수를 얻을 수 있게 된다.</p>

<center><img src="assets\img\posts\2024-05-03-DQN_ml_agents\7.png" width="220" /></center>
<p><a href="https://www.inflearn.com/course/%EC%9C%A0%EB%8B%88%ED%8B%B0-%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D-%EC%97%90%EC%9D%B4%EC%A0%84%ED%8A%B8-%EA%B8%B0%EC%B4%88">이미지 출처</a></p>

<p>(2) state = np.stack([b[0] for b  in batch], axis=0) <br />
추출된 batch 값에서 state, action, reward, next_state, done 값들을 각각의 array 값으로 추출한다.</p>

<p>(3) state, action, reward, next_state, done = map(
            lambda x: torch.FloatTensor(x).to(device), [state, action, reward, next_state, done]
        ) <br /></p>

<p>각 상태값들의 array 값들을 실수형 tensor 로 타입 변환 후, device 메모리에 추가</p>

<p>(4) eye = torch.eye(action_size).to(device) <br /></p>

<p>주 대각선 값 1, 나머지 요소는 0인 2차원 배열 (4 * 4 (action_size))을 생성하여 device 메모리에 추가</p>

<p>(5) one_hot_action = eye[action.view(-1).long()] <br /></p>

<p>action [0, 2, 3, 2, 1, 1, …] (0~3) 의 값 * 32 np array 에서 각각의 원소를 long 형 (int64) one_hot type * 32 형 으로 변경 한다. 
즉 [0, 2, 3, 2, 1, 1, …]  -&gt; [[1, 0, 0, 0], [0, 0, 1, 0], [0, 0, 0, 1], [0, 0, 0, 1], ….]</p>

<p>(6) q = (self.network(state) * one_hot_action).sum(1, keepdims=True)<br /></p>

<p>현재 상태에 대한 모델 q값 * one_hot_action = 선택된 action 에 대한 Q(x) 값 이외 값은 0 으로 변환하여 각 q값 ([32.334, 0, 0, 0]) 과 같은 형태에서 ([[\32.334]]) 로변환하여 q에 저장한다. (즉, one_hot data 에서 0 인 부분은 모두 제거 한다.)</p>

<p>(7) with torch.no_grad(): <br /></p>

<p>loss 를 계산하기 위해서 target 값이 필요하지만, target 값에 대한 제어는 별도로 이루어지므로 target 값을 얻는 과정이 network 에 영향을 주어서는 안되므로 with  문 내부에서 torch.no_grad() (gradient 추적이 되지 않는) 상태에서 값을 얻는다.</p>

<p>(8) next_q = self.target_network(next_state) <br /></p>

<p>next_q : target network 을 이용하요 다음상태 s’ 에대한 q 값들을 예측함.</p>

<p>(9) target_q = reward + next_q.max(1, keepdims=True).values * ((1 - done) * discount_factor) <br /></p>

<ul>
  <li>.max(1, keepdims=True).values : (0 차원: batch , 1 차원, action) 에서 action 차원의 최대값을 가져옴</li>
  <li>(1 - done) : done == False 이면 1 True 이면 해당 값은 0 이 됨.</li>
  <li>discount_factor : 감가율을 곱함.</li>
</ul>

<center><img src="assets\img\posts\2024-05-03-DQN_ml_agents\10.png" width="370" /></center>

<p>즉 벨만 방정식 최적 q 를 얻는 공식  target_q = 보상값 + 감가율(다음 상태에서의 최대 Q(x)값) 을 구함 + 혹시 끝난 상태인 경우 0으로 만들어 주는 수식을 결합한 상태</p>

<p>(10) loss = F.smooth_l1_loss(q, target_q) <br /></p>

<p>Huber loss 계산</p>

<center><img src="assets\img\posts\2024-05-03-DQN_ml_agents\8.png" width="220" /></center>

<center><img src="assets\img\posts\2024-05-03-DQN_ml_agents\9.png" width="280" /></center>
<p><a href="https://www.inflearn.com/course/%EC%9C%A0%EB%8B%88%ED%8B%B0-%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D-%EC%97%90%EC%9D%B4%EC%A0%84%ED%8A%B8-%EA%B8%B0%EC%B4%88">이미지 출처</a></p>

<h4 id="35-target_network-update-함수">3.5 target_network update 함수</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    <span class="k">def</span> <span class="nf">update_target</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">target_network</span><span class="p">.</span><span class="nf">load_state_dict</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">network</span><span class="p">.</span><span class="nf">state_dict</span><span class="p">())</span>
</code></pre></div></div>

<ul>
  <li>self.network.state_dict() : 일반 (훈련) 네트워크를 가져옴</li>
  <li>self.target_network.load_state_dict() : 가져운 일반 네트워크를 target 네트워크로 저장</li>
</ul>

<h3 id="4-프로그램-동작-구현-main">4. 프로그램 동작 구현 (main)</h3>

<p>아래 도식의 동작을 구현</p>

<center><img src="assets\img\posts\2024-05-03-DQN_ml_agents\11.png" width="600" /></center>
<p><a href="https://www.inflearn.com/course/%EC%9C%A0%EB%8B%88%ED%8B%B0-%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D-%EC%97%90%EC%9D%B4%EC%A0%84%ED%8A%B8-%EA%B8%B0%EC%B4%88">이미지 출처</a></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="sh">'</span><span class="s">__main__</span><span class="sh">'</span><span class="p">:</span>
    <span class="c1"># 4.1 unity 와 상호 작용이 가능한 UnityEnvironment 인스턴스(env) 생성
</span>    <span class="n">engine_configuration_channel</span> <span class="o">=</span> <span class="nc">EngineConfigurationChannel</span><span class="p">()</span>
    <span class="n">env</span> <span class="o">=</span> <span class="nc">UnityEnbironment</span><span class="p">(</span>
        <span class="n">file_name</span><span class="o">=</span><span class="n">env_name</span><span class="p">,</span> <span class="n">side_channels</span><span class="o">=</span><span class="p">[</span><span class="n">engine_configuration_channel</span><span class="p">]</span>
    <span class="p">)</span>
    <span class="n">env</span><span class="p">.</span><span class="nf">reset</span><span class="p">()</span>

    <span class="c1"># 4.2 env 로 부터 관측/target 공간 정보, step 진행 후 정보 및 구동 환경(time scale) 설정
</span>    <span class="n">behavior_name</span> <span class="o">=</span> <span class="nf">list</span><span class="p">(</span><span class="n">env</span><span class="p">.</span><span class="n">behavior_specs</span><span class="p">.</span><span class="nf">keys</span><span class="p">())[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">spec</span> <span class="o">=</span> <span class="n">env</span><span class="p">.</span><span class="n">behavior_specs</span><span class="p">[</span><span class="n">behavior_name</span><span class="p">]</span>

    <span class="n">engine_configuration_channel</span><span class="p">.</span><span class="nf">set_configuration_parameters</span><span class="p">(</span><span class="n">time_scale</span><span class="o">=</span><span class="mf">12.0</span><span class="p">)</span>
    <span class="n">dec</span><span class="p">,</span> <span class="n">term</span> <span class="o">=</span> <span class="n">env</span><span class="p">.</span><span class="nf">get_steps</span><span class="p">(</span><span class="n">behavior_name</span><span class="p">)</span> 
    <span class="n">agent</span> <span class="o">=</span> <span class="nc">DQNAgent</span><span class="p">()</span>

    <span class="n">losses</span><span class="p">,</span> <span class="n">scores</span><span class="p">,</span> <span class="n">episode</span><span class="p">,</span> <span class="n">score</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[],</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span>
    
    <span class="c1"># 4.3 반복문을 통해 run_step + test_step 동안 학습을 진행시킴
</span>    <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">run_step</span> <span class="o">+</span> <span class="n">test_step</span><span class="p">):</span>
        <span class="c1"># 4.3.1 (run_step 마지막 단계에서 모델을 저장하고 test_mode 로 전환)
</span>        <span class="k">if</span> <span class="n">step</span> <span class="o">==</span> <span class="n">run_step</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">train_mode</span><span class="p">:</span>
                <span class="n">agent</span><span class="p">.</span><span class="nf">save_model</span><span class="p">()</span>
            <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">TEST START</span><span class="sh">"</span><span class="p">)</span>
            <span class="n">train_mode</span> <span class="o">=</span> <span class="bp">False</span>
            <span class="n">engine_configuration_channel</span><span class="p">.</span><span class="nf">set_configuration_parameters</span><span class="p">(</span><span class="n">time_scale</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span> 

        <span class="c1"># 4.3.2 전처리: 시각적 관측 정보와 목적지 관측 정보를 전처리하여 state 로 저장
</span>        <span class="n">preprocess</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">obs</span><span class="p">,</span> <span class="n">goal</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="nf">concatenate</span><span class="p">((</span><span class="n">obs</span><span class="o">*</span><span class="n">goal</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="n">obs</span><span class="o">*</span><span class="n">goal</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">]),</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>        
        
        <span class="n">state</span> <span class="o">=</span> <span class="nf">preprocess</span><span class="p">(</span><span class="n">dec</span><span class="p">.</span><span class="n">obs</span><span class="p">[</span><span class="n">OBS</span><span class="p">],</span> <span class="n">dec</span><span class="p">.</span><span class="n">obs</span><span class="p">[</span><span class="n">GOAL_OBS</span><span class="p">])</span>

        <span class="c1"># 4.3.3 agent 를 통해 action 을 결정하고, 해당 action 으로 unity 에서 다음 step 을 진행시킴
</span>        <span class="n">action</span> <span class="o">=</span> <span class="n">agent</span><span class="p">.</span><span class="nf">get_action</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">train_mode</span><span class="p">)</span> 
        <span class="n">real_action</span> <span class="o">=</span> <span class="n">action</span> <span class="o">+</span> <span class="mi">1</span> 
        <span class="n">action_tuple</span> <span class="o">=</span> <span class="nc">ActionTuple</span><span class="p">()</span> 
        <span class="n">action_tuple</span><span class="p">.</span><span class="nf">add_discrete</span><span class="p">(</span><span class="n">real_action</span><span class="p">)</span> 
        <span class="n">env</span><span class="p">.</span><span class="nf">set_actions</span><span class="p">(</span><span class="n">behavior_name</span><span class="p">,</span> <span class="n">action_tuple</span><span class="p">)</span> 
        <span class="n">env</span><span class="p">.</span><span class="nf">step</span><span class="p">()</span> 

        <span class="c1"># 4.3.4 진행된 현재 step 정보 가져옴
</span>        <span class="n">dec</span><span class="p">,</span> <span class="n">term</span> <span class="o">=</span> <span class="n">env</span><span class="p">.</span><span class="nf">get_steps</span><span class="p">(</span><span class="n">behavior_name</span><span class="p">)</span> 

        <span class="c1"># 4.3.5 종료(termination) 확인 및 next_step -&gt; next_state 정보로 전처리
</span>        <span class="n">done</span> <span class="o">=</span> <span class="nf">len</span><span class="p">(</span><span class="n">term</span><span class="p">.</span><span class="n">agent_id</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span> 
        <span class="n">reward</span> <span class="o">=</span> <span class="n">term</span><span class="p">.</span><span class="n">reward</span> <span class="k">if</span> <span class="n">done</span> <span class="k">else</span> <span class="n">dec</span><span class="p">.</span><span class="n">reward</span>
        <span class="n">next_state</span> <span class="o">=</span> <span class="nf">preprocess</span><span class="p">(</span><span class="n">term</span><span class="p">.</span><span class="n">obs</span><span class="p">[</span><span class="n">OBS</span><span class="p">],</span> <span class="n">term</span><span class="p">.</span><span class="n">obs</span><span class="p">[</span><span class="n">GOAL_OBS</span><span class="p">])</span> <span class="k">if</span> <span class="n">done</span> \
            <span class="k">else</span> <span class="nf">preprocess</span><span class="p">(</span><span class="n">dec</span><span class="p">.</span><span class="n">obs</span><span class="p">[</span><span class="n">OBS</span><span class="p">],</span> <span class="n">dec</span><span class="p">.</span><span class="n">obs</span><span class="p">[</span><span class="n">GOAL_OBS</span><span class="p">])</span>
        <span class="n">score</span> <span class="o">+=</span> <span class="n">reward</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> 

        <span class="c1"># 4.3.6 (train mode 일 경우) next_state 를 replay memory 에 저장
</span>        <span class="k">if</span> <span class="n">train_mode</span><span class="p">:</span>
            <span class="n">agent</span><span class="p">.</span><span class="nf">append_sample</span><span class="p">(</span><span class="n">state</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">action</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">reward</span><span class="p">,</span> <span class="n">next_state</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="n">done</span><span class="p">])</span>

        <span class="c1"># 4.3.7 충분히 메모리에 state 정보가 차 있다면, 모델 학습으로 손실값을 계산하고, 일정 주기로 target_model 을 update 함.
</span>        <span class="k">if</span> <span class="n">train_mode</span> <span class="ow">and</span> <span class="n">step</span> <span class="o">&gt;</span> <span class="nf">max</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">train_start_step</span><span class="p">):</span> 
            <span class="n">loss</span> <span class="o">=</span> <span class="n">agent</span><span class="p">.</span><span class="nf">train_model</span><span class="p">()</span>
            <span class="n">losses</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">step</span> <span class="o">%</span> <span class="n">target_update_step</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">agent</span><span class="p">.</span><span class="nf">update_target</span><span class="p">()</span>

        <span class="c1"># 4.3.8 episode 종료 시, 필요한 설정값을 조정하고, tensorboard 에 보상/손실 값을 기록, 필요 조건마다 훈련된 모델 저장
</span>        <span class="k">if</span> <span class="n">done</span><span class="p">:</span>
            <span class="n">episode</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="n">scores</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">score</span><span class="p">)</span>
            <span class="n">score</span> <span class="o">=</span> <span class="mi">0</span> 

            <span class="k">if</span> <span class="n">episode</span> <span class="o">%</span> <span class="n">print_interval</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">mean_score</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">mean</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span>
                <span class="n">mean_loss</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">mean</span><span class="p">(</span><span class="n">losses</span><span class="p">)</span>
                <span class="n">agent</span><span class="p">.</span><span class="nf">write_summary</span><span class="p">(</span><span class="n">mean_score</span><span class="p">,</span> <span class="n">mean_loss</span><span class="p">,</span> <span class="n">agent</span><span class="p">.</span><span class="n">epsilon</span><span class="p">,</span> <span class="n">step</span><span class="p">)</span>
                <span class="n">losses</span><span class="p">,</span> <span class="n">scores</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>

                <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="si">{</span><span class="n">episode</span><span class="si">}</span><span class="s"> Episode / Step: </span><span class="si">{</span><span class="n">step</span><span class="si">}</span><span class="s"> / Score: </span><span class="si">{</span><span class="n">mean_score</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="s"> /</span><span class="sh">"</span> <span class="o">+</span> \
                      <span class="sa">f</span><span class="sh">"</span><span class="s">Loss: </span><span class="si">{</span><span class="n">mean_loss</span><span class="si">:</span><span class="p">.</span><span class="mi">4</span><span class="n">f</span><span class="si">}</span><span class="s"> / Epsilon: </span><span class="si">{</span><span class="n">agent</span><span class="p">.</span><span class="n">epsilon</span><span class="si">:</span><span class="p">.</span><span class="mi">4</span><span class="n">f</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>            
            
            <span class="k">if</span> <span class="n">train_mode</span> <span class="ow">and</span> <span class="n">episode</span> <span class="o">%</span> <span class="n">save_interval</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">agent</span><span class="p">.</span><span class="nf">save_model</span><span class="p">()</span>

    <span class="n">env</span><span class="p">.</span><span class="nf">close</span><span class="p">()</span>
</code></pre></div></div>

<h4 id="41-unity-와-상호-작용이-가능한-unityenvironment-인스턴스env-생성">4.1 unity 와 상호 작용이 가능한 UnityEnvironment 인스턴스(env) 생성</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    <span class="n">engine_configuration_channel</span> <span class="o">=</span> <span class="nc">EngineConfigurationChannel</span><span class="p">()</span>
    <span class="n">env</span> <span class="o">=</span> <span class="nc">UnityEnvironment</span><span class="p">(</span>
        <span class="n">file_name</span><span class="o">=</span><span class="n">env_name</span><span class="p">,</span> <span class="n">side_channels</span><span class="o">=</span><span class="p">[</span><span class="n">engine_configuration_channel</span><span class="p">]</span>
    <span class="p">)</span>
    <span class="n">env</span><span class="p">.</span><span class="nf">reset</span><span class="p">()</span>
</code></pre></div></div>

<p>env (UnityEnvironment 인스턴스)의 역할 및 기능</p>

<ol>
  <li>
    <p>유니티와의 인터페이스: UnityEnvironment는 유니티 엔진과 파이썬 코드 간의 주요 인터페이스. 이 인스턴스를 통해 유니티 게임 환경을 시작, 중지 및 관리할 수 있다.</p>
  </li>
  <li>
    <p>데이터 교환: 유니티 게임 환경에서 생성된 데이터(에이전트의 관측값, 보상 등)를 파이썬으로 전송하고, 파이썬에서 생성한 행동 지시를 유니티로 보내는 역할</p>
  </li>
  <li>
    <p>환경 제어: side_channels을 통해 유니티 환경의 세부적인 설정을 조정할 수 있다. 이를 통해 학습 중 시뮬레이션의 속도를 조절, 테스트 중에는 보다 정밀한 테스트를 수행 가능</p>
  </li>
</ol>

<ul>
  <li>file_name=env_name : 유니티 게임 환경의  실행 파일 경로를 지정</li>
  <li>side_channels=[engine_configuration_channel] : 유니티 환경의 timescale, 해상도, 그래픽 품질 등을 수정할 때 사용</li>
</ul>

<h4 id="42-env-로-부터-관측target-공간-정보-step-진행-후-정보-및-구동-환경time-scale-설정-유니티-브레인-설정">4.2 env 로 부터 관측/target 공간 정보, step 진행 후 정보 및 구동 환경(time scale) 설정 (유니티 브레인 설정)</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    <span class="c1"># 유니티 브레인 설정
</span>    <span class="n">behavior_name</span> <span class="o">=</span> <span class="nf">list</span><span class="p">(</span><span class="n">env</span><span class="p">.</span><span class="n">behavior_specs</span><span class="p">.</span><span class="nf">keys</span><span class="p">())[</span><span class="mi">0</span><span class="p">]</span>
    <span class="c1"># env.behavior_specs : 모든 behavior 정보 (예: 관측 공간의 크기, 행동의 유형 및 크기 등)를 가지고 있음. 
</span>    <span class="c1"># 해당 프로젝트에서는 behavior_sepc 중  behavior_name 만 있으면 된다. 해당 spec 은 첫번쩨 요소 이므로 [0] 의 값만 가져온다.
</span>    
    <span class="n">spec</span> <span class="o">=</span> <span class="n">env</span><span class="p">.</span><span class="n">behavior_specs</span><span class="p">[</span><span class="n">behavior_name</span><span class="p">]</span>
    <span class="c1"># behavior_name 에 대한 spec 을 가져오며 관련 정보는 아래와 같다. 
</span>    <span class="c1"># 1. 관측 공간(Obervation Space) : 에이전트가 환경에서 관측할 수 있는 데이터의 형태와 크기를 설명
</span>    <span class="c1">#                                  카메라 이미지, 속도계의 값, 위치 좌표 등
</span>    <span class="c1">#
</span>    <span class="c1"># 2. 행동 공간(Action Space) : 에이전트가 취할 수 있는 행동의 유형과 범위
</span>    <span class="c1">#                             에이전트가 조종할 수 있는 방향, 속도 조절, 점프 등의 행동
</span>
    <span class="n">engine_configuration_channel</span><span class="p">.</span><span class="nf">set_configuration_parameters</span><span class="p">(</span><span class="n">time_scale</span><span class="o">=</span><span class="mf">12.0</span><span class="p">)</span> <span class="c1"># 시간 12 배속 (빠르게) 설정
</span>    <span class="n">dec</span><span class="p">,</span> <span class="n">term</span> <span class="o">=</span> <span class="n">env</span><span class="p">.</span><span class="nf">get_steps</span><span class="p">(</span><span class="n">behavior_name</span><span class="p">)</span> <span class="c1"># behavior_name 으로 부터  step 정보를 얻음
</span>    <span class="c1"># dec : decision step - decision request step 정보
</span>    <span class="c1"># term : termination step - 에피소드 종료 스텝 정보
</span>
    <span class="c1"># DQNAgent 클래스를 agent 객체 생성
</span>    <span class="n">agent</span> <span class="o">=</span> <span class="nc">DQNAgent</span><span class="p">()</span>

    <span class="c1"># c.0 학습을 진행하기 위해 필요한 정보 초기화
</span>    <span class="n">losses</span><span class="p">,</span> <span class="n">scores</span><span class="p">,</span> <span class="n">episode</span><span class="p">,</span> <span class="n">score</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[],</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span>
</code></pre></div></div>

<h4 id="43-반복문을-통해-run_step--test_step-동안-학습을-진행시킴">4.3 반복문을 통해 run_step + test_step 동안 학습을 진행시킴</h4>

<h4 id="431-run_step-마지막-단계에서-모델을-저장하고-test_mode-로-전환">4.3.1 (run_step 마지막 단계에서 모델을 저장하고 test_mode 로 전환)</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">run_step</span> <span class="o">+</span> <span class="n">test_step</span><span class="p">):</span>
    <span class="c1"># run_step : 학습 모드 step
</span>    <span class="c1"># test_step: 테스트모드 step
</span>
        <span class="c1"># test step 진행 코드
</span>        <span class="k">if</span> <span class="n">step</span> <span class="o">==</span> <span class="n">run_step</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">train_mode</span><span class="p">:</span>
                <span class="n">agent</span><span class="p">.</span><span class="nf">save_model</span><span class="p">()</span>
            <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">TEST START</span><span class="sh">"</span><span class="p">)</span>
            <span class="n">train_mode</span> <span class="o">=</span> <span class="bp">False</span>
            <span class="n">engine_configuration_channel</span><span class="p">.</span><span class="nf">set_configuration_parameters</span><span class="p">(</span><span class="n">time_scale</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>  <span class="c1"># test_step 은 정속으로 수행
</span>
</code></pre></div></div>

<h4 id="432-전처리-시각적-관측-정보와-목적지-관측-정보를-전처리하여-state-로-저장">4.3.2 전처리: 시각적 관측 정보와 목적지 관측 정보를 전처리하여 state 로 저장</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>        <span class="c1">#  전처리 : 시각적 관측 정보와 목적지 관측 정보를 전처리하여 state 에 저장
</span>        <span class="n">preprocess</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">obs</span><span class="p">,</span> <span class="n">goal</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="nf">concatenate</span><span class="p">((</span><span class="n">obs</span><span class="o">*</span><span class="n">goal</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="n">obs</span><span class="o">*</span><span class="n">goal</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">]),</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>        
        <span class="c1"># a. obs*goal[0][0] : agent 관즉 이미지 * goal[0][0] (goal_plus 이면 1, goal_ex 이면 0)
</span>        <span class="c1"># b. obs*goal[0][1] : agent 관측 이미지 * goal[0][1] (goal_plus 이면 0, goal_ex 이면 1)
</span>        <span class="c1"># 위 값을 concatenate
</span>        <span class="c1">#  -&gt;  6 채널 중  goal_plus 의 경우 전반부 3 채널에 대해 값이 채워지고, 나머지 3채널에 대한 값은 모두 0 으로 처리
</span>        <span class="c1">#  -&gt;  6 채널 중  goal_ex   의 경우 후반부 3 채널에 대해 값이 채워지고, 나머지 3채널에 대한 값은 모두 0 으로 처리
</span>        
        <span class="n">state</span> <span class="o">=</span> <span class="nf">preprocess</span><span class="p">(</span><span class="n">dec</span><span class="p">.</span><span class="n">obs</span><span class="p">[</span><span class="n">OBS</span><span class="p">],</span> <span class="n">dec</span><span class="p">.</span><span class="n">obs</span><span class="p">[</span><span class="n">GOAL_OBS</span><span class="p">])</span>
        <span class="c1"># dec.obs : 지정된 behavior_name 을 가진 모든 agent 에 대한 모든 관측을 포함하는 튜플
</span>        <span class="c1"># dec.obs[0] (OBS = 0 시각적 관측 idx) : 로 시각적 관측 정보를 얻을 수 있음.
</span>        <span class="c1"># dec.obs[1] (GOAL_OBS = 1 (시각적) 목적지 관측 idx) : 로 목적지의 시각적 정보를 얻음.
</span>        <span class="c1"># dec.obs[GOAL_OBS] 에서  goal_plus : [[1., 0]] / goal_ex: [[0., 1.]]
</span>
</code></pre></div></div>

<h4 id="433-agent-를-통해-action-을-결정하고-해당-action-으로-unity-에서-다음-step-을-진행시킴">4.3.3 agent 를 통해 action 을 결정하고, 해당 action 으로 unity 에서 다음 step 을 진행시킴</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>        <span class="n">action</span> <span class="o">=</span> <span class="n">agent</span><span class="p">.</span><span class="nf">get_action</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">train_mode</span><span class="p">)</span> <span class="c1"># get_action 을 통해 현재 state 의 eps-greedy 행동 선택
</span>        <span class="n">real_action</span> <span class="o">=</span> <span class="n">action</span> <span class="o">+</span> <span class="mi">1</span> <span class="c1"># unity 에서 0 은 정지 action 을 의미하게 되므로 , 0 ~3  -&gt; 1 ~ 4 로 +1
</span>        <span class="n">action_tuple</span> <span class="o">=</span> <span class="nc">ActionTuple</span><span class="p">()</span> 
        <span class="n">action_tuple</span><span class="p">.</span><span class="nf">add_discrete</span><span class="p">(</span><span class="n">real_action</span><span class="p">)</span> <span class="c1"># 신경망을 통해 결정된 action 값을 동작 값으로 저장 
</span>        <span class="n">env</span><span class="p">.</span><span class="nf">set_actions</span><span class="p">(</span><span class="n">behavior_name</span><span class="p">,</span> <span class="n">action_tuple</span><span class="p">)</span> <span class="c1"># action 을 unity 환경에 전달
</span>        <span class="n">env</span><span class="p">.</span><span class="nf">step</span><span class="p">()</span> <span class="c1"># unity 에서 시뮬레이션 step 진행
</span></code></pre></div></div>

<h4 id="434-진행된-현재-step-정보-가져옴">4.3.4 진행된 현재 step 정보 가져옴</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>        <span class="n">dec</span><span class="p">,</span> <span class="n">term</span> <span class="o">=</span> <span class="n">env</span><span class="p">.</span><span class="nf">get_steps</span><span class="p">(</span><span class="n">behavior_name</span><span class="p">)</span> <span class="c1"># 진행한 현재 스텝 정보 가져오기
</span></code></pre></div></div>

<h4 id="435-종료termination-확인-및-next_step---next_state-정보로-전처리">4.3.5 종료(termination) 확인 및 next_step -&gt; next_state 정보로 전처리</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>        <span class="n">done</span> <span class="o">=</span> <span class="nf">len</span><span class="p">(</span><span class="n">term</span><span class="p">.</span><span class="n">agent_id</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="c1"># 현재 시뮬레이션은 agent 가 1개 이므로 termination agent_id 가 존재하면  종료되었음을 바로 확인 가능 
</span>        <span class="n">reward</span> <span class="o">=</span> <span class="n">term</span><span class="p">.</span><span class="n">reward</span> <span class="k">if</span> <span class="n">done</span> <span class="k">else</span> <span class="n">dec</span><span class="p">.</span><span class="n">reward</span>
        <span class="n">next_state</span> <span class="o">=</span> <span class="nf">preprocess</span><span class="p">(</span><span class="n">term</span><span class="p">.</span><span class="n">obs</span><span class="p">[</span><span class="n">OBS</span><span class="p">],</span> <span class="n">term</span><span class="p">.</span><span class="n">obs</span><span class="p">[</span><span class="n">GOAL_OBS</span><span class="p">])</span> <span class="k">if</span> <span class="n">done</span> \
            <span class="k">else</span> <span class="nf">preprocess</span><span class="p">(</span><span class="n">dec</span><span class="p">.</span><span class="n">obs</span><span class="p">[</span><span class="n">OBS</span><span class="p">],</span> <span class="n">dec</span><span class="p">.</span><span class="n">obs</span><span class="p">[</span><span class="n">GOAL_OBS</span><span class="p">])</span>
        <span class="n">score</span> <span class="o">+=</span> <span class="n">reward</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="c1"># step 보상 누적
</span></code></pre></div></div>

<h4 id="436-train-mode-일-경우-next_state-를-replay-memory-에-저장">4.3.6 (train mode 일 경우) next_state 를 replay memory 에 저장</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>        <span class="c1"># replay memory 에  data 저장 (학습 모드)
</span>        <span class="k">if</span> <span class="n">train_mode</span><span class="p">:</span>
            <span class="n">agent</span><span class="p">.</span><span class="nf">append_sample</span><span class="p">(</span><span class="n">state</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">action</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">reward</span><span class="p">,</span> <span class="n">next_state</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="n">done</span><span class="p">])</span>
</code></pre></div></div>

<h4 id="437-충분히-메모리에-state-정보가-차-있다면-모델-학습으로-손실값을-계산하고-일정-주기로-target_model-을-update-함">4.3.7 충분히 메모리에 state 정보가 차 있다면, 모델 학습으로 손실값을 계산하고, 일정 주기로 target_model 을 update 함.</h4>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>        <span class="k">if</span> <span class="n">train_mode</span> <span class="ow">and</span> <span class="n">step</span> <span class="o">&gt;</span> <span class="nf">max</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">train_start_step</span><span class="p">):</span> <span class="c1"># 충분한 학습 데이터가 모였다면 (최소 batch_size 이상)
</span>            <span class="c1"># 학습수행
</span>            <span class="n">loss</span> <span class="o">=</span> <span class="n">agent</span><span class="p">.</span><span class="nf">train_model</span><span class="p">()</span>
            <span class="n">losses</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>

            <span class="c1"># 타겟 네트워크 업데이트 (특정 수의 step 타이밍 마다)
</span>            <span class="k">if</span> <span class="n">step</span> <span class="o">%</span> <span class="n">target_update_step</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">agent</span><span class="p">.</span><span class="nf">update_target</span><span class="p">()</span>

</code></pre></div></div>

<h4 id="438-episode-종료-시-필요한-설정값을-조정하고-tensorboard-에-보상손실-값을-기록-필요-조건마다-훈련된-모델-저장">4.3.8 episode 종료 시, 필요한 설정값을 조정하고, tensorboard 에 보상/손실 값을 기록, 필요 조건마다 훈련된 모델 저장</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>        <span class="c1"># episode 완료 시,
</span>        <span class="k">if</span> <span class="n">done</span><span class="p">:</span>
            <span class="n">episode</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="n">scores</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">score</span><span class="p">)</span>
            <span class="n">score</span> <span class="o">=</span> <span class="mi">0</span> <span class="c1"># 초기화
</span>
            <span class="c1"># 게임 진행 상황 출력 및 텐서 보드에 보상과 손실 함수 값 기록
</span>            <span class="k">if</span> <span class="n">episode</span> <span class="o">%</span> <span class="n">print_interval</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">mean_score</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">mean</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span>
                <span class="n">mean_loss</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">mean</span><span class="p">(</span><span class="n">losses</span><span class="p">)</span>
                <span class="n">agent</span><span class="p">.</span><span class="nf">write_summary</span><span class="p">(</span><span class="n">mean_score</span><span class="p">,</span> <span class="n">mean_loss</span><span class="p">,</span> <span class="n">agent</span><span class="p">.</span><span class="n">epsilon</span><span class="p">,</span> <span class="n">step</span><span class="p">)</span>
                <span class="n">losses</span><span class="p">,</span> <span class="n">scores</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>

                <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="si">{</span><span class="n">episode</span><span class="si">}</span><span class="s"> Episode / Step: </span><span class="si">{</span><span class="n">step</span><span class="si">}</span><span class="s"> / Score: </span><span class="si">{</span><span class="n">mean_score</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="s"> /</span><span class="sh">"</span> <span class="o">+</span> \
                      <span class="sa">f</span><span class="sh">"</span><span class="s">Loss: </span><span class="si">{</span><span class="n">mean_loss</span><span class="si">:</span><span class="p">.</span><span class="mi">4</span><span class="n">f</span><span class="si">}</span><span class="s"> / Epsilon: </span><span class="si">{</span><span class="n">agent</span><span class="p">.</span><span class="n">epsilon</span><span class="si">:</span><span class="p">.</span><span class="mi">4</span><span class="n">f</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>            
            

                
            <span class="c1"># 네트워크 모델 저장
</span>            <span class="k">if</span> <span class="n">train_mode</span> <span class="ow">and</span> <span class="n">episode</span> <span class="o">%</span> <span class="n">save_interval</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">agent</span><span class="p">.</span><span class="nf">save_model</span><span class="p">()</span>
                
    <span class="n">env</span><span class="p">.</span><span class="nf">close</span><span class="p">()</span>
</code></pre></div></div>

<h3 id="최종-전체-코드">최종 전체 코드</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="n">random</span>
<span class="kn">import</span> <span class="n">copy</span>
<span class="kn">import</span> <span class="n">datetime</span>
<span class="kn">import</span> <span class="n">platform</span> <span class="c1"># system (OS) 관련
</span><span class="kn">import</span> <span class="n">torch</span>
<span class="kn">import</span> <span class="n">torch.nn.functional</span> <span class="k">as</span> <span class="n">F</span>
<span class="kn">from</span> <span class="n">torch.utils.tensorboard</span> <span class="kn">import</span> <span class="n">SummaryWriter</span>
<span class="kn">from</span> <span class="n">collections</span> <span class="kn">import</span> <span class="n">deque</span>
<span class="kn">from</span> <span class="n">mlagents_envs.environment</span> <span class="kn">import</span> <span class="n">UnityEnvironment</span><span class="p">,</span> <span class="n">ActionTuple</span> 
<span class="kn">from</span> <span class="n">mlagents_envs.side_channel.engine_configuration_channel</span> <span class="kn">import</span> <span class="n">EngineConfigurationChannel</span> 

<span class="n">state_size</span> <span class="o">=</span> <span class="p">[</span><span class="mi">3</span><span class="o">*</span><span class="mi">2</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">84</span><span class="p">]</span> 
<span class="n">action_size</span> <span class="o">=</span> <span class="mi">4</span> 

<span class="n">load_model</span> <span class="o">=</span> <span class="bp">False</span> 
<span class="n">train_mode</span> <span class="o">=</span> <span class="bp">True</span>  

<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">32</span>
<span class="n">mem_maxlen</span> <span class="o">=</span> <span class="mi">10000</span>  
<span class="n">discount_factor</span> <span class="o">=</span> <span class="mf">0.9</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.00025</span> 

<span class="n">run_step</span> <span class="o">=</span> <span class="mi">50000</span> <span class="k">if</span> <span class="n">train_mode</span> <span class="k">else</span> <span class="mi">0</span> 
<span class="n">test_step</span> <span class="o">=</span> <span class="mi">5000</span>       
<span class="n">train_start_step</span> <span class="o">=</span> <span class="mi">5000</span> 
<span class="n">target_update_step</span> <span class="o">=</span> <span class="mi">500</span> 

<span class="n">print_interval</span> <span class="o">=</span> <span class="mi">10</span>     
<span class="n">save_interval</span> <span class="o">=</span> <span class="mi">100</span>     

<span class="n">epsilon_eval</span> <span class="o">=</span> <span class="mf">0.05</span>    
<span class="n">epsilon_init</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="k">if</span> <span class="n">train_mode</span> <span class="k">else</span> <span class="n">epsilon_eval</span> 
<span class="n">epsilon_min</span> <span class="o">=</span> <span class="mf">0.1</span>      
<span class="n">explore_step</span> <span class="o">=</span> <span class="n">run_step</span> <span class="o">*</span> <span class="mf">0.8</span> 
<span class="n">eplsilon_data</span> <span class="o">=</span> <span class="p">(</span><span class="n">epsilon_init</span> <span class="o">-</span> <span class="n">epsilon_min</span><span class="p">)</span> <span class="o">/</span> <span class="n">explore_step</span> <span class="k">if</span> <span class="n">train_mode</span> <span class="k">else</span> <span class="mf">0.05</span>

<span class="n">VISUAL_OBS</span> <span class="o">=</span> <span class="mi">0</span>  
<span class="n">GOAL_OBS</span> <span class="o">=</span> <span class="mi">1</span>   
<span class="n">VECTOR_OBS</span> <span class="o">=</span> <span class="mi">2</span>  
<span class="n">OBS</span> <span class="o">=</span> <span class="n">VISUAL_OBS</span> 

<span class="n">game</span> <span class="o">=</span> <span class="sh">"</span><span class="s">GridWorld</span><span class="sh">"</span>          
<span class="n">os_name</span> <span class="o">=</span> <span class="n">platform</span><span class="p">.</span><span class="nf">system</span><span class="p">()</span> 
<span class="k">if</span> <span class="n">os_name</span> <span class="o">==</span> <span class="sh">'</span><span class="s">Windows</span><span class="sh">'</span><span class="p">:</span>
    <span class="n">env_name</span> <span class="o">=</span> <span class="sa">f</span><span class="sh">"</span><span class="s">../envs/</span><span class="si">{</span><span class="n">game</span><span class="si">}</span><span class="s">_</span><span class="si">{</span><span class="n">os_name</span><span class="si">}</span><span class="s">/</span><span class="si">{</span><span class="n">game</span><span class="si">}</span><span class="sh">"</span> 
<span class="k">elif</span> <span class="n">os_name</span> <span class="o">==</span> <span class="sh">'</span><span class="s">Darwin</span><span class="sh">'</span><span class="p">:</span> 
    <span class="n">env_name</span> <span class="o">=</span> <span class="sa">f</span><span class="sh">"</span><span class="s">../envs/</span><span class="si">{</span><span class="n">game</span><span class="si">}</span><span class="s">_</span><span class="si">{</span><span class="n">os_name</span><span class="si">}</span><span class="sh">"</span>

<span class="n">date_time</span> <span class="o">=</span> <span class="n">datetime</span><span class="p">.</span><span class="n">datetime</span><span class="p">.</span><span class="nf">now</span><span class="p">().</span><span class="nf">strftime</span><span class="p">(</span><span class="sh">"</span><span class="s">%Y%m%d%H%M%S</span><span class="sh">"</span><span class="p">)</span>
<span class="n">save_path</span> <span class="o">=</span> <span class="sa">f</span><span class="sh">"</span><span class="s">./saved_models/</span><span class="si">{</span><span class="n">game</span><span class="si">}</span><span class="s">/DQN/</span><span class="si">{</span><span class="n">date_time</span><span class="si">}</span><span class="sh">"</span> 
<span class="n">load_path</span> <span class="o">=</span> <span class="sa">f</span><span class="sh">"</span><span class="s">./saved_models/</span><span class="si">{</span><span class="n">game</span><span class="si">}</span><span class="s">/DQN/20240503201212</span><span class="sh">"</span> 

<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">device</span><span class="p">(</span><span class="sh">"</span><span class="s">cuda</span><span class="sh">"</span> <span class="k">if</span> <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="nf">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="sh">"</span><span class="s">cpu</span><span class="sh">"</span><span class="p">)</span> 

<span class="k">class</span> <span class="nc">DQN</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">(</span><span class="n">DQN</span><span class="p">,</span> <span class="n">self</span><span class="p">).</span><span class="nf">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">Conv2d</span><span class="p">(</span>
            <span class="n">in_channels</span><span class="o">=</span><span class="n">state_size</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">out_channels</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">4</span>
            <span class="p">)</span>
        <span class="n">dim1</span> <span class="o">=</span> <span class="p">((</span><span class="n">state_size</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="mi">8</span><span class="p">)</span><span class="o">//</span><span class="mi">4</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="p">(</span><span class="n">state_size</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">-</span> <span class="mi">8</span><span class="p">)</span><span class="o">//</span><span class="mi">4</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
        
        <span class="n">self</span><span class="p">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">Conv2d</span><span class="p">(</span>
            <span class="n">in_channels</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">out_channels</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span>
            <span class="p">)</span>
        <span class="n">dim2</span> <span class="o">=</span> <span class="p">((</span><span class="n">dim1</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="mi">4</span><span class="p">)</span><span class="o">//</span><span class="mi">2</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="p">(</span><span class="n">dim1</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="mi">4</span><span class="p">)</span><span class="o">//</span><span class="mi">2</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
        
        <span class="n">self</span><span class="p">.</span><span class="n">conv3</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">Conv2d</span><span class="p">(</span>
            <span class="n">in_channels</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">out_channels</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span>
            <span class="p">)</span>
        <span class="n">dim3</span> <span class="o">=</span> <span class="p">((</span><span class="n">dim2</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="mi">3</span><span class="p">)</span><span class="o">//</span><span class="mi">1</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="p">(</span><span class="n">dim2</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="mi">3</span><span class="p">)</span><span class="o">//</span><span class="mi">1</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>

        <span class="n">self</span><span class="p">.</span><span class="n">flat</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">Flatten</span><span class="p">()</span> 
        <span class="n">self</span><span class="p">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="mi">64</span><span class="o">*</span><span class="n">dim3</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="n">dim3</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">512</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">q</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="n">action_size</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="nf">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span> 
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="nf">relu</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="nf">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="nf">relu</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="nf">conv2</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="nf">relu</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="nf">conv3</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">flat</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="nf">relu</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="nf">fc1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="nf">q</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">DQNAgent</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">network</span> <span class="o">=</span> <span class="nc">DQN</span><span class="p">().</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">target_network</span> <span class="o">=</span> <span class="n">copy</span><span class="p">.</span><span class="nf">deepcopy</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">network</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">optim</span><span class="p">.</span><span class="nc">Adam</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">network</span><span class="p">.</span><span class="nf">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">memory</span> <span class="o">=</span> <span class="nf">deque</span><span class="p">(</span><span class="n">maxlen</span><span class="o">=</span><span class="n">mem_maxlen</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">epsilon</span> <span class="o">=</span> <span class="n">epsilon_init</span>
        <span class="n">self</span><span class="p">.</span><span class="n">writer</span> <span class="o">=</span> <span class="nc">SummaryWriter</span><span class="p">(</span><span class="n">save_path</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">load_model</span> <span class="o">==</span> <span class="bp">True</span><span class="p">:</span> 
            <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">... Load Model from </span><span class="si">{</span><span class="n">load_path</span><span class="si">}</span><span class="s">/ckpt</span><span class="sh">"</span><span class="p">)</span>
            <span class="n">checkpoint</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">load</span><span class="p">(</span><span class="n">load_path</span><span class="o">+</span><span class="sh">'</span><span class="s">/ckpt</span><span class="sh">'</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="n">device</span><span class="p">)</span> 
            <span class="n">self</span><span class="p">.</span><span class="n">network</span><span class="p">.</span><span class="nf">load_state_dict</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">[</span><span class="sh">"</span><span class="s">network</span><span class="sh">"</span><span class="p">])</span>
            <span class="n">self</span><span class="p">.</span><span class="n">target_network</span><span class="p">.</span><span class="nf">load_state_dict</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">[</span><span class="sh">"</span><span class="s">network</span><span class="sh">"</span><span class="p">])</span>
            <span class="n">self</span><span class="p">.</span><span class="n">optimizer</span><span class="p">.</span><span class="nf">load_state_dict</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">[</span><span class="sh">"</span><span class="s">optimizer</span><span class="sh">"</span><span class="p">])</span>

    <span class="k">def</span> <span class="nf">get_action</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>

        <span class="n">self</span><span class="p">.</span><span class="n">network</span><span class="p">.</span><span class="nf">train</span><span class="p">(</span><span class="n">training</span><span class="p">)</span> 
        <span class="n">epsilon</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">epsilon</span> <span class="k">if</span> <span class="n">training</span> <span class="k">else</span> <span class="n">epsilon_eval</span>

        <span class="k">if</span> <span class="n">epsilon</span> <span class="o">&gt;</span> <span class="n">random</span><span class="p">.</span><span class="nf">random</span><span class="p">():</span>
            <span class="n">action</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">action_size</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">state</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">))</span> 
        <span class="k">else</span><span class="p">:</span>
            <span class="n">q</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">network</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nc">FloatTensor</span><span class="p">(</span><span class="n">state</span><span class="p">).</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">))</span>
            <span class="n">action</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">argmax</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="bp">True</span><span class="p">).</span><span class="n">data</span><span class="p">.</span><span class="nf">cpu</span><span class="p">().</span><span class="nf">numpy</span><span class="p">()</span> 
        <span class="k">return</span> <span class="n">action</span>
        
    <span class="k">def</span> <span class="nf">append_sample</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">next_state</span><span class="p">,</span> <span class="n">done</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">memory</span><span class="p">.</span><span class="nf">append</span><span class="p">((</span><span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">next_state</span><span class="p">,</span> <span class="n">done</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">train_model</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="n">batch</span> <span class="o">=</span> <span class="n">random</span><span class="p">.</span><span class="nf">sample</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">memory</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>
        <span class="n">state</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">stack</span><span class="p">([</span><span class="n">b</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">b</span>  <span class="ow">in</span> <span class="n">batch</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">action</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">stack</span><span class="p">([</span><span class="n">b</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">b</span>  <span class="ow">in</span> <span class="n">batch</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">reward</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">stack</span><span class="p">([</span><span class="n">b</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="k">for</span> <span class="n">b</span>  <span class="ow">in</span> <span class="n">batch</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">next_state</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">stack</span><span class="p">([</span><span class="n">b</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span> <span class="k">for</span> <span class="n">b</span>  <span class="ow">in</span> <span class="n">batch</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">done</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">stack</span><span class="p">([</span><span class="n">b</span><span class="p">[</span><span class="mi">4</span><span class="p">]</span> <span class="k">for</span> <span class="n">b</span>  <span class="ow">in</span> <span class="n">batch</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

        <span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">next_state</span><span class="p">,</span> <span class="n">done</span> <span class="o">=</span> <span class="nf">map</span><span class="p">(</span>
            <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="nc">FloatTensor</span><span class="p">(</span><span class="n">x</span><span class="p">).</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="p">[</span><span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">next_state</span><span class="p">,</span> <span class="n">done</span><span class="p">]</span>
        <span class="p">)</span>

        <span class="n">eye</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">eye</span><span class="p">(</span><span class="n">action_size</span><span class="p">).</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">one_hot_action</span> <span class="o">=</span> <span class="n">eye</span><span class="p">[</span><span class="n">action</span><span class="p">.</span><span class="nf">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">).</span><span class="nf">long</span><span class="p">()]</span> 

        <span class="n">q</span> <span class="o">=</span> <span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="nf">network</span><span class="p">(</span><span class="n">state</span><span class="p">)</span> <span class="o">*</span> <span class="n">one_hot_action</span><span class="p">).</span><span class="nf">sum</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

        <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="nf">no_grad</span><span class="p">():</span>
            <span class="n">next_q</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">target_network</span><span class="p">(</span><span class="n">next_state</span><span class="p">)</span>
            <span class="n">target_q</span> <span class="o">=</span> <span class="n">reward</span> <span class="o">+</span> <span class="n">next_q</span><span class="p">.</span><span class="nf">max</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="bp">True</span><span class="p">).</span><span class="n">values</span> <span class="o">*</span> <span class="p">((</span><span class="mi">1</span> <span class="o">-</span> <span class="n">done</span><span class="p">)</span> <span class="o">*</span> <span class="n">discount_factor</span><span class="p">)</span>

        <span class="n">loss</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="nf">smooth_l1_loss</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">target_q</span><span class="p">)</span>
 
        <span class="n">self</span><span class="p">.</span><span class="n">optimizer</span><span class="p">.</span><span class="nf">zero_grad</span><span class="p">()</span>  
        <span class="n">loss</span><span class="p">.</span><span class="nf">backward</span><span class="p">()</span>             
        <span class="n">self</span><span class="p">.</span><span class="n">optimizer</span><span class="p">.</span><span class="nf">step</span><span class="p">()</span>      
        <span class="n">self</span><span class="p">.</span><span class="n">epsilon</span> <span class="o">=</span> <span class="nf">max</span><span class="p">(</span><span class="n">epsilon_min</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">epsilon</span> <span class="o">-</span> <span class="n">eplsilon_data</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">loss</span><span class="p">.</span><span class="nf">item</span><span class="p">()</span>
    
    <span class="k">def</span> <span class="nf">update_target</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">target_network</span><span class="p">.</span><span class="nf">load_state_dict</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">network</span><span class="p">.</span><span class="nf">state_dict</span><span class="p">())</span>

    <span class="k">def</span> <span class="nf">save_model</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">... Save Model to </span><span class="si">{</span><span class="n">save_path</span><span class="si">}</span><span class="s">/ckpt ...</span><span class="sh">"</span><span class="p">)</span>
        <span class="n">torch</span><span class="p">.</span><span class="nf">save</span><span class="p">({</span>
            <span class="sh">"</span><span class="s">network</span><span class="sh">"</span> <span class="p">:</span> <span class="n">self</span><span class="p">.</span><span class="n">network</span><span class="p">.</span><span class="nf">state_dict</span><span class="p">(),</span>   
            <span class="sh">"</span><span class="s">optimizer</span><span class="sh">"</span> <span class="p">:</span> <span class="n">self</span><span class="p">.</span><span class="n">optimizer</span><span class="p">.</span><span class="nf">state_dict</span><span class="p">(),</span>
        <span class="p">},</span> <span class="n">save_path</span><span class="o">+</span><span class="sh">'</span><span class="s">/ckpt</span><span class="sh">'</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">write_summary</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">score</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">epsilon</span><span class="p">,</span> <span class="n">step</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">writer</span><span class="p">.</span><span class="nf">add_scalar</span><span class="p">(</span><span class="sh">"</span><span class="s">run/score</span><span class="sh">"</span><span class="p">,</span> <span class="n">score</span><span class="p">,</span> <span class="n">step</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">writer</span><span class="p">.</span><span class="nf">add_scalar</span><span class="p">(</span><span class="sh">"</span><span class="s">model/loss</span><span class="sh">"</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">step</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">writer</span><span class="p">.</span><span class="nf">add_scalar</span><span class="p">(</span><span class="sh">"</span><span class="s">model/epsilon</span><span class="sh">"</span><span class="p">,</span> <span class="n">epsilon</span><span class="p">,</span> <span class="n">step</span><span class="p">)</span>

<span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="sh">'</span><span class="s">__main__</span><span class="sh">'</span><span class="p">:</span>
    <span class="n">engine_configuration_channel</span> <span class="o">=</span> <span class="nc">EngineConfigurationChannel</span><span class="p">()</span>
    <span class="n">env</span> <span class="o">=</span> <span class="nc">UnityEnbironment</span><span class="p">(</span>
        <span class="n">file_name</span><span class="o">=</span><span class="n">env_name</span><span class="p">,</span> <span class="n">side_channels</span><span class="o">=</span><span class="p">[</span><span class="n">engine_configuration_channel</span><span class="p">]</span>
    <span class="p">)</span>
    <span class="n">env</span><span class="p">.</span><span class="nf">reset</span><span class="p">()</span>


    <span class="n">behavior_name</span> <span class="o">=</span> <span class="nf">list</span><span class="p">(</span><span class="n">env</span><span class="p">.</span><span class="n">behavior_specs</span><span class="p">.</span><span class="nf">keys</span><span class="p">())[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">spec</span> <span class="o">=</span> <span class="n">env</span><span class="p">.</span><span class="n">behavior_specs</span><span class="p">[</span><span class="n">behavior_name</span><span class="p">]</span>

    <span class="n">engine_configuration_channel</span><span class="p">.</span><span class="nf">set_configuration_parameters</span><span class="p">(</span><span class="n">time_scale</span><span class="o">=</span><span class="mf">12.0</span><span class="p">)</span>
    <span class="n">dec</span><span class="p">,</span> <span class="n">term</span> <span class="o">=</span> <span class="n">env</span><span class="p">.</span><span class="nf">get_steps</span><span class="p">(</span><span class="n">behavior_name</span><span class="p">)</span> 
    <span class="n">agent</span> <span class="o">=</span> <span class="nc">DQNAgent</span><span class="p">()</span>

    <span class="n">losses</span><span class="p">,</span> <span class="n">scores</span><span class="p">,</span> <span class="n">episode</span><span class="p">,</span> <span class="n">score</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[],</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span>
    
    <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">run_step</span> <span class="o">+</span> <span class="n">test_step</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">step</span> <span class="o">==</span> <span class="n">run_step</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">train_mode</span><span class="p">:</span>
                <span class="n">agent</span><span class="p">.</span><span class="nf">save_model</span><span class="p">()</span>
            <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">TEST START</span><span class="sh">"</span><span class="p">)</span>
            <span class="n">train_mode</span> <span class="o">=</span> <span class="bp">False</span>
            <span class="n">engine_configuration_channel</span><span class="p">.</span><span class="nf">set_configuration_parameters</span><span class="p">(</span><span class="n">time_scale</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span> 

        <span class="n">preprocess</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">obs</span><span class="p">,</span> <span class="n">goal</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="nf">concatenate</span><span class="p">((</span><span class="n">obs</span><span class="o">*</span><span class="n">goal</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="n">obs</span><span class="o">*</span><span class="n">goal</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">]),</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>        
        
        <span class="n">state</span> <span class="o">=</span> <span class="nf">preprocess</span><span class="p">(</span><span class="n">dec</span><span class="p">.</span><span class="n">obs</span><span class="p">[</span><span class="n">OBS</span><span class="p">],</span> <span class="n">dec</span><span class="p">.</span><span class="n">obs</span><span class="p">[</span><span class="n">GOAL_OBS</span><span class="p">])</span>

        <span class="n">action</span> <span class="o">=</span> <span class="n">agent</span><span class="p">.</span><span class="nf">get_action</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">train_mode</span><span class="p">)</span> 
        <span class="n">real_action</span> <span class="o">=</span> <span class="n">action</span> <span class="o">+</span> <span class="mi">1</span> 
        <span class="n">action_tuple</span> <span class="o">=</span> <span class="nc">ActionTuple</span><span class="p">()</span> 
        <span class="n">action_tuple</span><span class="p">.</span><span class="nf">add_discrete</span><span class="p">(</span><span class="n">real_action</span><span class="p">)</span> 
        <span class="n">env</span><span class="p">.</span><span class="nf">set_actions</span><span class="p">(</span><span class="n">behavior_name</span><span class="p">,</span> <span class="n">action_tuple</span><span class="p">)</span> 
        <span class="n">env</span><span class="p">.</span><span class="nf">step</span><span class="p">()</span> 

        <span class="n">dec</span><span class="p">,</span> <span class="n">term</span> <span class="o">=</span> <span class="n">env</span><span class="p">.</span><span class="nf">get_steps</span><span class="p">(</span><span class="n">behavior_name</span><span class="p">)</span> 
        <span class="n">done</span> <span class="o">=</span> <span class="nf">len</span><span class="p">(</span><span class="n">term</span><span class="p">.</span><span class="n">agent_id</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span> 
        <span class="n">reward</span> <span class="o">=</span> <span class="n">term</span><span class="p">.</span><span class="n">reward</span> <span class="k">if</span> <span class="n">done</span> <span class="k">else</span> <span class="n">dec</span><span class="p">.</span><span class="n">reward</span>
        <span class="n">next_state</span> <span class="o">=</span> <span class="nf">preprocess</span><span class="p">(</span><span class="n">term</span><span class="p">.</span><span class="n">obs</span><span class="p">[</span><span class="n">OBS</span><span class="p">],</span> <span class="n">term</span><span class="p">.</span><span class="n">obs</span><span class="p">[</span><span class="n">GOAL_OBS</span><span class="p">])</span> <span class="k">if</span> <span class="n">done</span> \
            <span class="k">else</span> <span class="nf">preprocess</span><span class="p">(</span><span class="n">dec</span><span class="p">.</span><span class="n">obs</span><span class="p">[</span><span class="n">OBS</span><span class="p">],</span> <span class="n">dec</span><span class="p">.</span><span class="n">obs</span><span class="p">[</span><span class="n">GOAL_OBS</span><span class="p">])</span>
        <span class="n">score</span> <span class="o">+=</span> <span class="n">reward</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> 

        <span class="k">if</span> <span class="n">train_mode</span><span class="p">:</span>
            <span class="n">agent</span><span class="p">.</span><span class="nf">append_sample</span><span class="p">(</span><span class="n">state</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">action</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">reward</span><span class="p">,</span> <span class="n">next_state</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="n">done</span><span class="p">])</span>

        <span class="k">if</span> <span class="n">train_mode</span> <span class="ow">and</span> <span class="n">step</span> <span class="o">&gt;</span> <span class="nf">max</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">train_start_step</span><span class="p">):</span> 
            <span class="n">loss</span> <span class="o">=</span> <span class="n">agent</span><span class="p">.</span><span class="nf">train_model</span><span class="p">()</span>
            <span class="n">losses</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">step</span> <span class="o">%</span> <span class="n">target_update_step</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">agent</span><span class="p">.</span><span class="nf">update_target</span><span class="p">()</span>

        <span class="k">if</span> <span class="n">done</span><span class="p">:</span>
            <span class="n">episode</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="n">scores</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">score</span><span class="p">)</span>
            <span class="n">score</span> <span class="o">=</span> <span class="mi">0</span> 

            <span class="k">if</span> <span class="n">episode</span> <span class="o">%</span> <span class="n">print_interval</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">mean_score</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">mean</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span>
                <span class="n">mean_loss</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">mean</span><span class="p">(</span><span class="n">losses</span><span class="p">)</span>
                <span class="n">agent</span><span class="p">.</span><span class="nf">write_summary</span><span class="p">(</span><span class="n">mean_score</span><span class="p">,</span> <span class="n">mean_loss</span><span class="p">,</span> <span class="n">agent</span><span class="p">.</span><span class="n">epsilon</span><span class="p">,</span> <span class="n">step</span><span class="p">)</span>
                <span class="n">losses</span><span class="p">,</span> <span class="n">scores</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>

                <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="si">{</span><span class="n">episode</span><span class="si">}</span><span class="s"> Episode / Step: </span><span class="si">{</span><span class="n">step</span><span class="si">}</span><span class="s"> / Score: </span><span class="si">{</span><span class="n">mean_score</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="s"> /</span><span class="sh">"</span> <span class="o">+</span> \
                      <span class="sa">f</span><span class="sh">"</span><span class="s">Loss: </span><span class="si">{</span><span class="n">mean_loss</span><span class="si">:</span><span class="p">.</span><span class="mi">4</span><span class="n">f</span><span class="si">}</span><span class="s"> / Epsilon: </span><span class="si">{</span><span class="n">agent</span><span class="p">.</span><span class="n">epsilon</span><span class="si">:</span><span class="p">.</span><span class="mi">4</span><span class="n">f</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>            
            
            <span class="k">if</span> <span class="n">train_mode</span> <span class="ow">and</span> <span class="n">episode</span> <span class="o">%</span> <span class="n">save_interval</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">agent</span><span class="p">.</span><span class="nf">save_model</span><span class="p">()</span>

    <span class="n">env</span><span class="p">.</span><span class="nf">close</span><span class="p">()</span>
</code></pre></div></div>]]></content><author><name>Yong gon Yun</name></author><category term="cuda" /><category term="pytorch" /><category term="unity" /><category term="dqn" /><category term="ml-agents" /><summary type="html"><![CDATA[Deep Q-Network + ML-agents 구현]]></summary></entry><entry><title type="html">(Windows) CUDA 사용 tensorflow 작업 환경 설정</title><link href="http://localhost:4000/tensorflow_gpu_setting.html" rel="alternate" type="text/html" title="(Windows) CUDA 사용 tensorflow 작업 환경 설정" /><published>2024-04-08T09:32:20+09:00</published><updated>2024-04-08T09:32:20+09:00</updated><id>http://localhost:4000/tensorflow_gpu_setting</id><content type="html" xml:base="http://localhost:4000/tensorflow_gpu_setting.html"><![CDATA[<style>
    summary::-webkit-details-marker {
        display: none;
    }
    summary {
        list-style: none;
    }
</style>

<details><summary></summary>
에러방지  에러방지 에러방지  에러방지 에러방지  에러방지 에러방지  에러방지
에러방지  에러방지 에러방지  에러방지 에러방지  에러방지 에러방지  에러방지
에러방지  에러방지 에러방지  에러방지 에러방지  에러방지 에러방지  에러방지
에러방지  에러방지 에러방지  에러방지 에러방지  에러방지 에러방지  에러방지
에러방지  에러방지 에러방지  에러방지 에러방지  에러방지 에러방지  에러방지
에러방지  에러방지 에러방지  에러방지 에러방지  에러방지 에러방지  에러방지
에러방지  에러방지 에러방지  에러방지 에러방지  에러방지 에러방지  에러방지
에러방지  에러방지 에러방지  에러방지 에러방지  에러방지 에러방지  에러방지
에러방지  에러방지 에러방지  에러방지 에러방지  에러방지 에러방지  에러방지
에러방지  에러방지 에러방지  에러방지 에러방지  에러방지 에러방지  에러방지
에러방지  에러방지 에러방지  에러방지 에러방지  에러방지 에러방지  에러방지
에러방지  에러방지 에러방지  에러방지 에러방지  에러방지 에러방지  에러방지
</details>

<p>tensflow 기반 딥러닝 학습을 하는데 cpu 기반 작업이 너무 느려서 GPU 를 사용하고자 하였으나 최신 자료는 없는것 같아 이를 다시 정리해 보았다. 다만 윈도우 환경에서 지원되는 CUDA toolkit 버젼은 그리 변화가 있지는 않았다.</p>

<ul>
  <li>사용환경</li>
  <li>OS: Windows 10  64bits</li>
  <li>GPU : RTX 3070</li>
  <li>GPU driver : Nvidia Graphic Driver 537.13</li>
  <li>CUDA Toolkit : 11.2</li>
  <li>Visual Studio : 2019</li>
  <li>cudnn : 8.2.1 (for cuda toolkit 11.x)</li>
  <li>python : 3.10</li>
  <li>Anacoda 가상환경 - jupyter notebook</li>
  <li>tensorflow-gpy : 2.10</li>
</ul>

<p>2024년 4월 기준, 아래 페이지에서 다음과 같이 윈도우 환경에서 Nvidia GPU 사용 환경 조건을 확인 할 수 있다. 
<a href="https://www.tensorflow.org/install/source_windows?hl=en">링크 : Tensorflow Build from source on Windows </a></p>

<center><img src="assets\img\posts\2024-04-08-tensorflow_gpu_setting.png" width="600" /></center>
<p><br /></p>

<h4 id="1nvidia-graphic-driver-설치-확인-및-전체-환경-설정-조건-확인">1.Nvidia Graphic Driver 설치 확인 및 전체 환경 설정 조건 확인</h4>

<p>아래와 같이 우선 cmd 에서  ‘nvidia-smi’명령어를 실행하여 그래픽 드라이버라 정상적으로 설치되었는지 확인하며, 이 때 ‘CUDA Version’ 을 확인한다.</p>

<center><img src="assets\img\posts\2024-04-08-tensorflow_gpu_settingnvidiasmi.png" width="600" /></center>

<p>만약 본인 GPU CUDA 버전과 Tensorflow 가이드에 명시된 버젼이 맞다면 해당 버젼에 맞게 모든 설정을 조정하면 된다. 그러나 내 경우와 같이 아직 해당 버젼이 지원하지 않는 경우, 낮춰 모든 설정을 적용해야 한다. 내 경우는 CUDA 11.2 로 적용하였다.</p>

<h4 id="2-cuda-tookit--cudnn-설치">2. CUDA Tookit &amp; cuDNN 설치</h4>

<p>아래 링크에서  CUDA Tookit 을 받아 설치한다. 
<a href="https://developer.nvidia.com/cuda-11.2.0-download-archive">CUDA Tookit 11.2 Downlaods</a></p>

<p>상위 버전의 경우, 필요한 경우 함께  visual studio 를 설치지만, 해당 버젼은 별도로 설치 해주어야 한다. 해당 버전에 맞는 visual studio 는 2019 로 아래 링크에서 다운로드 받아 추가 설치해야 한다. 
<a href="https://visualstudio.microsoft.com/ko/vs/older-downloads/">Visual Studio 2019 Download</a></p>

<p>그리고 아래 링크에서 본인에게 맞는 버전의 cuDNN 을 다운 받는다. 
<a href="https://developer.nvidia.com/rdp/cudnn-archive">cuDNN download</a></p>

<p>내 경우, 아래 버젼으로 받아 설치하였다.</p>

<center><img src="assets\img\posts\2024-04-08-tensorflow_gpu_setting_cudnn.png" width="600" /></center>

<p>해당 파일을 받아 압축을 풀고 내부 파일들을 모두 복사하여, CUDA Toolkit 이 설치된 폴더 ( C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.2)에 붙여 넣는다.</p>

<h4 id="3-환경변수-설정">3. 환경변수 설정</h4>

<p>앞에서 설치한 CUDA Toolkit 이 정상적으로 설치되었는지 확인과 함께 환경 변수 경로를 추가 해준다.
작업표시줄 검색창에서 “환경 변수” 를 검색하여 시스템 환경 변수 편집을 찾아 들어간다. 환경변수 버튼을 눌러서 들어가면 아래와 같이 창이 나오는데 여기에서 시스템 변수로 ‘CUDA_PATH’ 와 ‘CUDA_PATH_해당버전’ 이 포함되어 있어야 한다.</p>

<center><img src="assets\img\posts\2024-04-08-tensorflow_gpu_setting_env1.png" width="400" /></center>

<p>(다음 작업은 필요한지 잘 모르겠다.)
추가로 사용자 변수 - Path 에 아래와 같이 CUDA Toolkit  설치 경로에 bin, include, lib 폴더 경로를 추가한다.</p>

<center><img src="assets\img\posts\2024-04-08-tensorflow_gpu_setting_env2.png" width="500" /></center>

<h4 id="4-아나콘다-내-가상환경-설정-및-tensorflow-gpu-설치">4. 아나콘다 내 가상환경 설정 및 tensorflow-gpu 설치</h4>

<p>아나콘다를 최신 버전으로 설치하고, Anaconda Prompt 를 실행한다. 
여기서 가상환경을 추가할 때 phython 버젼을 앞에서 확인한 tensorflow-gpu 지원 버전을 설치한다. 내 경우는 3.10 으로 설치하여 진행하였다.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>conda create <span class="nt">-n</span> <span class="o">[</span>가상환경 이름] <span class="nv">python</span><span class="o">=</span>3.10
</code></pre></div></div>

<p>이후 해당 가상환경을 활성화 한다.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>conda activate <span class="o">[</span>가상환경이름]
</code></pre></div></div>

<p>그리고 tensorflow-gpu 를 홈페이지에서 확인한 버전으로 설치해 준다.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pip <span class="nb">install </span>tensorflow-gpu<span class="o">==</span>2.10
</code></pre></div></div>

<p>기타 필요한 라이브러리들을 설치하고, jupyter notebook 을 실행하기 위한 notebook 을 설치하고 jupyter notebook 을 실행한다.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pip <span class="nb">install </span>notebook
...
jupyter notebook
</code></pre></div></div>

<h4 id="5-jupyter-에서-tensorflow-gpu-정상-작동-확인">5. jupyter 에서 tensorflow-gpu 정상 작동 확인</h4>

<p>jupyter 커널에서 새 notebook 을 실행하여 아래 code 를 입력하여 gpu 가 정상적으로 연결되었는지를 확인한다.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>from tensorflow.python.client import device_lib
print<span class="o">(</span>device_lib.list_local_devices<span class="o">())</span>
</code></pre></div></div>

<p>코드를 실행하면 아래와 같이 출력되는데, 만약 GPU 연결이 되지 않았다면, CPU 정보만 출력되고, GPU 관련 정보는 출력되지 않는다.</p>

<center><img src="assets\img\posts\2024-04-08-tensorflow_gpu_setting_ju.png" width="600" /></center>

<p>만약 여기에서 CPU 만 잡힌 상태라면, 앞의 과정에서 무언가 잘못되었다는 의미이므로 다시 작업해야 한다. (개인적으로도 해당 설치까지 여러번 반복하였으며, 타 블로그 글에도 수차례 실패했다는 글이 많다.)</p>

<p>최종적으로 성공했다면, 이제 GPU 실행 환경으로 설정하고 사용하면 된다. 우측 상단에 ‘Python 3(ipkernel)’ 로 되어 있다면 클릭해서 본인이 생성한 가상환겅 (ex. b2404) 로 선택하여 사용하면 된다.</p>

<center><img src="assets\img\posts\2024-04-08-tensorflow_gpu_setting_ju1.png" width="600" /></center>]]></content><author><name>Yong gon Yun</name></author><category term="cuda" /><category term="cudnn" /><category term="tensorflow" /><summary type="html"><![CDATA[(Windows 10) CUDA 사용 tensorflow 작업 환경 설정]]></summary></entry><entry><title type="html">IPC 실습 05 - Named Semaphore</title><link href="http://localhost:4000/service-daemon.html" rel="alternate" type="text/html" title="IPC 실습 05 - Named Semaphore" /><published>2024-03-24T10:32:20+09:00</published><updated>2024-03-24T10:32:20+09:00</updated><id>http://localhost:4000/service-daemon</id><content type="html" xml:base="http://localhost:4000/service-daemon.html"><![CDATA[<style>
    summary::-webkit-details-marker {
        display: none;
    }
    summary {
        list-style: none;
    }
</style>

<details><summary></summary>
에러방지  에러방지 에러방지  에러방지 에러방지  에러방지 에러방지  에러방지
에러방지  에러방지 에러방지  에러방지 에러방지  에러방지 에러방지  에러방지
에러방지  에러방지 에러방지  에러방지 에러방지  에러방지 에러방지  에러방지
에러방지  에러방지 에러방지  에러방지 에러방지  에러방지 에러방지  에러방지
에러방지  에러방지 에러방지  에러방지 에러방지  에러방지 에러방지  에러방지
에러방지  에러방지 에러방지  에러방지 에러방지  에러방지 에러방지  에러방지
에러방지  에러방지 에러방지  에러방지 에러방지  에러방지 에러방지  에러방지
에러방지  에러방지 에러방지  에러방지 에러방지  에러방지 에러방지  에러방지
에러방지  에러방지 에러방지  에러방지 에러방지  에러방지 에러방지  에러방지
에러방지  에러방지 에러방지  에러방지 에러방지  에러방지 에러방지  에러방지
에러방지  에러방지 에러방지  에러방지 에러방지  에러방지 에러방지  에러방지
에러방지  에러방지 에러방지  에러방지 에러방지  에러방지 에러방지  에러방지
</details>

<p>아래 내용은 개발자를 위한 시스템 반도체 SW개발 기초(디바이스 드라이버 개발) (https://comento.kr/) 강의 내용 중 일부에 해당함.</p>

<h3 id="1-systemd-란">1. Systemd 란?</h3>

<p>커널이 가장 처음 띄우는 init 프로세스 (PID : 1)</p>
<ul>
  <li>
    <p>시스템을 초기화 하여 여려가지 서비스 데몬들을 띄우고 관리함. 예를 들어, 디바이스 노드를 자동을 생성하는 udev 데몬도 systemd 서비스로 구동됨.</p>
  </li>
  <li>
    <p>journalctl 을 사용하여 각 데몬의 로그도 저장 관리함.</p>
  </li>
  <li>
    <p>각 서비스 간의 의존성을 자동으로 관리</p>
  </li>
</ul>

<h4 id="기본-systemd-서비스-관리-명령어">기본 Systemd 서비스 관리 명령어</h4>

<ul>
  <li>systemctl status <서비스 이름=""> : 해당 서비스의 상태 조회</서비스></li>
  <li>systemclt enable/disable <서비스 이름=""> : 해당 서비스 활성화/비활성화</서비스></li>
  <li>systemclt start/stop <서비스 이름=""> : 해당 서비스 시작/종료</서비스></li>
  <li>
    <p>systemclt daemon-reload : 어떤 서비스를 수정하거나 추가했을 때 해당 명령를 통해 변경사항을 적용해줘양 함.</p>
  </li>
  <li>systemctl list-unit : 모든 서비스 목록 출력</li>
  <li>systemctl list-sockets : 서비스가 사요아는 소켓의 목록을 출력</li>
  <li>
    <p>systemctl list-dependencies : 서비스를 tree 구조로 의존성을 표시하여 출력</p>
  </li>
  <li>journalctl -fn : 모든 systemd 서비스 데몬들의 로그 출력</li>
  <li>journalctl -fn -u <서비스이름>.service : 모든 systemd 서비스 데몬들의 로그 출력</서비스이름></li>
</ul>

<h3 id="2-daemon-이란">2. Daemon 이란?</h3>

<p>여러 요청에 따라서 서비스를 제공하기 위해 백그라운드로 길게 떠 있는 프로세스</p>

<p>사용자가 직접 제어하지 않으며 init 시스템 등이 데몬을 관리하게 됨.</p>
<ul>
  <li>부모의 PID 는 1 (systemd) 이며 세션 및 그룩 아이디는 본인 자신이어야 함 - daemonize 과정 필요
    <ul>
      <li>init 프로세스에 입양시킨다고 표현되기도</li>
    </ul>
  </li>
</ul>

<h4 id="daemonnochdir-noclose">daemon(nochdir, noclose)</h4>

<p>데몬 프로세스를 생성 함수.</p>

<ul>
  <li>
    <p>nochdir   : 0 이면, daemon 함수는 루트 디렉토리(/)로 현재 작업 디렉토리를 변경, 1 이면 현재 디렉토리를 변경하지 않고 진행. 일반적으로 0 의 설정값을 가지며 그 이유는 데몬 프로세스가 파일 시스템을 마운트 해제하는데 방해가 되지 않도록 하기 위함이다.</p>
  </li>
  <li>
    <p>noclose   : 0이면, daemon 함수는 표준 입력(stdin), 표준 출력(stdout), 그리고 표준 에러(stderr)를 /dev/null로 리다이렉트. 만약 1이라면, 이러한 파일 디스크립터들을 리다이렉트하지 않음. 일반적으로 1의 값으로 설정되며 그 이유는 데몬 프로세스가 터미널과의 연결을 끊고, 백그라운드에서 조용히 실행되게 하고자함이다.</p>
  </li>
</ul>

<h4 id="데몬-생성-과정">데몬 생성 과정</h4>

<ol>
  <li>
    <p>프로세스 분기: 부모 프로세스를 종료하고 자식 프로세스를 백그라운드에서 실행하여 세션 리더가 되게 한다.</p>
  </li>
  <li>
    <p>세션 생성: 새로운 세션을 생성하여 프로세스 그룹 리더가 된다.</p>
  </li>
  <li>
    <p>작업 디렉토리 변경: 파일 시스템의 마운트 해제를 방지하기 위해 작업 디렉토리를 루트(/)로 변경(nochdir 0  인 경우).</p>
  </li>
  <li>
    <p>파일 모드 마스크 초기화: 새로 생성되는 파일과 디렉토리의 권한을 제어.</p>
  </li>
  <li>
    <p>표준 입출력 리다이렉트: 데몬 프로세스가 터미널과의 입출력 연결을 끊음(noclose 1 인 경우).</p>
  </li>
</ol>

<h3 id="3-서비스-데몬-개발">3. 서비스 데몬 개발</h3>

<p>구현하고자 하는 서비스 데몬은  systemd socket 활셩화하는 것이다.</p>

<p>구현 동작</p>

<ol>
  <li>systemd 소켓을 열고 listen 상태로 둠.</li>
  <li>소켓에 접속 요청이 들어오면, systemd 는 서비스 데몬을 실행</li>
  <li>서비스 데몬은 실행되었을 때, accept 부터 처리하게 됨.</li>
  <li>서비스 데몬이 더이상 처리할 것이 없으면 종료함.</li>
  <li>요청이 들어올 때마다 2~4번 작업을 반복함.</li>
</ol>

<p>구현 서비스 데몬 관련 내용 (이해가 안감…;;)</p>
<ul>
  <li>소켓으로의 접속이 없을 경우는 서비스 데몬을 열지 않아 메모리 절약 가능</li>
  <li>Accept = yse 까지 사용하면 accpet 도 systemd 가 해주나 성능상 이유로 추천되지는 않음.</li>
</ul>

<h3 id="4-코드-작성">4. 코드 작성</h3>

<p>1.1. 루트 파일 시스템의 /usr/lib/systemd/system 밑에 <서비스>.socket 파일 생성</서비스></p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">[</span>Unit]
<span class="nv">Description</span><span class="o">=</span>socket <span class="k">for </span>Comento Example
service

<span class="o">[</span>Socket]
<span class="nv">ListenStream</span><span class="o">=</span>/run/comento.sock

<span class="o">[</span>Install]
<span class="nv">WantedBy</span><span class="o">=</span>sockets.target
</code></pre></div></div>

<p>1.2. systemctl enable <서비스>.socket : 해당 소켓 켜기</서비스></p>
<ul>
  <li>소켓을 켜게 되면 ls -l /run/comento.sock 파일 생성</li>
</ul>

<p>2.1 루트파일 시스템의 /usr/lib/systemd/system 밑에 <서비스>.service 파일 생성</서비스></p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">[</span>Unit]
<span class="nv">Description</span><span class="o">=</span>Comento Example service

<span class="o">[</span>Service]
<span class="nv">Type</span><span class="o">=</span>forking
<span class="nv">ExecStart</span><span class="o">=</span>/usr/bin/comento-daemon
<span class="nv">StandardOutput</span><span class="o">=</span>journal
<span class="nv">Restart</span><span class="o">=</span>on-failure
<span class="nv">StartLimitIntervalSec</span><span class="o">=</span>1s
<span class="nv">StartLimitBurst</span><span class="o">=</span>32

<span class="o">[</span>Install]
<span class="nv">WantedBy</span><span class="o">=</span>basic.target
</code></pre></div></div>]]></content><author><name>Yong gon Yun</name></author><category term="linux" /><category term="IPC" /><category term="daemon" /><category term="shared systemd" /><category term="socket" /><summary type="html"><![CDATA[개발자를 위한 반도체 SW개발 기초 (디바이스 드라이버 개발) 관련 학습 20]]></summary></entry><entry><title type="html">IPC 실습 05 - Named Semaphore</title><link href="http://localhost:4000/IPC05.html" rel="alternate" type="text/html" title="IPC 실습 05 - Named Semaphore" /><published>2024-03-22T14:32:20+09:00</published><updated>2024-03-22T14:32:20+09:00</updated><id>http://localhost:4000/IPC05</id><content type="html" xml:base="http://localhost:4000/IPC05.html"><![CDATA[<style>
    summary::-webkit-details-marker {
        display: none;
    }
    summary {
        list-style: none;
    }
</style>

<details><summary></summary>
에러방지  에러방지 에러방지  에러방지 에러방지  에러방지 에러방지  에러방지
에러방지  에러방지 에러방지  에러방지 에러방지  에러방지 에러방지  에러방지
에러방지  에러방지 에러방지  에러방지 에러방지  에러방지 에러방지  에러방지
에러방지  에러방지 에러방지  에러방지 에러방지  에러방지 에러방지  에러방지
에러방지  에러방지 에러방지  에러방지 에러방지  에러방지 에러방지  에러방지
에러방지  에러방지 에러방지  에러방지 에러방지  에러방지 에러방지  에러방지
에러방지  에러방지 에러방지  에러방지 에러방지  에러방지 에러방지  에러방지
에러방지  에러방지 에러방지  에러방지 에러방지  에러방지 에러방지  에러방지
에러방지  에러방지 에러방지  에러방지 에러방지  에러방지 에러방지  에러방지
에러방지  에러방지 에러방지  에러방지 에러방지  에러방지 에러방지  에러방지
에러방지  에러방지 에러방지  에러방지 에러방지  에러방지 에러방지  에러방지
에러방지  에러방지 에러방지  에러방지 에러방지  에러방지 에러방지  에러방지
</details>

<p>아래 내용은 개발자를 위한 시스템 반도체 SW개발 기초(디바이스 드라이버 개발) (https://comento.kr/) 강의 내용 중 일부에 해당함.</p>

<h3 id="1-semaphore">1. Semaphore</h3>

<p>동시에 자원에 접근할 수 있는 스레드의 수를 제한하는 메커니즘. 일종의 카운터로, 특정 자원을 접근하려는 스레드의 수를 제어한다. 세마포어는 주로 두 가지 유형으로 나뉜다:</p>

<ul>
  <li>
    <p>이진 세마포어(Binary Semaphore): 값이 0 또는 1만 될 수 있으며, 이는 뮤텍스와 유사한 방식, 자원에 대한 독점적 접근을 제어하는데 사용됨.</p>
  </li>
  <li>
    <p>카운팅 세마포어(Counting Semaphore): 값이 정해진 범위 내에서 증가하거나 감소할 수 있으며, 동시에 여러 스레드가 자원에 접근할 수 있게 함.</p>
  </li>
</ul>

<p>(카운팅) 세마포어의 동작 과정</p>

<ol>
  <li>
    <p>읽기 작업 시작: 스레드가 읽기 작업을 시작하기 전, 쓰기 세마포어의 상태를 확인하여 쓰기 작업이 진행 중이지 않은지 확인한다. 그 후 읽기 세마포어의 카운트를 증가시켜 읽기 작업을 수행 중인 스레드의 수를 저장.</p>
  </li>
  <li>
    <p>읽기 작업 종료: 스레드가 읽기 작업을 마치면, 읽기 세마포어의 카운트를 감소시켜 읽기 작업을 수행 중인 스레드의 수를 감소시킨다.</p>
  </li>
  <li>
    <p>쓰기 작업 시작: 스레드가 쓰기 작업을 시작하기 전, 먼저 읽기 작업이 진행 중인지 확인하기 위해 읽기 세마포어의 카운트가 0이 될 때까지 기다린다. 이는 모든 읽기 작업이 완료됨을 의미합니다. 그 다음, 쓰기 세마포어를 잠금 상태로 전환하여 쓰기 작업을 시작한다.</p>
  </li>
  <li>
    <p>쓰기 작업 종료: 쓰기 작업을 마친 후, 쓰기 세마포어를 해제하여 다른 스레드가 읽기 또는 쓰기 작업을 시작할 수 있도록 한다.</p>
  </li>
</ol>

<p>위와 같은 방법을 통해 데이터를 쓰기 작업과 읽기 작업의 충돌을 예방할 수 있다. 다만 데이터의 일관성 (data consistency) 의 경우, 위와 같은 기본적인 세마포어로는 보장될 수 없다.</p>

<p>예를 들어 기존 데이터가 0 일때, 하나의 스레드에서  해당 값을 읽어서 +1 을 하고 나서 쓰고, 그 결과 (1)을 다른 스레드가 읽어서 -1 하여 0최종 0의 결과 값을 의도 했을 때, 단순히 읽는 과정이 마무리되었을 때 쓰기를 하는 형태로 구현한다면, 위의 과정에서 최종 결과가 0 일 수도 있고 1 이거나 -1 일 수도 있는 불확정한 상황이 발생할 수 있다.</p>

<p>이런 과정은 해당 작업 전체 (읽기-연산-쓰기) 과정에 lock 을 사용하여, 모든 작업이 작업의 절차가 분리되지 않고 하나의 덩어리르 처리되는 원자성이 보장되도록 처리하거나 하는 등의 방식을 사용하여 처리하여야 일관성을 유지할 수 있다.</p>

<h3 id="2-주요-함수">2. 주요 함수</h3>

<h4 id="sem_t-sem_openconst-char-name-int-oflag-mode_t-mode-unsigned-int-value">sem_t *sem_open(const char *name, int oflag, mode_t mode, unsigned int value);</h4>

<p>POSIX 세마포어를 생성하거나 열기 위한 함수</p>

<ul>
  <li>name  : 세마포어의 이름</li>
  <li>oflag : O_CREAT (세마포어가 존재하지 않을 경우 생성), O_EXCL (함께 O_CREAT와 사용되며, 세마포어가 이미 존재할 경우 실패), 등</li>
  <li>mode  : 세마포어에 대한 접근 권한을 설정 (e.g. 0600)</li>
  <li>valeu : 세마포어의 초기값. 이 값은 세마포어가 생성될 때만 의미가 있으며, 세마포어가 동시에 허용할 수 있는 최대 리소스 접근 수를 나타낸다. 예를 들어, 1로 설정할 경우, 해당 세마포어는 뮤텍스(mutex)와 유사하게 동작한다.</li>
</ul>

<h4 id="int-sem_waitsem_t-sem">int sem_wait(sem_t *sem);</h4>

<p>세마포어의 제어권 획득</p>

<ul>
  <li>sem   : 작업할 세마포어 객체에 대한 포인터</li>
</ul>

<h4 id="int-sem_postsem_t-sem">int sem_post(sem_t *sem);</h4>

<p>세마포어의 제어권 내려 놓음</p>

<ul>
  <li>sem   : 작업할 세마포어 객체에 대한 포인터</li>
</ul>

<h3 id="3-code">3. code</h3>

<div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cp">#include</span> <span class="cpf">&lt;fcntl.h&gt;</span><span class="cp">
#include</span> <span class="cpf">&lt;stdio.h&gt;</span><span class="cp">
#include</span> <span class="cpf">&lt;stdlib.h&gt;</span><span class="cp">
#include</span> <span class="cpf">&lt;string.h&gt;</span><span class="cp">
#include</span> <span class="cpf">&lt;unistd.h&gt;</span><span class="cp">
#include</span> <span class="cpf">&lt;sys/mman.h&gt;</span><span class="cp">
#include</span> <span class="cpf">&lt;sys/stat.h&gt;</span><span class="cp">
#include</span> <span class="cpf">&lt;sys/wait.h&gt;</span><span class="cp">
#include</span> <span class="cpf">&lt;semaphore.h&gt;</span><span class="cp">
</span>
<span class="cp">#define SEM_NAME "comento"
</span>
<span class="kt">int</span> <span class="nf">main</span><span class="p">(</span><span class="kt">int</span> <span class="n">argc</span><span class="p">,</span> <span class="kt">char</span> <span class="o">*</span><span class="n">argv</span><span class="p">[])</span> <span class="p">{</span>
    <span class="kt">int</span> <span class="o">*</span><span class="n">ptr</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">sem_init</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span> 
    <span class="n">sem_t</span> <span class="o">*</span><span class="n">sem</span><span class="p">;</span>
    <span class="n">pid_t</span> <span class="n">pid</span><span class="p">;</span>

    <span class="c1">// 동시 접근 가능 스레드 : 2 </span>
    <span class="c1">// -&gt; 두 스레드가 동시에 제어권을 가지므로써 데이터 일관성을 유지할 수 없는 상태로 만듬.</span>
    <span class="k">if</span><span class="p">(</span><span class="n">argc</span> <span class="o">==</span> <span class="mi">2</span> <span class="o">&amp;&amp;</span> <span class="o">!</span><span class="n">strcmp</span><span class="p">(</span><span class="n">argv</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="s">"-no-sem"</span><span class="p">))</span> <span class="p">{</span>
        <span class="n">sem_init</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>
    <span class="p">}</span>

    <span class="n">sem_unlink</span><span class="p">(</span><span class="n">SEM_NAME</span><span class="p">);</span> <span class="c1">// Remove semaphore if exists</span>
    <span class="n">sem</span> <span class="o">=</span> <span class="n">sem_open</span><span class="p">(</span><span class="n">SEM_NAME</span><span class="p">,</span> <span class="n">O_CREAT</span> <span class="o">|</span> <span class="n">O_EXCL</span><span class="p">,</span> <span class="mo">0600</span><span class="p">,</span> <span class="n">sem_init</span><span class="p">);</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">sem</span> <span class="o">==</span> <span class="n">SEM_FAILED</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">fprintf</span><span class="p">(</span><span class="n">stderr</span><span class="p">,</span> <span class="s">"Failed to create semaphore</span><span class="se">\n</span><span class="s">"</span><span class="p">);</span>
        <span class="k">return</span> <span class="mi">1</span><span class="p">;</span>
    <span class="p">}</span>

    <span class="n">printf</span><span class="p">(</span><span class="s">"Mapping an anonymous share memory</span><span class="se">\n</span><span class="s">"</span><span class="p">);</span>

    <span class="c1">// 익명의 공유 메모리 </span>
    <span class="c1">// 프로그램 내에서 바로 해당 메모리 포인터를 받아 부모-자식 간 사용할 것이므로 이름 없이 사용 가능</span>
    <span class="n">ptr</span> <span class="o">=</span> <span class="n">mmap</span><span class="p">(</span><span class="nb">NULL</span><span class="p">,</span> <span class="k">sizeof</span><span class="p">(</span><span class="o">*</span><span class="n">ptr</span><span class="p">),</span> <span class="n">PROT_READ</span> <span class="o">|</span> <span class="n">PROT_WRITE</span><span class="p">,</span> <span class="n">MAP_SHARED</span> <span class="o">|</span> <span class="n">MAP_ANONYMOUS</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">);</span>
    <span class="n">pid</span> <span class="o">=</span> <span class="n">fork</span><span class="p">();</span>

    <span class="c1">// 자식 프로세스는 1씩 10000 번 더하기 수행</span>
    <span class="k">if</span><span class="p">(</span><span class="n">pid</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
        <span class="k">for</span> <span class="p">(</span><span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="mi">10000</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
            <span class="n">sem_wait</span><span class="p">(</span><span class="n">sem</span><span class="p">);</span>
            <span class="p">(</span><span class="o">*</span><span class="n">ptr</span><span class="p">)</span><span class="o">++</span><span class="p">;</span> 
            <span class="c1">// 해당 더하기 작업은 실제 기계어 수준에서는</span>
            <span class="c1">// load *ptr, reg</span>
            <span class="c1">// inc reg, 1</span>
            <span class="c1">// store reg, *ptr</span>
            <span class="c1">// 이렇게 세번의 명령어 수행으로 이루어진다.</span>

            <span class="n">sem_post</span><span class="p">(</span><span class="n">sem</span><span class="p">);</span>
            <span class="k">if</span><span class="p">(</span><span class="n">i</span> <span class="o">%</span> <span class="mi">1000</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
                <span class="n">printf</span><span class="p">(</span><span class="s">"[Child] %d</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="o">*</span><span class="n">ptr</span><span class="p">);</span>
            <span class="p">}</span>
        <span class="p">}</span>
    <span class="p">}</span> 
    <span class="c1">// 부모 프로세스는 1씩 10000 번 빼기 수행</span>
    <span class="k">else</span> <span class="p">{</span>
        <span class="k">for</span> <span class="p">(</span><span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="mi">10000</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
            <span class="n">sem_wait</span><span class="p">(</span><span class="n">sem</span><span class="p">);</span>
            
            <span class="p">(</span><span class="o">*</span><span class="n">ptr</span><span class="p">)</span><span class="o">--</span><span class="p">;</span> <span class="c1">// </span>
            <span class="c1">// 해당 빼기 작업은 실제 기계어 수준에서는</span>
            <span class="c1">// load *ptr, reg </span>
            <span class="c1">// dec reg, 1</span>
            <span class="c1">//store reg, *ptr</span>
            <span class="c1">// 이렇게 세번의 명령어 수행으로 이루어진다. </span>

            <span class="n">sem_post</span><span class="p">(</span><span class="n">sem</span><span class="p">);</span>
            <span class="k">if</span> <span class="p">(</span><span class="n">i</span> <span class="o">%</span> <span class="mi">1000</span> <span class="o">==</span> <span class="mi">0</span> <span class="p">)</span> <span class="p">{</span>
                <span class="n">printf</span><span class="p">(</span><span class="s">"[Parent] %d</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="o">*</span><span class="n">ptr</span><span class="p">);</span>
            <span class="p">}</span>
        <span class="p">}</span>
        
        <span class="n">wait</span><span class="p">(</span><span class="nb">NULL</span><span class="p">);</span>

        <span class="n">printf</span><span class="p">(</span><span class="s">"Final value: %d</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="o">*</span><span class="n">ptr</span><span class="p">);</span>
    <span class="p">}</span>

    <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div></div>

<h3 id="4-실행">4. 실행</h3>

<p>위 코드 파일을 컴파일하고, 동시 접근 스레드를 1개만 허용하여 실행하면 그 최종 결과 값은 항상 0이 나오게 된다.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>user@DESKTOP:~<span class="nv">$ </span> gcc <span class="nt">-o</span> sema sema.c
user@DESKTOP:~<span class="nv">$ </span> ./sema
Mapping an anonymous share memory
<span class="o">[</span>Parent] <span class="nt">-1</span>
<span class="o">[</span>Parent] <span class="nt">-1001</span>
<span class="o">[</span>Parent] <span class="nt">-2001</span>
<span class="o">[</span>Parent] <span class="nt">-3000</span>
<span class="o">[</span>Child] <span class="nt">-2652</span>
<span class="o">[</span>Parent] <span class="nt">-3039</span>
<span class="o">[</span>Child] <span class="nt">-3000</span>
<span class="o">[</span>Parent] <span class="nt">-3175</span>
<span class="o">[</span>Child] <span class="nt">-3000</span>
<span class="o">[</span>Parent] <span class="nt">-3119</span>
<span class="o">[</span>Child] <span class="nt">-3000</span>
<span class="o">[</span>Parent] <span class="nt">-3287</span>
<span class="o">[</span>Child] <span class="nt">-3000</span>
<span class="o">[</span>Parent] <span class="nt">-3250</span>
<span class="o">[</span>Child] <span class="nt">-3000</span>
<span class="o">[</span>Parent] <span class="nt">-3060</span>
<span class="o">[</span>Child] <span class="nt">-3000</span>
<span class="o">[</span>Child] <span class="nt">-2999</span>
<span class="o">[</span>Child] <span class="nt">-1999</span>
<span class="o">[</span>Child] <span class="nt">-999</span>
Final value: 0
</code></pre></div></div>

<p>그러나 ‘-no-sem’ 옵션을 써서 부모 자식 스레드 동시 접근이 가능하도록 설정하면, 그 최종 결과는 0일 수도 있고, 아래와 같이 0 이 아닌 다른 값이 나올 수 도 있게 된다.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>user@DESKTOP:~<span class="nv">$ </span>./sema <span class="nt">-no-sem</span>
Mapping an anonymous share memory
<span class="o">[</span>Parent] <span class="nt">-1</span>
<span class="o">[</span>Parent] <span class="nt">-992</span>
<span class="o">[</span>Child] <span class="nt">-177</span>
<span class="o">[</span>Parent] <span class="nt">-1005</span>
<span class="o">[</span>Child] <span class="nt">-999</span>
<span class="o">[</span>Child] <span class="nt">-626</span>
<span class="o">[</span>Parent] <span class="nt">-1001</span>
<span class="o">[</span>Parent] <span class="nt">-1006</span>
<span class="o">[</span>Child] <span class="nt">-1001</span>
<span class="o">[</span>Parent] <span class="nt">-1086</span>
<span class="o">[</span>Child] <span class="nt">-1007</span>
<span class="o">[</span>Parent] <span class="nt">-1034</span>
<span class="o">[</span>Child] <span class="nt">-1010</span>
<span class="o">[</span>Parent] <span class="nt">-1041</span>
<span class="o">[</span>Child] <span class="nt">-1021</span>
<span class="o">[</span>Parent] <span class="nt">-1078</span>
<span class="o">[</span>Child] <span class="nt">-1014</span>
<span class="o">[</span>Parent] <span class="nt">-1097</span>
<span class="o">[</span>Child] <span class="nt">-1013</span>
<span class="o">[</span>Child] <span class="nt">-1006</span>
Final value: <span class="nt">-7</span>
</code></pre></div></div>]]></content><author><name>Yong gon Yun</name></author><category term="linux" /><category term="IPC" /><category term="inter-process communication" /><category term="shared memory" /><category term="semaphore" /><summary type="html"><![CDATA[개발자를 위한 반도체 SW개발 기초 (디바이스 드라이버 개발) 관련 학습 19]]></summary></entry><entry><title type="html">IPC 실습 04 - Shared Memeory</title><link href="http://localhost:4000/IPC04.html" rel="alternate" type="text/html" title="IPC 실습 04 - Shared Memeory" /><published>2024-03-22T10:32:20+09:00</published><updated>2024-03-22T10:32:20+09:00</updated><id>http://localhost:4000/IPC04</id><content type="html" xml:base="http://localhost:4000/IPC04.html"><![CDATA[<style>
    summary::-webkit-details-marker {
        display: none;
    }
    summary {
        list-style: none;
    }
</style>

<details><summary></summary>
에러방지  에러방지 에러방지  에러방지 에러방지  에러방지 에러방지  에러방지
에러방지  에러방지 에러방지  에러방지 에러방지  에러방지 에러방지  에러방지
에러방지  에러방지 에러방지  에러방지 에러방지  에러방지 에러방지  에러방지
에러방지  에러방지 에러방지  에러방지 에러방지  에러방지 에러방지  에러방지
에러방지  에러방지 에러방지  에러방지 에러방지  에러방지 에러방지  에러방지
에러방지  에러방지 에러방지  에러방지 에러방지  에러방지 에러방지  에러방지
에러방지  에러방지 에러방지  에러방지 에러방지  에러방지 에러방지  에러방지
에러방지  에러방지 에러방지  에러방지 에러방지  에러방지 에러방지  에러방지
에러방지  에러방지 에러방지  에러방지 에러방지  에러방지 에러방지  에러방지
에러방지  에러방지 에러방지  에러방지 에러방지  에러방지 에러방지  에러방지
에러방지  에러방지 에러방지  에러방지 에러방지  에러방지 에러방지  에러방지
에러방지  에러방지 에러방지  에러방지 에러방지  에러방지 에러방지  에러방지
</details>

<p>아래 내용은 개발자를 위한 시스템 반도체 SW개발 기초(디바이스 드라이버 개발) (https://comento.kr/) 강의 내용 중 일부에 해당함.</p>

<h3 id="1-공유메모리-란">1. 공유메모리 란?</h3>

<p>데이터 공유를 목적으로 물리적인 메모리의 동일한 영영을 각 프로세스가 매핑</p>
<ul>
  <li>일반적인 메모리 접근과 동일한 방식으로 사용 가능</li>
  <li>별동의 시스템콜이나 함수 없이 직접 데이터 접근이 가능하므로 작업 속도가 빠름.</li>
  <li>여러 프로세스가 동시에 같은 영역에 작업하여 데이터의 일관성이 깨지는 것을 방지하기 위한 기법 필요 (e.g. semaphore)</li>
</ul>

<h3 id="2-주요-함수">2. 주요 함수</h3>

<h4 id="void-mmapvoid-start-size_t-length-int-prot-int-flags-int-fd-off_t-offset">void *mmap(void *start, size_t length, int prot, int flags, int fd, off_t offset);</h4>

<p>파일이나 장치의 내용을 메모리에 매핑하여, 이를통해 프로세스는 파일이나 장치를 마치 메모리 배열인것저럼 접근할 수 있게 해주는 함수.</p>

<ul>
  <li>start : 매핑 시작 메모리 주소. NULL 로 설정시, 커널이 자동으로 설정.</li>
  <li>length: 매핑할 메로리 크기(bytes)</li>
  <li>prot  : 매핑된 메모리 영역의 보호 수준
    <ul>
      <li>PROT_READ : 읽기 가능</li>
      <li>PROT_WRITE: 쓰기 가능</li>
      <li>PROT_EXEC : 실행 가능</li>
      <li>PROT_NONE : 접근 금지</li>
    </ul>
  </li>
  <li>flag  : 매핑의 특성을 제어
    <ul>
      <li>MAP_SHARED    : 매핑된 메모리 영역에 대한 변경사항이 파일이 직접 반영되며, 변경사항은 다른 모든 매핑을 통해서도 볼 수 있음.</li>
      <li>MAP_PRIVATE   : 매핑된 메모리 영영에 대한 변경사항이 복사본에만 적용되며, 원본 파일은 변경되지 않음. 변경사항은 해당 프로세스에서만 볼 수 있음.</li>
      <li>MAP_FIXED     : start 에 지정된 주소에 매핑을 강제.</li>
    </ul>
  </li>
  <li>fd    : 매핑할 파일의 파일 디스크립터. <code class="language-plaintext highlighter-rouge">open</code> 함수등을 통해 얻을 수 있음.</li>
  <li>offset: 파일 내에서 매핑을 시작할 offset. 이값은 시스템의 메모리 관리 기본단위 (페이지 - 일반적으로 4KB) 의 배수로 표기</li>
</ul>

<h4 id="int-shm_openconst-char-name-int-flags-mode_t-mode">int shm_open(const char *name, int flags, mode_t mode);</h4>

<p>POSIX (Portable Operating System Interface) 기반 시스템에서 공유 메모리 객체를 생성하거나 열기 위해 사용되는 함수. 이 함수는 공유 메모리를 사용하여 프로세스 간 통신(IPC)에 활용될 수 있는 메커니즘을 제공, 해당 함수로 생성된 객체는 파일처럼 관리되며, 이를 통해 프로세스들이 메모리 공간을 공유할 수 있다. 해당 객체는 ‘/dev/shm’ 밑에 생성, 재부팅시 사라짐.</p>

<ul>
  <li>name  : 공유 메모리 객체 이름. ‘/’ 로 시작하는 경로 형식을 사용</li>
  <li>flags :
    <ul>
      <li>O_RDONLY  : 읽기 전용</li>
      <li>O_RDWR    : 읽기 및 쓰기</li>
      <li>O_CREAT   : (존재하지 않을 경우) 객체 생성</li>
      <li>O_EXCL    : (O_CREATE 와 함께 사용하여), 동일 경로의 객체가 이미 존재한다면 shm_open은 -1을 반환하고, errno를 EEXIST로 설정</li>
    </ul>
  </li>
  <li>
    <p>mode  : 생성한 공유메모리 객체에 대한 접근 권한 지정 (e.g.  0644는 소유자는 읽기와 쓰기 권한 부여)</p>
  </li>
  <li>반환값: 파일 디스크립터</li>
</ul>

<h4 id="int-ftruncateint-fd-off_t-length">int ftruncate(int fd, off_t length)</h4>

<p>파일 크기를 변경하는데 사용하며, 특히 공유 메모리 객체의 크기를 조정할 때 사용됨.</p>

<ul>
  <li>fd    : 크기를 변경하고자 하는 파일의 파일 디스크립터</li>
  <li>length: 파일의 새로운 크기를 바이트 단위로 지정</li>
</ul>

<h3 id="3-code">3. code</h3>

<div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cp">#include</span> <span class="cpf">&lt;fcntl.h&gt;</span><span class="cp">
#include</span> <span class="cpf">&lt;unistd.h&gt;</span><span class="cp">
#include</span> <span class="cpf">&lt;stdio.h&gt;</span><span class="cp">
#include</span> <span class="cpf">&lt;string.h&gt;</span><span class="cp">
#include</span> <span class="cpf">&lt;sys/mman.h&gt;</span><span class="c1"> // mmap, munmap, PROT_READ, PROT_WRITE, MAP_SHARED, MAP_FAILED 등을 정의</span><span class="cp">
#include</span> <span class="cpf">&lt;sys/stat.h&gt;</span><span class="c1"> // shm_open, shm_unlink 함수 사용 시 필요한 mode 매크로(S_IRUSR, S_IWUSR 등)를 정의</span><span class="cp">
</span>
<span class="c1">//  POSIX 호환 시스템에서 정의된, 오류를 보고하는 데 사용되는 전역 변수 </span>
<span class="c1">// 해당 코드에서 'errno' 변수에 함수 실행 오류 반환 값을 받아 처리하기 위해 사용</span>
<span class="cp">#include</span> <span class="cpf">&lt;errno.h&gt;</span><span class="c1"> </span><span class="cp">
</span>
<span class="cp">#define SHM_NAME "/comento_mem"
#define SHM_SIZE 4096
</span>
<span class="kt">int</span> <span class="nf">main</span><span class="p">(</span><span class="kt">int</span> <span class="n">argc</span><span class="p">,</span>  <span class="kt">char</span> <span class="o">*</span><span class="k">const</span> <span class="n">argv</span><span class="p">[])</span> <span class="p">{</span>
    <span class="kt">int</span> <span class="n">needs_init</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">fd</span><span class="p">;</span>
    <span class="kt">char</span> <span class="o">*</span><span class="n">ptr</span><span class="p">;</span>

    <span class="c1">// 파일 실행 '-d' 옵션 시 기존 공유 메모리 삭제</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">argc</span> <span class="o">==</span> <span class="mi">2</span> <span class="o">&amp;&amp;</span> <span class="o">!</span><span class="n">strcmp</span><span class="p">(</span><span class="n">argv</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="s">"-d"</span><span class="p">))</span> <span class="p">{</span>
        <span class="n">printf</span><span class="p">(</span><span class="s">"Delete the shared memory</span><span class="se">\n</span><span class="s">"</span><span class="p">);</span>
        <span class="n">shm_unlink</span><span class="p">(</span><span class="n">SHM_NAME</span><span class="p">);</span>
        <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
    <span class="p">}</span> 

    <span class="c1">// '-l' : 생성된 객체를 리스트로 확인 </span>
    <span class="c1">// ls 명령어로 "/dev/shm" 내 파일 목록을 가져오는 것으로 구현</span>
    <span class="k">else</span> <span class="k">if</span> <span class="p">(</span><span class="n">argc</span> <span class="o">==</span> <span class="mi">2</span> <span class="o">&amp;&amp;</span> <span class="o">!</span><span class="n">strcmp</span><span class="p">(</span><span class="n">argv</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="s">"-l"</span><span class="p">))</span> <span class="p">{</span>
        <span class="k">static</span> <span class="kt">char</span> <span class="o">*</span><span class="k">const</span> <span class="n">ls_argv</span><span class="p">[]</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s">"/bin/ls"</span><span class="p">,</span> <span class="s">"/dev/shm"</span><span class="p">,</span> <span class="nb">NULL</span>
        <span class="p">};</span>
        <span class="n">printf</span><span class="p">(</span><span class="s">"List the shared memory:</span><span class="se">\n</span><span class="s">"</span><span class="p">);</span>
        <span class="n">execve</span><span class="p">(</span><span class="n">ls_argv</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">ls_argv</span><span class="p">,</span> <span class="nb">NULL</span><span class="p">);</span>
        <span class="n">fprintf</span><span class="p">(</span><span class="n">stderr</span><span class="p">,</span> <span class="s">"Failed to run ls command"</span><span class="p">);</span>
        <span class="k">return</span> <span class="mi">5</span><span class="p">;</span>
    <span class="p">}</span> 

    <span class="c1">// 위 옵션 &amp;&amp; 옵션 없는 상태를 제외하고 예외 처리</span>
    <span class="k">else</span> <span class="k">if</span><span class="p">(</span><span class="n">argc</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">fprintf</span><span class="p">(</span><span class="n">stderr</span><span class="p">,</span> <span class="s">"Usage : %s &lt;-d&gt; &lt;-l&gt;</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="n">argv</span><span class="p">[</span><span class="mi">0</span><span class="p">]);</span>
        <span class="k">return</span> <span class="mi">4</span><span class="p">;</span>
    <span class="p">}</span>

    <span class="c1">// 옵션이 없는 상태 - 공유 메모리 객체 사용 모드 설정</span>
    <span class="n">fd</span> <span class="o">=</span> <span class="n">shm_open</span><span class="p">(</span><span class="n">SHM_NAME</span><span class="p">,</span> <span class="n">O_RDWR</span><span class="p">,</span> <span class="mo">0600</span><span class="p">);</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">fd</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
        <span class="c1">// 'ENOENT' : "Error NO ENTry" 파일, 디렉토리 또는 지정된 객체가 존지 하지 않을 때 반환되는 오류코드</span>
        <span class="c1">// 'shm_open' 함수 실행 오류 코드를 errno 전역 변수에 할당.</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">errno</span> <span class="o">==</span> <span class="n">ENOENT</span><span class="p">)</span> <span class="p">{</span>
            <span class="n">printf</span><span class="p">(</span><span class="s">"Create new shared memory</span><span class="se">\n</span><span class="s">"</span><span class="p">);</span>

            <span class="c1">// 기존에 객체가 없는 경우 새로 생성하고 사용 모드 설정</span>
            <span class="n">fd</span> <span class="o">=</span> <span class="n">shm_open</span><span class="p">(</span><span class="n">SHM_NAME</span><span class="p">,</span> <span class="n">O_CREAT</span> <span class="o">|</span> <span class="n">O_RDWR</span><span class="p">,</span> <span class="mo">0600</span><span class="p">);</span>
            <span class="n">printf</span><span class="p">(</span><span class="s">"Set the size of shared memory</span><span class="se">\n</span><span class="s">"</span><span class="p">);</span>

            <span class="k">if</span> <span class="p">(</span><span class="n">ftruncate</span><span class="p">(</span><span class="n">fd</span><span class="p">,</span> <span class="n">SHM_SIZE</span><span class="p">)</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
                <span class="n">fprintf</span><span class="p">(</span><span class="n">stderr</span><span class="p">,</span> <span class="s">"Failed to ftruncate</span><span class="se">\n\n</span><span class="s">"</span><span class="p">);</span>
                <span class="k">return</span> <span class="mi">2</span><span class="p">;</span>
            <span class="p">}</span>
            <span class="n">needs_init</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
        <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
            <span class="n">fprintf</span><span class="p">(</span><span class="n">stderr</span><span class="p">,</span> <span class="s">"Failed to shm_open</span><span class="se">\n</span><span class="s">"</span><span class="p">);</span>
            <span class="k">return</span> <span class="mi">1</span><span class="p">;</span>
        <span class="p">}</span>
    <span class="p">}</span>

    <span class="c1">// 메모리 매핑 설정</span>
    <span class="n">printf</span><span class="p">(</span><span class="s">"Mapping the shared memeory</span><span class="se">\n</span><span class="s">"</span><span class="p">);</span>
    <span class="n">ptr</span> <span class="o">=</span> <span class="p">(</span><span class="kt">char</span><span class="o">*</span><span class="p">)</span> <span class="n">mmap</span><span class="p">(</span><span class="nb">NULL</span><span class="p">,</span> <span class="n">SHM_SIZE</span><span class="p">,</span> <span class="n">PROT_READ</span> <span class="o">|</span> <span class="n">PROT_WRITE</span><span class="p">,</span> <span class="n">MAP_SHARED</span><span class="p">,</span> <span class="n">fd</span><span class="p">,</span> <span class="mi">0</span><span class="p">);</span>
    
    <span class="k">if</span> <span class="p">(</span><span class="n">ptr</span> <span class="o">==</span> <span class="n">MAP_FAILED</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">fprintf</span><span class="p">(</span><span class="n">stderr</span><span class="p">,</span> <span class="s">"Failed to mmap</span><span class="se">\n</span><span class="s">"</span><span class="p">);</span>
        <span class="k">return</span> <span class="mi">3</span><span class="p">;</span>
    <span class="p">}</span>

    <span class="c1">// 공유 메모리 객체가 새로 생성한 상태가 아니라면, 해당 메모리에 기존에 저장된 내용을 출력</span>
    <span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">needs_init</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">printf</span><span class="p">(</span><span class="s">"before: %.4095s</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="n">ptr</span><span class="p">);</span> <span class="c1">// 최대 4095 개 문자 출력</span>
    <span class="p">}</span>
    <span class="n">scanf</span><span class="p">(</span><span class="s">"%4095s"</span><span class="p">,</span> <span class="n">ptr</span><span class="p">);</span>

    <span class="n">munmap</span><span class="p">(</span><span class="n">ptr</span><span class="p">,</span> <span class="n">SHM_SIZE</span><span class="p">);</span>
    <span class="n">close</span><span class="p">(</span><span class="n">fd</span><span class="p">);</span>
    <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div></div>

<h3 id="4-공유-메모리-사용">4. 공유 메모리 사용</h3>

<p>위 소스 파일을 컴파일 하여 사용</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>user@DESKTOP:~<span class="nv">$ </span>gcc <span class="nt">-o</span> mmap mmap.c
</code></pre></div></div>

<p>우선, 사용하기전 공유 메모리 객체 저장 디렉토리를 확인하면, 아무것도 없는 것을 확인할 수 있다.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>user@DESKTOP:~<span class="nv">$ </span><span class="nb">ls</span> <span class="nt">-lah</span> /dev/shm
total 0
drwxrwxrwt  2 root root   40 Mar 22 11:40 <span class="nb">.</span>
drwxr-xr-x 16 root root 3.5K Mar 22 11:27 ..
</code></pre></div></div>

<p>객체 생성 파일을 실행하고, 다시 ls 명령어 또는 <code class="language-plaintext highlighter-rouge">mmap -l</code> 옵션을 사용하여 모두 객체가 생성되었음을 확인할 수 있다.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>user@DESKTOP:~<span class="nv">$ </span>./mmap
Create new shared memory
Set the size of shared memory
Mapping the shared memeory
First!!!!!!!!!
user@DESKTOP:~<span class="nv">$ </span><span class="nb">ls</span> <span class="nt">-lah</span> /dev/shm
total 4.0K
drwxrwxrwt  2 root root   60 Mar 22 11:38 <span class="nb">.</span>
drwxr-xr-x 16 root root 3.5K Mar 22 11:27 ..
<span class="nt">-rw-------</span>  1 gon  gon  4.0K Mar 22 11:38 comento_mem
user@DESKTOP:~<span class="nv">$ </span> ./mmap <span class="nt">-l</span>
List the shared memory:
comento_mem
</code></pre></div></div>

<p>만약 다시 객체를 생성하고자 하면 기존 저장된 내용을 확인할 수 있다.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>user@DESKTOP:~<span class="nv">$ </span> ./mmap
Mapping the shared memeory
before: First!!!!!!!!!
Second!!!!!!!
</code></pre></div></div>

<p>마지막으로 해당 객체를 제거 및 확인</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>user@DESKTOP:~<span class="nv">$ </span>./mmap <span class="nt">-d</span>
Delete the shared memory
user@DESKTOP:~<span class="nv">$ </span><span class="nb">ls</span> <span class="nt">-lah</span> /dev/shm
total 0
drwxrwxrwt  2 root root   40 Mar 22 11:40 <span class="nb">.</span>
drwxr-xr-x 16 root root 3.5K Mar 22 11:27 ..
</code></pre></div></div>

<p>그러나, 실제 공유 메모리의 경우, 여러 프로세스가 접근하여 읽기, 쓰기를 수행할 수 있기 때문에 위와 같이 작성하면 데이터의 일관성을 보장할 수 없다. 따라서 일관성을 보장하기 위한 추가 작업 (e.g. semaphore 구현 등) 이 필요하다.</p>]]></content><author><name>Yong gon Yun</name></author><category term="linux" /><category term="IPC" /><category term="inter-process communication" /><category term="shared memory" /><summary type="html"><![CDATA[개발자를 위한 반도체 SW개발 기초 (디바이스 드라이버 개발) 관련 학습 18]]></summary></entry><entry><title type="html">IPC 실습 03 - Unix socket</title><link href="http://localhost:4000/IPC03.html" rel="alternate" type="text/html" title="IPC 실습 03 - Unix socket" /><published>2024-03-20T10:32:20+09:00</published><updated>2024-03-20T10:32:20+09:00</updated><id>http://localhost:4000/IPC03</id><content type="html" xml:base="http://localhost:4000/IPC03.html"><![CDATA[<style>
    summary::-webkit-details-marker {
        display: none;
    }
    summary {
        list-style: none;
    }
</style>

<details><summary></summary>
에러방지  에러방지 에러방지  에러방지 에러방지  에러방지 에러방지  에러방지
에러방지  에러방지 에러방지  에러방지 에러방지  에러방지 에러방지  에러방지
에러방지  에러방지 에러방지  에러방지 에러방지  에러방지 에러방지  에러방지
에러방지  에러방지 에러방지  에러방지 에러방지  에러방지 에러방지  에러방지
에러방지  에러방지 에러방지  에러방지 에러방지  에러방지 에러방지  에러방지
에러방지  에러방지 에러방지  에러방지 에러방지  에러방지 에러방지  에러방지
에러방지  에러방지 에러방지  에러방지 에러방지  에러방지 에러방지  에러방지
에러방지  에러방지 에러방지  에러방지 에러방지  에러방지 에러방지  에러방지
에러방지  에러방지 에러방지  에러방지 에러방지  에러방지 에러방지  에러방지
에러방지  에러방지 에러방지  에러방지 에러방지  에러방지 에러방지  에러방지
에러방지  에러방지 에러방지  에러방지 에러방지  에러방지 에러방지  에러방지
에러방지  에러방지 에러방지  에러방지 에러방지  에러방지 에러방지  에러방지
</details>

<p>아래 내용은 개발자를 위한 시스템 반도체 SW개발 기초(디바이스 드라이버 개발) (https://comento.kr/) 강의 내용 중 일부에 해당함.</p>

<h3 id="1-unix-socket">1. Unix Socket</h3>

<p>웹서버 서버-클라이언트 구조와 같이, 다수의 프로세스간 양방향 통신을 가능하게 함.</p>

<ul>
  <li>serever</li>
</ul>

<div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cp">#include</span> <span class="cpf">&lt;sys/socket.h&gt;</span><span class="cp">
#include</span> <span class="cpf">&lt;sys/un.h&gt;</span><span class="cp">
#include</span> <span class="cpf">&lt;stdio.h&gt;</span><span class="cp">
#include</span> <span class="cpf">&lt;stdlib.h&gt;</span><span class="cp">
#include</span> <span class="cpf">&lt;unistd.h&gt;</span><span class="cp">
#include</span> <span class="cpf">&lt;string.h&gt;</span><span class="cp">
#define SOCKET_NAME "/tmp/echo_socket"
</span>
<span class="kt">int</span> <span class="nf">main</span><span class="p">()</span> <span class="p">{</span>
    <span class="n">pid_t</span> <span class="n">pid</span><span class="p">;</span>
    <span class="kt">int</span> <span class="n">sockfd</span><span class="p">,</span> <span class="n">connfd</span><span class="p">;</span>
    <span class="k">struct</span> <span class="n">socketaddr_un</span> <span class="n">addr</span><span class="p">;</span>
    <span class="kt">int</span> <span class="n">recv_bytes</span><span class="p">;</span>
    <span class="kt">char</span> <span class="n">buf</span><span class="p">[</span><span class="mi">256</span><span class="p">];</span>

    <span class="n">sockfd</span> <span class="o">=</span> <span class="n">socket</span><span class="p">(</span><span class="n">AF_UNIX</span><span class="p">,</span> <span class="n">SOCK_STREAM</span><span class="p">,</span> <span class="mi">0</span><span class="p">);</span>
    <span class="k">if</span><span class="p">(</span><span class="n">sockfd</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">fprintf</span><span class="p">(</span><span class="n">stderr</span><span class="p">,</span> <span class="s">"[Server] Failed to create socket</span><span class="se">\n</span><span class="s">"</span><span class="p">);</span>
        <span class="k">return</span> <span class="mi">1</span><span class="p">;</span>
    <span class="p">}</span>

    <span class="n">memset</span><span class="p">(</span><span class="o">&amp;</span><span class="n">addr</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="k">sizeof</span><span class="p">(</span><span class="n">addr</span><span class="p">));</span>
    <span class="n">addr</span><span class="p">.</span><span class="n">sun_family</span> <span class="o">=</span> <span class="n">AF_UNIX</span><span class="p">;</span>
    <span class="n">snprintf</span><span class="p">(</span><span class="n">addr</span><span class="p">.</span><span class="n">sun_path</span><span class="p">,</span> <span class="k">sizeof</span><span class="p">(</span><span class="n">addr</span><span class="p">.</span><span class="n">sun_path</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">SOCKET_NAME</span><span class="p">);</span>

    <span class="n">unlink</span><span class="p">(</span><span class="n">addr</span><span class="p">.</span><span class="n">sun_path</span><span class="p">);</span> <span class="c1">// remove the socket file if exists</span>
    <span class="k">if</span><span class="p">(</span><span class="n">bind</span><span class="p">(</span><span class="n">sockfd</span><span class="p">,</span> <span class="p">(</span><span class="k">struct</span> <span class="n">sockaddr</span><span class="o">*</span><span class="p">)</span><span class="o">&amp;</span><span class="n">addr</span><span class="p">,</span> <span class="k">sizeof</span><span class="p">(</span><span class="n">addr</span><span class="p">))</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">fprintf</span><span class="p">(</span><span class="n">stderr</span><span class="p">,</span> <span class="s">"[Server] Failed to bind</span><span class="se">\n</span><span class="s">"</span><span class="p">);</span>
        <span class="k">return</span> <span class="mi">2</span><span class="p">;</span>
    <span class="p">}</span>

    <span class="k">if</span><span class="p">(</span><span class="n">listen</span><span class="p">(</span><span class="n">sockfd</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">fprintf</span><span class="p">(</span><span class="n">stderr</span><span class="p">,</span> <span class="s">"[Server] Failed to listen</span><span class="se">\n</span><span class="s">"</span><span class="p">);</span>
        <span class="k">return</span> <span class="mi">2</span><span class="p">;</span>
    <span class="p">}</span>

    <span class="k">while</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">connfd</span> <span class="o">=</span> <span class="n">accept</span><span class="p">(</span><span class="n">sockfd</span><span class="p">,</span> <span class="nb">NULL</span><span class="p">,</span> <span class="nb">NULL</span><span class="p">);</span>
        <span class="k">if</span><span class="p">(</span><span class="n">connfd</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
            <span class="n">fprintf</span><span class="p">(</span><span class="n">stderr</span><span class="p">,</span> <span class="s">"[Server] Failed to accept</span><span class="se">\n</span><span class="s">"</span><span class="p">);</span>
            <span class="k">break</span><span class="p">;</span>
        <span class="p">}</span>
        <span class="n">printf</span><span class="p">(</span><span class="s">"[Server] Client connected!</span><span class="se">\n</span><span class="s">"</span><span class="p">);</span>

        <span class="n">pid</span> <span class="o">=</span> <span class="n">fork</span><span class="p">();</span>
        <span class="k">if</span><span class="p">(</span><span class="n">pid</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
            <span class="k">while</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
                <span class="n">recv_bytes</span> <span class="o">=</span> <span class="n">read</span><span class="p">(</span><span class="n">connfd</span><span class="p">,</span> <span class="n">buf</span><span class="p">,</span> <span class="k">sizeof</span><span class="p">(</span><span class="n">buf</span><span class="p">));</span>
                <span class="k">if</span><span class="p">(</span><span class="n">recv_bytes</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
                    <span class="k">break</span><span class="p">;</span>
                <span class="p">}</span>
                <span class="n">printf</span><span class="p">(</span><span class="s">"[Server] Recv : %.*s</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="n">recv_bytes</span><span class="p">,</span> <span class="n">buf</span><span class="p">);</span>
                <span class="n">write</span><span class="p">(</span><span class="n">connfd</span><span class="p">,</span> <span class="n">buf</span><span class="p">,</span> <span class="n">recv_bytes</span><span class="p">);</span>
            <span class="p">}</span>

            <span class="n">close</span><span class="p">(</span><span class="n">connfd</span><span class="p">);</span>
            <span class="n">printf</span><span class="p">(</span><span class="s">"[Server] Client disconnected!</span><span class="se">\n</span><span class="s">"</span><span class="p">);</span>
            <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
        <span class="p">}</span>
    <span class="p">}</span>
    <span class="n">close</span><span class="p">(</span><span class="n">sockfd</span><span class="p">);</span>
    <span class="k">return</span> <span class="mi">3</span><span class="p">;</span> 
<span class="p">}</span>
</code></pre></div></div>

<ul>
  <li>client</li>
</ul>

<div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cp">#include</span> <span class="cpf">&lt;sys/socket.h&gt;</span><span class="cp">
#include</span> <span class="cpf">&lt;sys/un.h&gt;</span><span class="cp">
#include</span> <span class="cpf">&lt;stdio.h&gt;</span><span class="cp">
#include</span> <span class="cpf">&lt;stdlib.h&gt;</span><span class="cp">
#include</span> <span class="cpf">&lt;unistd.h&gt;</span><span class="cp">
#include</span> <span class="cpf">&lt;string.h&gt;</span><span class="cp">
</span>
<span class="cp">#define SOCKET_NAME "/tmp/echo_socket"
</span>
<span class="kt">int</span> <span class="nf">main</span><span class="p">()</span> <span class="p">{</span>
    <span class="n">pid_t</span> <span class="n">pid</span><span class="p">;</span>
    <span class="kt">int</span> <span class="n">socketfd</span><span class="p">,</span> <span class="n">recv_bytes</span><span class="p">;</span>
    <span class="k">struct</span> <span class="n">sockaddr_un</span> <span class="n">addr</span><span class="p">;</span>
    <span class="kt">char</span> <span class="n">buf</span><span class="p">[</span><span class="mi">256</span><span class="p">];</span>

    <span class="n">sockfd</span> <span class="o">=</span> <span class="n">socket</span><span class="p">(</span><span class="n">AF_UNIX</span><span class="p">,</span> <span class="n">SOCK_STREAM</span><span class="p">,</span> <span class="mi">0</span><span class="p">);</span>
    <span class="k">if</span><span class="p">(</span><span class="n">sockfd</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">fprintf</span><span class="p">(</span><span class="n">stderr</span><span class="p">,</span> <span class="s">"[Client] Failed to create socket</span><span class="se">\n</span><span class="s">"</span><span class="p">);</span>
        <span class="k">return</span> <span class="mi">1</span><span class="p">;</span>
    <span class="p">}</span>

    <span class="n">memset</span><span class="p">(</span><span class="o">&amp;</span><span class="n">addr</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="k">sizeof</span><span class="p">(</span><span class="n">addr</span><span class="p">));</span>
    <span class="n">addr</span><span class="p">.</span><span class="n">sun_family</span> <span class="o">=</span> <span class="n">AF_UNIX</span><span class="p">;</span>
    <span class="n">snprintf</span><span class="p">(</span><span class="n">addr</span><span class="p">.</span><span class="n">sun_path</span><span class="p">,</span> <span class="k">sizeof</span><span class="p">(</span><span class="n">addr</span><span class="p">.</span><span class="n">sun_path</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">SOCKET_NAME</span><span class="p">);</span>

    <span class="k">if</span><span class="p">(</span><span class="n">connect</span><span class="p">(</span><span class="n">sockfd</span><span class="p">,</span> <span class="p">(</span><span class="n">strcut</span> <span class="n">sockaddr</span><span class="o">*</span><span class="p">)</span><span class="o">&amp;</span><span class="n">addr</span><span class="p">,</span> <span class="k">sizeof</span><span class="p">(</span><span class="n">addr</span><span class="p">))</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">fprintf</span><span class="p">(</span><span class="n">stderr</span><span class="p">,</span> <span class="s">"[Client] Failed to connect</span><span class="se">\n</span><span class="s">"</span><span class="p">);</span>
        <span class="k">return</span> <span class="mi">2</span><span class="p">;</span>
    <span class="p">}</span>

    <span class="k">while</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">printf</span><span class="p">(</span><span class="s">"'q' for exit&gt;"</span><span class="p">);</span>

        <span class="n">buf</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="sc">'\0'</span><span class="p">;</span>

        <span class="n">scanf</span><span class="p">(</span><span class="s">"%255s"</span><span class="p">,</span> <span class="n">buf</span><span class="p">);</span>
        <span class="k">if</span><span class="p">(</span><span class="o">!</span><span class="n">strcmp</span><span class="p">(</span><span class="n">buf</span><span class="p">,</span> <span class="s">"q"</span><span class="p">))</span> <span class="p">{</span>
            <span class="k">break</span><span class="p">;</span>
        <span class="p">}</span>

        <span class="n">write</span><span class="p">(</span><span class="n">sockfd</span><span class="p">,</span> <span class="n">buf</span><span class="p">,</span> <span class="n">strlen</span><span class="p">(</span><span class="n">buf</span><span class="p">));</span>
        <span class="n">recv_bytes</span> <span class="o">=</span> <span class="n">read</span><span class="p">(</span><span class="n">sockfd</span><span class="p">,</span> <span class="n">buf</span><span class="p">,</span> <span class="k">sizeof</span><span class="p">(</span><span class="n">buf</span><span class="p">));</span>
        <span class="k">if</span><span class="p">(</span><span class="n">recv_bytes</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
            <span class="n">printf</span><span class="p">(</span><span class="s">"[Client] Server shutdown!</span><span class="se">\n</span><span class="s">"</span><span class="p">);</span>
            <span class="k">break</span><span class="p">;</span>
        <span class="p">}</span>

        <span class="n">printf</span><span class="p">(</span><span class="s">"[Client] Recv: %.*s</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="n">recv_bytes</span><span class="p">,</span> <span class="n">buf</span><span class="p">);</span>
    <span class="p">}</span>

    <span class="n">close</span><span class="p">(</span><span class="n">sockfd</span><span class="p">);</span>
    <span class="n">printf</span><span class="p">(</span><span class="s">"[Client] Exit!</span><span class="se">\n</span><span class="s">"</span><span class="p">);</span>

    <span class="k">return</span> <span class="mi">3</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div></div>]]></content><author><name>Yong gon Yun</name></author><category term="linux" /><category term="IPC" /><category term="inter-process communication" /><category term="unix socket" /><summary type="html"><![CDATA[개발자를 위한 반도체 SW개발 기초 (디바이스 드라이버 개발) 관련 학습 17]]></summary></entry><entry><title type="html">IPC 실습 02 - pipe</title><link href="http://localhost:4000/IPC02.html" rel="alternate" type="text/html" title="IPC 실습 02 - pipe" /><published>2024-03-19T10:32:20+09:00</published><updated>2024-03-19T10:32:20+09:00</updated><id>http://localhost:4000/IPC02</id><content type="html" xml:base="http://localhost:4000/IPC02.html"><![CDATA[<style>
    summary::-webkit-details-marker {
        display: none;
    }
    summary {
        list-style: none;
    }
</style>

<details><summary></summary>
에러방지  에러방지 에러방지  에러방지 에러방지  에러방지 에러방지  에러방지
에러방지  에러방지 에러방지  에러방지 에러방지  에러방지 에러방지  에러방지
에러방지  에러방지 에러방지  에러방지 에러방지  에러방지 에러방지  에러방지
에러방지  에러방지 에러방지  에러방지 에러방지  에러방지 에러방지  에러방지
에러방지  에러방지 에러방지  에러방지 에러방지  에러방지 에러방지  에러방지
에러방지  에러방지 에러방지  에러방지 에러방지  에러방지 에러방지  에러방지
에러방지  에러방지 에러방지  에러방지 에러방지  에러방지 에러방지  에러방지
에러방지  에러방지 에러방지  에러방지 에러방지  에러방지 에러방지  에러방지
에러방지  에러방지 에러방지  에러방지 에러방지  에러방지 에러방지  에러방지
에러방지  에러방지 에러방지  에러방지 에러방지  에러방지 에러방지  에러방지
에러방지  에러방지 에러방지  에러방지 에러방지  에러방지 에러방지  에러방지
에러방지  에러방지 에러방지  에러방지 에러방지  에러방지 에러방지  에러방지
</details>

<p>아래 내용은 개발자를 위한 시스템 반도체 SW개발 기초(디바이스 드라이버 개발) (https://comento.kr/) 강의 내용 중 일부에 해당함.</p>

<h3 id="1-pipe-구현을-통한-부모-프로세서와-자식-프로세서-ipc">1. pipe 구현을 통한 부모 프로세서와 자식 프로세서 IPC</h3>

<p>pipe 개념도</p>

<center>
  <img src="assets\img\posts\2024-03-19-IPC0201.png" width="500" />
</center>

<div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cp">#include</span> <span class="cpf">&lt;stdio.h&gt;</span><span class="cp">
#include</span> <span class="cpf">&lt;string.h&gt;</span><span class="cp">
#include</span> <span class="cpf">&lt;unistd.h&gt;</span><span class="cp">
#include</span> <span class="cpf">&lt;sys/wait.h&gt;</span><span class="cp">
</span>
<span class="kt">int</span> <span class="nf">main</span><span class="p">()</span> <span class="p">{</span>
    <span class="n">pid_t</span> <span class="n">pid</span><span class="p">;</span>
    <span class="kt">int</span> <span class="n">pipe_from_parent_to_child</span><span class="p">[</span><span class="mi">2</span><span class="p">];</span>
    <span class="kt">int</span> <span class="n">pipe_from_child_to_parent</span><span class="p">[</span><span class="mi">2</span><span class="p">];</span>
    <span class="kt">char</span> <span class="n">buf</span><span class="p">[</span><span class="mi">256</span><span class="p">];</span>

    <span class="n">pipe</span><span class="p">(</span><span class="n">pipe_from_parent_to_child</span><span class="p">);</span>
    <span class="n">pipe</span><span class="p">(</span><span class="n">pipe_from_child_to_parent</span><span class="p">);</span>

    <span class="n">pid</span> <span class="o">=</span> <span class="n">fork</span><span class="p">();</span>
    <span class="k">if</span><span class="p">(</span><span class="n">pid</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
        <span class="c1">// 사용하지 않는 fd 는 닫아줌.</span>
        <span class="n">close</span><span class="p">(</span><span class="n">pipe_from_child_to_parent</span><span class="p">[</span><span class="mi">0</span><span class="p">]);</span>
        <span class="n">close</span><span class="p">(</span><span class="n">pipe_from_parent_to_child</span><span class="p">[</span><span class="mi">1</span><span class="p">]);</span>

        <span class="k">const</span> <span class="kt">char</span> <span class="o">*</span><span class="n">msg</span> <span class="o">=</span> <span class="s">"I'm child~!!"</span><span class="p">;</span>

        <span class="n">printf</span><span class="p">(</span><span class="s">"[Child] send mes: %s</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="n">msg</span><span class="p">);</span>
        <span class="n">write</span><span class="p">(</span><span class="n">pipe_from_child_to_parent</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">msg</span><span class="p">,</span> <span class="n">strlen</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">);</span>
        <span class="n">sleep</span><span class="p">(</span><span class="mi">1</span><span class="p">);</span>

        <span class="n">read</span><span class="p">(</span><span class="n">pipe_from_parent_to_child</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">buf</span><span class="p">,</span> <span class="mi">256</span><span class="p">);</span>
        <span class="n">printf</span><span class="p">(</span><span class="s">"[Child] recv msg: %s</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="n">buf</span><span class="p">);</span>

        <span class="n">close</span><span class="p">(</span><span class="n">pipe_from_child_to_parent</span><span class="p">[</span><span class="mi">1</span><span class="p">]);</span>
        <span class="n">close</span><span class="p">(</span><span class="n">pipe_from_parent_to_child</span><span class="p">[</span><span class="mi">0</span><span class="p">]);</span>
    <span class="p">}</span>
    <span class="k">else</span> <span class="p">{</span>
        <span class="c1">// 사용하지 않는 fd 는 닫아줌.</span>
        <span class="n">close</span><span class="p">(</span><span class="n">pipe_from_child_to_parent</span><span class="p">[</span><span class="mi">1</span><span class="p">]);</span>
        <span class="n">close</span><span class="p">(</span><span class="n">pipe_from_parent_to_child</span><span class="p">[</span><span class="mi">0</span><span class="p">]);</span>

        <span class="k">const</span> <span class="kt">char</span> <span class="o">*</span><span class="n">msg</span> <span class="o">=</span> <span class="s">"I'm parent~!!"</span><span class="p">;</span>

        <span class="n">printf</span><span class="p">(</span><span class="s">"[Parent] send mes: %s</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="n">msg</span><span class="p">);</span>
        <span class="n">write</span><span class="p">(</span><span class="n">pipe_from_parent_to_child</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">msg</span><span class="p">,</span> <span class="n">strlen</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">);</span>
        <span class="n">sleep</span><span class="p">(</span><span class="mi">1</span><span class="p">);</span>

        <span class="n">read</span><span class="p">(</span><span class="n">pipe_from_child_to_parent</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">buf</span><span class="p">,</span> <span class="mi">256</span><span class="p">);</span>
        <span class="n">printf</span><span class="p">(</span><span class="s">"[Parent] recv msg: %s</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="n">buf</span><span class="p">);</span>

        <span class="n">close</span><span class="p">(</span><span class="n">pipe_from_child_to_parent</span><span class="p">[</span><span class="mi">0</span><span class="p">]);</span>
        <span class="n">close</span><span class="p">(</span><span class="n">pipe_from_parent_to_child</span><span class="p">[</span><span class="mi">1</span><span class="p">]);</span>
    <span class="p">}</span>
    
    <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div></div>

<p>실행</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>user@DESKTOP:~<span class="nv">$ </span> vim pipe.c
user@DESKTOP:~<span class="nv">$ </span> gcc <span class="nt">-o</span> pipe pipe.c
user@DESKTOP:~<span class="nv">$ </span> ./pipe
<span class="o">[</span>Parent] send mes: I<span class="s1">'m parent~!!
[Child] send mes: I'</span>m child~!!
<span class="o">[</span>Child] recv msg: I<span class="s1">'m parent~!!
[Parent] recv msg: I'</span>m child~!!
</code></pre></div></div>

<h3 id="2-파이프-명령어-구현">2. 파이프 명령어 구현</h3>

<p>리눅스에서 사요하는 파이프 기호 <code class="language-plaintext highlighter-rouge">|</code> 도 동일한 pipe IPC 를 사용한 기능이다. 따라서, 예를 들면 <code class="language-plaintext highlighter-rouge">cat /etc/passwd | wc -l</code> 을 pipe IPC 를 사용하여 프로그램으로 구현해볼 수 있다.</p>

<center>
  <img src="assets\img\posts\2024-03-19-IPC0202.png" width="600" />
</center>

<div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cp">#include</span> <span class="cpf">&lt;stdio.h&gt;</span><span class="cp">
#include</span> <span class="cpf">&lt;string.h&gt;</span><span class="cp">
#include</span> <span class="cpf">&lt;unistd.h&gt;</span><span class="cp">
#include</span> <span class="cpf">&lt;sys/wait.h&gt;</span><span class="cp">
</span>
<span class="cm">/* cat /etc/passwd | wc -l */</span>

<span class="k">extern</span> <span class="kt">char</span><span class="o">**</span> <span class="n">environ</span><span class="p">;</span>

<span class="kt">char</span><span class="o">*</span> <span class="k">const</span> <span class="n">front_argv</span><span class="p">[]</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s">"/bin/cat"</span><span class="p">,</span>
    <span class="s">"/etc/passwd"</span><span class="p">,</span>
    <span class="nb">NULL</span>
<span class="p">};</span>

<span class="kt">char</span><span class="o">*</span> <span class="k">const</span> <span class="n">back_argv</span><span class="p">[]</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s">"/bin/wc"</span><span class="p">,</span>
    <span class="s">"-l"</span><span class="p">,</span>
    <span class="nb">NULL</span>
<span class="p">};</span>

<span class="kt">int</span> <span class="nf">main</span><span class="p">()</span> <span class="p">{</span>
    <span class="n">pid_t</span> <span class="n">pid</span><span class="p">;</span>
    <span class="kt">int</span> <span class="n">pipefd</span><span class="p">[</span><span class="mi">2</span><span class="p">];</span>

    <span class="n">pipe</span><span class="p">(</span><span class="n">pipefd</span><span class="p">);</span>

    <span class="n">pid</span> <span class="o">=</span> <span class="n">fork</span><span class="p">();</span>
    <span class="k">if</span><span class="p">(</span><span class="n">pid</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">close</span><span class="p">(</span><span class="n">pipefd</span><span class="p">[</span><span class="mi">0</span><span class="p">]);</span> <span class="c1">// 읽기 fd 사용 X</span>
        <span class="n">dup2</span><span class="p">(</span><span class="n">pipefd</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">STDOUT_FILENO</span><span class="p">);</span> <span class="c1">// 쓰기 fd 를 표준출력 -&gt; 모든 표준출력은 쓰기 fd 로 전송됨</span>
        <span class="n">close</span><span class="p">(</span><span class="n">pipefd</span><span class="p">[</span><span class="mi">1</span><span class="p">]);</span>  <span class="c1">// 표준 출력 복제 후 닫음.</span>
        <span class="n">execve</span><span class="p">(</span><span class="n">front_argv</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">front_argv</span><span class="p">,</span> <span class="n">environ</span><span class="p">);</span>
    <span class="p">}</span>

    <span class="n">pid</span> <span class="o">=</span> <span class="n">fork</span><span class="p">();</span>
    <span class="k">if</span><span class="p">(</span><span class="n">pid</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">close</span><span class="p">(</span><span class="n">pipefd</span><span class="p">[</span><span class="mi">1</span><span class="p">]);</span> <span class="c1">// 읽기 fd 사용 X</span>
        <span class="n">dup2</span><span class="p">(</span><span class="n">pipefd</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">STDIN_FILENO</span><span class="p">);</span> <span class="c1">// 일기 fd 를 표준출력 -&gt; 읽기 fd 에서 읽ㅇ느 값을 표준입력으로 사용</span>
        <span class="n">close</span><span class="p">(</span><span class="n">pipefd</span><span class="p">[</span><span class="mi">0</span><span class="p">]);</span> <span class="c1">// 표준 입력 복제 후 닫음.</span>
        <span class="n">execve</span><span class="p">(</span><span class="n">back_argv</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">back_argv</span><span class="p">,</span> <span class="n">environ</span><span class="p">);</span>
    <span class="p">}</span>

    <span class="n">wait</span><span class="p">(</span><span class="nb">NULL</span><span class="p">);</span> 

    <span class="c1">// 부모프로세스에서의 fd 는 별개로 닫아야 함.</span>
    <span class="n">close</span><span class="p">(</span><span class="n">pipefd</span><span class="p">[</span><span class="mi">0</span><span class="p">]);</span> <span class="c1">// 읽기 fd 가 닫히면 2번째 프로세스의 표준 입력도</span>
    <span class="n">close</span><span class="p">(</span><span class="n">pipefd</span><span class="p">[</span><span class="mi">1</span><span class="p">]);</span> <span class="c1">// 닫히면서 2번째 프로세스도 종료됨.</span>

    <span class="n">wait</span><span class="p">(</span><span class="nb">NULL</span><span class="p">);</span>

    <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div></div>

<p>결과 확인</p>

<p>아래와 같이 해당 파일을 실행한 결과와  <code class="language-plaintext highlighter-rouge">cat /etc/passwd | wc -l</code> 의 실행 결과가 동일함을 확인할 수 있다.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>user@DESKTOP:~<span class="nv">$ </span>gcc <span class="nt">-o</span> pipe2 pipe2.c
user@DESKTOP:~<span class="nv">$ </span>./pipe2
27
user@DESKTOP:~<span class="nv">$ </span><span class="nb">cat</span> /etc/passwd | <span class="nb">wc</span> <span class="nt">-l</span>
27
</code></pre></div></div>

<h3 id="3-네임드-파이프">3. 네임드 파이프</h3>

<p>부모 자식간이 아닌 프로세스간 FIFO 파일의 경로를 알 수 있다면 통신이 가능하며, 이는 <code class="language-plaintext highlighter-rouge">mkfifo(fifo_file, mode)</code> 를 사용하여 수행 가능하다.</p>

<p>따라서, 앞에서 구현한 <code class="language-plaintext highlighter-rouge">cat /etc/passwd | wc -l</code> 를 독립적으로 수행하는 두개의 프로세스를 구현하고 이를 연결하여 사용가능하다. 해당 사항을 shell script 로 구현하면</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#!/bin/bash</span>
<span class="nb">mkfifo</span> <span class="nt">-m</span> 0600 fifo
<span class="nb">wc</span> <span class="nt">-l</span> &lt; fifo &amp;
<span class="nb">cat</span> /etc/passwd <span class="o">&gt;</span> fifo
<span class="nb">rm </span>fifo
</code></pre></div></div>

<p>실행결과</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>user@DESKTOP:~<span class="nv">$ </span><span class="nb">chmod</span> +x pipe3.sh
user@DESKTOP:~<span class="nv">$ </span>./pipe3.sh
27
user@DESKTOP:~<span class="nv">$ </span><span class="nb">cat</span> /etc/passwd | <span class="nb">wc</span> <span class="nt">-l</span>
27
</code></pre></div></div>]]></content><author><name>Yong gon Yun</name></author><category term="linux" /><category term="IPC" /><category term="inter-process communication" /><category term="pipe" /><summary type="html"><![CDATA[개발자를 위한 반도체 SW개발 기초 (디바이스 드라이버 개발) 관련 학습 16]]></summary></entry><entry><title type="html">IPC 실습 01 - fork / execve</title><link href="http://localhost:4000/IPC01.html" rel="alternate" type="text/html" title="IPC 실습 01 - fork / execve" /><published>2024-03-18T10:32:20+09:00</published><updated>2024-03-18T10:32:20+09:00</updated><id>http://localhost:4000/IPC01</id><content type="html" xml:base="http://localhost:4000/IPC01.html"><![CDATA[<style>
    summary::-webkit-details-marker {
        display: none;
    }
    summary {
        list-style: none;
    }
</style>

<details><summary></summary>
에러방지  에러방지 에러방지  에러방지 에러방지  에러방지 에러방지  에러방지
에러방지  에러방지 에러방지  에러방지 에러방지  에러방지 에러방지  에러방지
에러방지  에러방지 에러방지  에러방지 에러방지  에러방지 에러방지  에러방지
에러방지  에러방지 에러방지  에러방지 에러방지  에러방지 에러방지  에러방지
에러방지  에러방지 에러방지  에러방지 에러방지  에러방지 에러방지  에러방지
에러방지  에러방지 에러방지  에러방지 에러방지  에러방지 에러방지  에러방지
에러방지  에러방지 에러방지  에러방지 에러방지  에러방지 에러방지  에러방지
에러방지  에러방지 에러방지  에러방지 에러방지  에러방지 에러방지  에러방지
에러방지  에러방지 에러방지  에러방지 에러방지  에러방지 에러방지  에러방지
에러방지  에러방지 에러방지  에러방지 에러방지  에러방지 에러방지  에러방지
에러방지  에러방지 에러방지  에러방지 에러방지  에러방지 에러방지  에러방지
에러방지  에러방지 에러방지  에러방지 에러방지  에러방지 에러방지  에러방지
</details>

<p>아래 내용은 개발자를 위한 시스템 반도체 SW개발 기초(디바이스 드라이버 개발) (https://comento.kr/) 강의 내용 중 일부에 해당함.</p>

<h3 id="fork-를-사용한-자식-프로세스-생성-및-종료">fork 를 사용한 자식 프로세스 생성 및 종료</h3>

<p>아래와 같이 소스코드를 작성하여 자식 프로세스의 생애 주기 (생성 - 작업 - 좀비(작업완료) - 정리) 를 확인할 수 있는 코드를 작성한다.</p>

<div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cp">#include</span> <span class="cpf">&lt;stdio.h&gt;</span><span class="cp">
#include</span> <span class="cpf">&lt;unistd.h&gt;</span><span class="cp">
#include</span> <span class="cpf">&lt;sys/wait.h&gt;</span><span class="cp">
</span>
<span class="k">extern</span> <span class="kt">char</span> <span class="o">**</span><span class="n">environ</span><span class="p">;</span> <span class="c1">// 환경변수를 나타내는 전역 변수</span>

<span class="kt">char</span> <span class="n">ppid_str</span><span class="p">[</span><span class="mi">32</span><span class="p">];</span>
<span class="kt">char</span><span class="o">*</span> <span class="k">const</span> <span class="n">ps_argv</span><span class="p">[]</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s">"/bin/ps"</span><span class="p">,</span>
    <span class="s">"-fx"</span><span class="p">,</span>
    <span class="nb">NULL</span><span class="p">,</span>
<span class="p">};</span>

<span class="kt">int</span> <span class="nf">run_ps</span><span class="p">()</span> <span class="p">{</span> <span class="c1">// 현재 작업 중인 시스템 프로세스 리스트를 확인하기 위한 자식 프로세스 생성 -- (b)</span>
    <span class="kt">int</span> <span class="n">status</span><span class="p">;</span>
    <span class="n">pid_t</span> <span class="n">pid</span><span class="p">;</span>

    <span class="n">printf</span><span class="p">(</span><span class="s">"Process list &gt;</span><span class="se">\n</span><span class="s">"</span><span class="p">);</span>

    <span class="n">pid</span> <span class="o">=</span> <span class="n">fork</span><span class="p">();</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">pid</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">execve</span><span class="p">(</span><span class="n">ps_argv</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">ps_argv</span><span class="p">,</span> <span class="n">environ</span><span class="p">);</span> <span class="c1">// execve 시스템 콜 실행 -- (c)</span>
    <span class="p">}</span>

    <span class="n">waitpid</span><span class="p">(</span><span class="n">pid</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">status</span><span class="p">,</span> <span class="mi">0</span><span class="cm">/*no option*/</span><span class="p">);</span>  
<span class="p">}</span>

<span class="kt">int</span> <span class="nf">main</span><span class="p">()</span> <span class="p">{</span> <span class="c1">// fork 프로세스 생애 주기를 보기 위해 순차적 작업 구현 -- (a)</span>
    <span class="kt">int</span> <span class="n">status</span><span class="p">;</span>
    <span class="n">pid_t</span> <span class="n">pid</span><span class="p">;</span>
    <span class="n">pid</span> <span class="o">=</span> <span class="n">fork</span><span class="p">();</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">pid</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="p">{</span> <span class="c1">// c. 생성된 자식 프로세스의 작업</span>
        <span class="n">printf</span><span class="p">(</span><span class="s">"[Child] pid-%d ppid-%d</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="n">getpid</span><span class="p">(),</span> <span class="n">getppid</span><span class="p">());</span>
        <span class="n">sleep</span><span class="p">(</span><span class="mi">1</span><span class="p">);</span> <span class="c1">// 부모프로세스 </span>
        <span class="n">printf</span><span class="p">(</span><span class="s">"[Child] exit</span><span class="se">\n</span><span class="s">"</span><span class="p">);</span>
        
        <span class="k">return</span> <span class="mi">3</span><span class="p">;</span> <span class="c1">// c-1. 자식 프로세스 작업 종료</span>
    <span class="p">}</span>
    <span class="k">else</span> <span class="p">{</span> <span class="c1">// p. 부모 프로세스</span>
        <span class="n">printf</span><span class="p">(</span><span class="s">"[Parent] pid-%d</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="n">getpid</span><span class="p">());</span>
        <span class="n">run_ps</span><span class="p">();</span> <span class="c1">// p-1 작업 수행 </span>

        <span class="n">sleep</span><span class="p">(</span><span class="mi">2</span><span class="p">);</span> <span class="c1">// 자식 프로세스 작업 완료 대기</span>
        <span class="n">run_ps</span><span class="p">();</span> <span class="c1">// p-2 자식 프로세스 작업 완료 후 전체 시스템 프로세스 상태 확인</span>

        <span class="n">waitpid</span><span class="p">(</span><span class="n">pid</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">status</span><span class="p">,</span> <span class="mi">0</span><span class="cm">/*no option*/</span><span class="p">);</span> <span class="c1">// p-3 자식 프로세스 작업 완료 대기 및 좀비 프로세스 정리 후</span>
        <span class="n">printf</span><span class="p">(</span><span class="s">"[Parent] child exit: %d</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="n">WEXITSTATUS</span><span class="p">(</span><span class="n">status</span><span class="p">));</span> <span class="c1">// 자식 프로세스 종료 상태 확인</span>

        <span class="n">run_ps</span><span class="p">();</span> <span class="c1">// p-4 (자식 프로세스를 완전히 제거한 이후) 프로세스 실행 상태 확인</span>
        <span class="n">printf</span><span class="p">(</span><span class="s">"[Parent] exit</span><span class="se">\n</span><span class="s">"</span><span class="p">);</span>

        <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
    <span class="p">}</span>
<span class="p">}</span>
</code></pre></div></div>

<h4 id="a-fork-프로세스-생애-주기를-보기-위해-순차적-작업-구현">a. fork 프로세스 생애 주기를 보기 위해 순차적 작업 구현</h4>

<p><code class="language-plaintext highlighter-rouge">pid = fork();</code> 를 수행하면 동일한 내용을 가진 부모 프로세스와 자식 프로세스가 생성된다. 다른 점은 해당 시스템콜 수행후 반환값 <code class="language-plaintext highlighter-rouge">pid</code> 는 자식프로세스는 0, 부모 프로세스는 자식 프로세스 PID 값을 가지게 된다.</p>

<p>따라서 그다음 조건문에서 각각의 프로세스 작업이 달라지게 되며, 각각의 작업은 동시에 수행되므로, 작업의 우선 순위를 확정할 수 없다. 여기서는 그 작업을 시간 순서대로 실행시켜서 그 생애 주기를 정확하게 확인하기 위해 필요한 구간에 각 프로세스에 <code class="language-plaintext highlighter-rouge">sleep()</code> 조건을 주어서 구현하였다.</p>

<p>그 작업 과정을 시간 순서대로 정리하면 아래와 같다.</p>

<ul>
  <li>부모/ 자식 프로세스 각각 pid 출력 (우선순위 없음)</li>
  <li>부모 p-1 : 자식 프로세스가 아직 실행 중인 상태에서 시스템 프로세스 리스트를 출력하는 작업 수행</li>
  <li>자식 c-1 : 자식 프로세스 내부 작업을 종료. 해당 프로세스는 반환 값(3) 을 가진 좀비 상태로 전환됨.</li>
  <li>부모 p-2 : 시스템 프로세스 리스트를 출력하는 작업 수행. 여기서 아직 자식 프로세스가 좀비(z) 상태로 남아있음을 볼 수 있다.</li>
  <li>부모 p-3 : 좀비 상태의 자식 프로세스를 정리하고, 자식 프로세스 반환값(3)을 확인.</li>
  <li>부모 p-4 : 마지막으로  시스템 프로세스 리스트에서 자식 프로세스가 사라짐을 확인.</li>
</ul>

<p>위 내용을 실제로 실행하여 그 결과를 확인하면 아래와 같다</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>user@DESKTOP:~<span class="nv">$ </span>gcc <span class="nt">-o</span> fork fork.c
user@DESKTOP:~<span class="nv">$ </span>./fork
<span class="o">[</span>Parent] pid-7653
Process list <span class="o">&gt;</span>
<span class="o">[</span>Child] pid-7654 ppid-7653
    PID TTY      STAT   TIME COMMAND
    437 pts/1    S+     0:00 <span class="nt">-bash</span>
    372 pts/0    Ss     0:00 <span class="nt">-bash</span>
   7653 pts/0    S+     0:00  <span class="se">\_</span> ./fork
   7654 pts/0    S+     0:00      <span class="se">\_</span> ./fork
   7655 pts/0    R+     0:00      <span class="se">\_</span> /bin/ps <span class="nt">-fx</span>
    431 ?        Ss     0:00 /lib/systemd/systemd <span class="nt">--user</span>
    432 ?        S      0:00  <span class="se">\_</span> <span class="o">(</span>sd-pam<span class="o">)</span>
<span class="o">[</span>Child] <span class="nb">exit
</span>Process list <span class="o">&gt;</span>
    PID TTY      STAT   TIME COMMAND
    437 pts/1    S+     0:00 <span class="nt">-bash</span>
    372 pts/0    Ss     0:00 <span class="nt">-bash</span>
   7653 pts/0    S+     0:00  <span class="se">\_</span> ./fork
   7654 pts/0    Z+     0:00      <span class="se">\_</span> <span class="o">[</span>fork] &lt;defunct&gt;
   7664 pts/0    R+     0:00      <span class="se">\_</span> /bin/ps <span class="nt">-fx</span>
    431 ?        Ss     0:00 /lib/systemd/systemd <span class="nt">--user</span>
    432 ?        S      0:00  <span class="se">\_</span> <span class="o">(</span>sd-pam<span class="o">)</span>
<span class="o">[</span>Parent] child <span class="nb">exit</span>: 3
Process list <span class="o">&gt;</span>
    PID TTY      STAT   TIME COMMAND
    437 pts/1    S+     0:00 <span class="nt">-bash</span>
    372 pts/0    Ss     0:00 <span class="nt">-bash</span>
   7653 pts/0    S+     0:00  <span class="se">\_</span> ./fork
   7665 pts/0    R+     0:00      <span class="se">\_</span> /bin/ps <span class="nt">-fx</span>
    431 ?        Ss     0:00 /lib/systemd/systemd <span class="nt">--user</span>
    432 ?        S      0:00  <span class="se">\_</span> <span class="o">(</span>sd-pam<span class="o">)</span>
<span class="o">[</span>Parent] <span class="nb">exit</span>
</code></pre></div></div>

<p>해당 출력중 아래에 해당하는 항목을 보면, 자식 프로세스 작업을 완료한 이후</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>   7654 pts/0    Z+     0:00      <span class="se">\_</span> <span class="o">[</span>fork] &lt;defunct&gt;
</code></pre></div></div>

<p>state  는 좀비(z) 이며 <defunct> 처리된 것을 볼 수 있다.</defunct></p>

<h4 id="b-현재-작업-중인-시스템-프로세스-리스트를-확인하기-위한-자식-프로세스-생성">b. 현재 작업 중인 시스템 프로세스 리스트를 확인하기 위한 자식 프로세스 생성</h4>

<p><code class="language-plaintext highlighter-rouge">run_ps()</code> 는 현재 실행 중인 시스템 프로세스 목록을 출력하기 위한 명령어 <code class="language-plaintext highlighter-rouge">ps</code> 을 해당 명령어 파일로 실행 시키는 함수 이다.</p>

<p>해당 함수 내에서 실제로 ps 명령어를 실행하는 작업은 <code class="language-plaintext highlighter-rouge">fork</code> 하여 자식 프로세스가 작업하도록 구성되어 있으며, 해당 프로세스는 아래와 같이 출력됨을 확인 할 수 있다.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    7655 pts/0    R+     0:00      <span class="se">\_</span> /bin/ps <span class="nt">-fx</span>
</code></pre></div></div>

<h4 id="c-execve-시스템-콜-실행">c. execve 시스템 콜 실행</h4>

<p>` execve(ps_argv[0], ps_argv, environ)<code class="language-plaintext highlighter-rouge"> 시스템 콜이 자식 프로세스가 </code>ps` 명령어를 실행 시키는 부분이다.</p>

<p>해당 함수의 매개 변수를 보면 다음가 같다.</p>

<p>execve(filename, argv, env)</p>

<ul>
  <li>filename : 현재 프로세스에서 실행 시킬 파일</li>
  <li>argv : 실행 프로그램에 전달할 인자 배열. 배열 첫번째는 일반적으로 실행파일의 이름, 중간 인자들은 해당 프로그램 실행시 설정 옵션, 파라미터 들, 마지막은 NULL 로 종료를 의미한다.</li>
  <li>env(환경변수) : 실행 프로그램에게 전달되는 환경 변수 배열이며, 각 환경 변수는 “KEY=value” 형태의 문자열이며, 마지막 값은 NULL 이어야 한다. 다만, 환경변수는 프로세스가 실행될 때, 자체적으로 설정되며, 해당 변수를 <code class="language-plaintext highlighter-rouge">extern char **environ;</code> 선언으로 포인터로 지정해서 사용하게 된다.</li>
</ul>]]></content><author><name>Yong gon Yun</name></author><category term="linux" /><category term="IPC" /><category term="inter-process communication" /><category term="fork" /><category term="execve" /><summary type="html"><![CDATA[개발자를 위한 반도체 SW개발 기초 (디바이스 드라이버 개발) 관련 학습 15]]></summary></entry><entry><title type="html">udev 와 연동하기</title><link href="http://localhost:4000/udev1.html" rel="alternate" type="text/html" title="udev 와 연동하기" /><published>2024-03-02T10:32:20+09:00</published><updated>2024-03-02T10:32:20+09:00</updated><id>http://localhost:4000/udev1</id><content type="html" xml:base="http://localhost:4000/udev1.html"><![CDATA[<style>
    summary::-webkit-details-marker {
        display: none;
    }
    summary {
        list-style: none;
    }
</style>

<details><summary></summary>
에러방지  에러방지 에러방지  에러방지 에러방지  에러방지 에러방지  에러방지
에러방지  에러방지 에러방지  에러방지 에러방지  에러방지 에러방지  에러방지
에러방지  에러방지 에러방지  에러방지 에러방지  에러방지 에러방지  에러방지
에러방지  에러방지 에러방지  에러방지 에러방지  에러방지 에러방지  에러방지
에러방지  에러방지 에러방지  에러방지 에러방지  에러방지 에러방지  에러방지
에러방지  에러방지 에러방지  에러방지 에러방지  에러방지 에러방지  에러방지
에러방지  에러방지 에러방지  에러방지 에러방지  에러방지 에러방지  에러방지
에러방지  에러방지 에러방지  에러방지 에러방지  에러방지 에러방지  에러방지
에러방지  에러방지 에러방지  에러방지 에러방지  에러방지 에러방지  에러방지
에러방지  에러방지 에러방지  에러방지 에러방지  에러방지 에러방지  에러방지
에러방지  에러방지 에러방지  에러방지 에러방지  에러방지 에러방지  에러방지
에러방지  에러방지 에러방지  에러방지 에러방지  에러방지 에러방지  에러방지
</details>

<p>아래 내용은 개발자를 위한 시스템 반도체 SW개발 기초(디바이스 드라이버 개발) (https://comento.kr/) 강의 내용 중 일부에 해당함.</p>

<h3 id="1-udev-란">1. udev 란?</h3>

<p>리눅스 시스템에서 장치 관리를 담당하는 사용자 공간의 데몬. 이는 커널에서 장치 이벤트를 수신하고, 이를 기반으로 장치 파일을 동적으로 생성하거나 삭제하며, 장치에 대한 규칙을 처리하는 역할을 한다. udev의 주요 목적은 시스템이 실행 중일 때 장치를 관리하고, 장치 간의 일관된 명명 규칙을 유지하며, 사용자가 정의한 규칙에 따라 장치에 대한 추가적인 설정을 자동으로 적용하는 것이다.</p>

<p>주요 기능</p>

<ol>
  <li>
    <p>동적 장치 관리: udev는 USB 드라이브나 네트워크 어댑터 같은 하드웨어 장치가 시스템에 추가되거나 제거될 때, 해당 변화를 감지하고 반응한다. 이를 통해, 시스템은 실행 중에도 장치의 추가 및 제거를 실시간으로 처리할 수 있다. 특히 해당 경우는, 미리 앞에서 학습한 방법(major 번호를 미리 입력)으로 처리할 수 없다. (ex. USB 인식)</p>
  </li>
  <li>
    <p>장치 파일 생성 및 삭제: 장치가 시스템에 연결될 때, udev는 /dev 디렉토리에 해당 장치를 대표하는 장치 파일(또는 노드)을 생성합니다. 장치가 제거되면, 해당 파일도 삭제됩니다. 이 과정은 자동으로 수행되어 사용자나 시스템 관리자가 수동으로 장치 파일을 관리할 필요가 없습니다.</p>
  </li>
  <li>
    <p>규칙 기반 장치 관리: udev는 /etc/udev/rules.d와 같은 디렉토리에 저장된 규칙 파일을 사용하여 장치에 대한 세부적인 관리를 수행합니다. 이 규칙들은 장치의 명명, 권한 설정, 장치에 대한 사용자 정의 액션 실행 등을 정의할 수 있습니다.</p>
  </li>
  <li>
    <p>장치 정보 제공: udev는 연결된 장치에 대한 상세한 메타데이터를 제공합니다. 이 정보는 시스템이 장치를 정확히 식별하고, 적절한 드라이버를 로드하며, 사용자 정의 규칙을 적용하는 데 사용됩니다.</p>
  </li>
  <li>
    <p>사용자 정의 액션: 사용자는 udev 규칙을 통해 특정 장치에 대해 특정 이벤트가 발생했을 때 실행할 명령이나 스크립트를 지정할 수 있습니다. 이를 통해 장치가 시스템에 연결될 때 자동으로 필요한 설정을 적용하거나, 필요한 서비스를 시작할 수 있습니다.</p>
  </li>
</ol>

<p>장치 인식 process</p>

<p>새로운 디바이스가 인식되면,</p>

<ol>
  <li>커널이 uevent 를 발생시켜서 udev 데몬에게 이를 알림</li>
  <li>udev 데몬은 /sys 를 확인하여 디바이스에 대한 정보를 알아냄
    <ul>
      <li>커널이 /sys/devices 와 /sys/class 에 새로운 디바이스에 대한 디렉토리를 생성</li>
      <li>디렉토리 내의 dev 파일을 읽으면 주번호와 부번호를 알 수 있음.</li>
    </ul>
  </li>
  <li>udev 데몬은 알아낸 정보를 바탕으로 새로운 디바이스 노드를 /dev 에 생성</li>
</ol>

<h3 id="2-device-class">2. device class</h3>

<p>리눅스 커널의 디바이스 모델에서 “디바이스 클래스(Device Class)”는 시스템 내의 디바이스들을 분류하는 방법 중 하나. 유사한 기능이나 목적을 가진 디바이스들을 그룹화하여 관리</p>

<p>예를 들면,</p>
<ul>
  <li>input 클래스 : 키보드, 마우스 등의 입력 장치를 포함</li>
  <li>net 클래스 : 네트워크 인터페이스 카드(NICs)와 같은 네트워킹 장치를 포함</li>
</ul>

<p>디바이스 클래스 기능</p>

<ol>
  <li>
    <p>통합된 관리: 디바이스 클래스는 특정 유형의 디바이스들(예: 입력 디바이스, 네트워크 인터페이스, 오디오 장치 등)을 묶어서 일관된 방식으로 시스템 내에서 작동할 수 있도록 관리.</p>
  </li>
  <li>
    <p>자동 디바이스 파일 생성: /dev 디렉토리에 있는 디바이스 파일들은 사용자 공간의 애플리케이션이 커널의 디바이스 드라이버와 통신하는 인터페이스를 제공한다. 클래스 시스템을 사용하면, 새로운 디바이스가 시스템에 추가될 때 자동으로 해당 디바이스 파일이 생성된다.</p>
  </li>
  <li>
    <p>시스템의 가시성 및 접근성 향상: /sys/class 내에는 각 디바이스 클래스에 대한 디렉토리가 있으며 (ex. input, mem, pci_bus, net, tty ..), 이는 디바이스에 대한 메타데이터와 상태 정보를 제공한다. 이 정보를 통해 사용자나 애플리케이션은 디바이스의 현재 상태를 쉽게 파악할 수 있다.</p>
  </li>
  <li>
    <p>표준화된 인터페이스 제공: 디바이스 클래스는 개발자들에게 표준화된 프로그래밍 인터페이스를 제공한다. 이를 통해 개발자는 특정 클래스에 속하는 모든 디바이스들과 일관된 방식으로 상호작용할 수 있게 된다.</p>
  </li>
</ol>

<h3 id="3-디바이스-생성을-udev-에게-알리기">3. 디바이스 생성을 udev 에게 알리기</h3>

<ol>
  <li>class_create(owner, name): /sys/class 에 새로운 디바이스 클래스 생성
    <ul>
      <li>owner : 어떤 모듈에 속해 있는가를 나타냄 (자체 모듈인 경우 <code class="language-plaintext highlighter-rouge">THIS_MODULE</code> 로 지정)</li>
    </ul>
  </li>
  <li>device_create(class, parent, dev_no, data, name): 새로운 디바이스 생성 (/dev)
    <ul>
      <li>parent : 부모 디바이스 (일반적으로 버스 디바이스) 를 나타내며 NULL 로 지정 가능</li>
      <li>dev_no : <code class="language-plaintext highlighter-rouge">MKDEV(major, minor)</code> 매크로를 사용하여 주번호, 부번호 명시. (MKDEV 매크로는 주/부번호를 하나의 디바이스 번호로 결합항 디바이스 파일 고유 식별자 역할을 함.)</li>
      <li>data   : 디바이스와 관련된 데이터를 지정</li>
      <li>name   : 디바이스의 이름을 지정. printf 함수에서 사용하는 것과 유사하게, 문자열과 숫자를 조합하여 디바이스 이름을 생성할 수 있다. (ex. <code class="language-plaintext highlighter-rouge">"%s%d", DEVICE_NAME, minor</code>) <br /><br /></li>
    </ul>

    <p>-&gt; /sys/devices/ 에 새로운 디렉토리와 dev 파일 생성</p>
  </li>
</ol>

<h3 id="4-드라이브-노드-소스코드-작성">4. 드라이브 노드 소스코드 작성</h3>

<p>기존 /linux/drivers/comento/main.c 파일의 <code class="language-plaintext highlighter-rouge">init</code> 함수 내용을 수정한다.</p>

<p>아래 첫번째 코드는 udev 를 사용하는 해당 함수의 정식적 구조를 따라 작성된 것이며, 그 아래 코드는 해당 포스트 실습에서 사용한 간략화된 코드 이다.</p>

<ul>
  <li>일반적 구조 구현 코드
```c
#include &lt;linux/device.h&gt;
#include &lt;linux/fs.h&gt;</li>
</ul>

<p>#define COMENTO_DEVICE_NAME “comento-device”
#define COMENTO_CLASS_NAME “comento”</p>

<p>static struct file_operations comento_device_fops;</p>

<p>static int comento_device_major;
static struct class *comento_class;
static struct device *comento_device;</p>

<p>static int __init comento_module_init(void) {
    int minor = 0;</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>comento_device_major = register_chardev(
    0, 
    COMENTO_DEVICE_NAME, 
    &amp;comento_device_fops
    );

if(comento_device_major &lt; 0) {
    printk(KENR_ERR "%s: Failed to get major number", COMENTO_DEVICE_NAME);
    ret = comento_device_major;
    goto err_register_chrdev;
}

comento_class = class_create(THIS_MODULE, COMENTO_CLASS_NAME);

// 반환값이 error 인지 확인 
if(IS_ERR(comento_class)) {
    printk(KERN_ERR "%s: Failed to create class", COMENTO_DEVICE_NAME);
    ret = PTR_ERR(comento_class);
    goto err_class;
    // goto 문의 사용은 일반적으로 anti-pattern 이지만, 
    // 예외적으로 어떤 자원의 획득과 해제 관련(해당의 경우) 자주 사용됨. 
}

comento_device = device_create(
    comento_class, 
    NULL, 
    MKDEV(comento_device_major, minor), 
    NULL,
    "%s%d",
    COMENTO_DEVICE_NAME,
    minor
    );

if (IS_ERR(comento_device[minor])) {
    ret = PTR_ERR(comento_device[minor]);
    goto err_device;
}

// error 발생시 class 해제  device 등록 해제 
err_device: class_destroy(comento_class);
err_class: unregister_chrdev(comento_device_major, COMENTO_DEVICE_NAME);
err_register_chrdev: 

return ret; }
</code></pre></div></div>

<p>module_init(comento_module_init);</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
* 실습 구현 코드
```c
...
#include &lt;linux/spinlock.h&gt;

// 기존 device name, major number 설정값 삭제
// #define COMENTO_DEVICE_NAME "comento-device"
// #define COMENTO_MAJOR_NUMBER 177
#define COMENTO_BUF_SIZE 16
...

// 현재 코드에서 구현하지 않았지만 일반적으로 exit 할 때, 
// class / device 모두 destroy 처리해준다. 
// 이 때 goto 문 이용하기도 하므로 이런 이유로 전역 변수로 선언해준다. 
static struct class* class;
static struct device* device;

static int __init comento_module_init(void)
{
    printk(KERN_DEBUG "%s\n", __func__);

    // udev 를 통해서 major 번호를 자동 부여받을 것이브로 0 (자동 지정) 으로 설정
    int major = register_chrdev(0, "comento", &amp;fops); 
    int minor = 17; // 임의의 숫자 부여

    // THIS_MODULE : 이 모듈이 클래스의 주인 (owner)임을 명시. (최신 코드에서는 명시하지 않음?)
    // owner의 의미 : 이 모듈이 사라졌을 때, class destroy 를 따라하지 않는다고 하더라도
    //               해당 클래스는 알아서 사라지게 된다. 이유는 owner 인 `THIS_MODULE` 이 사라졌기 때문이다.
    //               그래도 일반적으로 exit 할 때, 해당 클래스를 destroy 해준다.
    class = class_create("comento");

    // 부모 디바이스, data 는 NULL
    // name : printf 함수에서 사용하는 것과 유사하게, 문자열과 숫자를 조합하여 디바이스 이름을 생성
    device = device_create(class, NULL, MKDEV(major, minor), NULL, "%s%d", "comento", minor);

    return 0; // 자동 지정 이므로 0 으로 설정
}
...
</code></pre></div></div>

<p>빌드 &amp; ko 파일 rootfs 이미지 내 추가, QEMU 실행</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>user@DESKTOP:~/linux<span class="nv">$ ARCH</span><span class="o">=</span>arm64 <span class="nv">CROSS_COMPILE</span><span class="o">=</span>/home/gon/gcc-arm-10.3-2021.07-x86_64-aarch64-none-linux-gnu/bin/aarch64-none-linux-gnu- make
ch64-none-linux-gnu/bin/aarch64-none-linux-gnu- make
  CALL    scripts/checksyscalls.sh
  CC <span class="o">[</span>M]  drivers/comento/main.o
  LD <span class="o">[</span>M]  drivers/comento/comento.o
  MODPOST Module.symvers
  LD <span class="o">[</span>M]  drivers/comento/comento.ko
user@DESKTOP:~/linux<span class="nv">$ </span><span class="nb">sudo </span>mount <span class="nt">-o</span> loop buildroot/output/images/rootfs.ext4 /mnt
user@DESKTOP:~/linux<span class="nv">$ </span><span class="nb">sudo cp </span>drivers/comento/comento.ko /mnt/usr/lib/modules/.
user@DESKTOP:~/linux<span class="nv">$ </span><span class="nb">sync 
</span>user@DESKTOP:~/linux<span class="nv">$ </span><span class="nb">sudo </span>umount /mnt
user@DESKTOP:~/linux<span class="nv">$ </span><span class="nb">cd</span> ..
user@DESKTOP:~<span class="nv">$ </span>qemu-system-aarch64 <span class="nt">-kernel</span> linux/arch/arm64/boot/Image <span class="nt">-drive</span> <span class="nv">format</span><span class="o">=</span>raw,file<span class="o">=</span>buildroot/output/images/rootfs.ext4,if<span class="o">=</span>virtio <span class="nt">-append</span> <span class="s2">"root=/dev/vda console=ttyAMA0 nokaslr"</span> <span class="nt">-nographic</span> <span class="nt">-M</span> virt <span class="nt">-cpu</span> cortex-a72 <span class="nt">-m</span> 2G <span class="nt">-smp</span> 2
</code></pre></div></div>

<h3 id="5-커널-모듈-삽입-및-실행">5. 커널 모듈 삽입 및 실행</h3>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code># cd /sys/class
# ls
ata_device    drm           misc          scsi_device   tty
ata_link      graphics      net           scsi_disk     vc
ata_port      hwmon         pci_bus       scsi_generic  virtio-ports
bdi           i2c-adapter   power_supply  scsi_host     vtconsole
block         input         pps           thermal       wakeup
bsg           iommu         ptp           tpm
devlink       mem           rtc           tpmrm
</code></pre></div></div>

<p>위와 같이  /sys/class 에 들어가면 기존 class 디렉토리들이 있다.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code># insmod /usr/lib/modules/comento.ko
# ls
ata_device    devlink       mem           rtc           tpmrm
ata_link      drm           misc          scsi_device   tty
ata_port      graphics      net           scsi_disk     vc
bdi           hwmon         pci_bus       scsi_generic  virtio-ports
block         i2c-adapter   power_supply  scsi_host     vtconsole
bsg           input         pps           thermal       wakeup
comento       iommu         ptp           tpm
# cd comento
# ls -lah
total 0
drwxr-xr-x    2 root     root           0 Mar  3 08:48 .
drwxr-xr-x   36 root     root           0 Mar  3 08:46 ..
lrwxrwxrwx    1 root     root           0 Mar  3 08:53 comento17 -&gt; ../../devices/virtual/comento/comento17
</code></pre></div></div>

<p>comento 커널 모듈을 삽입해주면 comento 디렉토리가 추가된것을 확인할 수 있으며, 해당 디렉토리 안에 코드에서 명명한 대로 comento17 (minor 번호 추가) 디바이스가 생성된 것을 볼 수 있다. 해당 파일을 symbolic link 실제 파일은 /sys/devices/virtual/coment/comento17 에 존재함을 알 수 있다 해당 경로로 다시 가보면,</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code># cd /sys/devices/virtual/comento/comento17
# ls -lah
total 0
drwxr-xr-x    3 root     root           0 Mar  3 08:53 .
drwxr-xr-x    3 root     root           0 Mar  3 08:53 ..
-r--r--r--    1 root     root        4.0K Mar  3 08:59 dev
drwxr-xr-x    2 root     root           0 Mar  3 08:59 power
lrwxrwxrwx    1 root     root           0 Mar  3 08:59 subsystem -&gt; ../../../../class/comento
-rw-r--r--    1 root     root        4.0K Mar  3 08:59 uevent
</code></pre></div></div>

<p>여기에 dev 파일이 존재한다. 그 내용을 출력해보면</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code># cat dev
248:17
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">주번호:부번호</code> 를 볼 수 있다. 주번호 값은 udev 데몬 가 할당한 임의의 번호임도 확인 된다. 
주번호, 부번호는  /dev/coment 내 존재하는 드라이버 노드 정보로도 확인 가능하다.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code># ls -lah /dev/comento*
crw-------    1 root     root      248,  17 Mar  3 08:48 /dev/comento17
</code></pre></div></div>

<p>앞에서 확인한 내용과 udev 를 사용하여 어떻게 디바이스 파일이 생성되는지 과정을 정리하면 아래와 같다.</p>

<ol>
  <li>
    <p>커널 모듈을 삽입 (insmod): 해당 모듈을 커널에 로드</p>
  </li>
  <li>
    <p>uevent 발생: 시스템에 새로운 하드웨어가 추가되었거나, 새로운 드라이버가 로드되었음을 알림</p>
  </li>
  <li>
    <p>udev class 생성 (/sys/class/): 커널 모듈(또는 드라이버) 내에서 class_create() 함수를 호출하여 디바이스 클래스를 생성하고, 이 정보는 /sys/class/에 반영</p>
  </li>
  <li>
    <p>udev는 앞에서 생성한 정보를 바탕으로 작업을 수행</p>
  </li>
  <li>
    <p>주번호 및 디바이스 생성 (/sys/device/): 커널에 의해 주번호가 생성되며, 커널 모듈이나 드라이버는 디바이스 파일에 대한 메이저 번호와 마이너 번호를 할당받아 사용. /sys/devices/는 실제 장치와 그 속성을 반영하는 커널의 디바이스 트리를 나타내며, 여기서 디바이스는 커널이나 모듈에 의해 등록됨.</p>
  </li>
  <li>
    <p>드라이버 생성 (/dev/): /dev/ 디렉토리에 디바이스 파일이 생성됨. 이 과정은 udev에 의해 자동으로 처리되며, /dev/ 내의 디바이스 파일은 사용자 공간에서 해당 디바이스에 접근하기 위한 인터페이스를 제공. udev 규칙에 따라 디바이스 파일의 이름, 권한 등이 설정.</p>
  </li>
</ol>]]></content><author><name>Yong gon Yun</name></author><category term="linux" /><category term="device driver" /><category term="udev" /><summary type="html"><![CDATA[개발자를 위한 반도체 SW개발 기초 (디바이스 드라이버 개발) 관련 학습 14]]></summary></entry></feed>